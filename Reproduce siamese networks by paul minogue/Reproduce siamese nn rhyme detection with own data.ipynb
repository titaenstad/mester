{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://github.com/minoguep/rhyme_detection and https://paulminogue.com/index.php/2021/02/14/using-a-siamese-neural-network-to-create-a-simple-rhyme-detector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 16:33:17.337084: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-07 16:33:17.337104: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Subtract\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TerminateOnNaN, CSVLogger\n",
    "tqdm.pandas()\n",
    "\n",
    "MAX_LEN = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create dataset\n",
    "We want equally many positive and negative samples of rhyme pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 420\n",
    "\n",
    "positive = pd.read_csv(\"../../norwegian_rhyme_scheme_corpus/annotation_tool/rhyme_pairs.tsv\", sep=\"\\t\", names=[\"word_a\", \"word_b\"], header=0)\n",
    "negative = pd.read_csv(\"../../norwegian_rhyme_scheme_corpus/annotation_tool/negative_rhyme_pairs.tsv\", sep=\"\\t\", names=[\"word_a\", \"word_b\"], header=0)\n",
    "negative = negative.sample(n=len(positive), random_state=seed)\n",
    "positive[\"rhyme\"] = [1]*len(positive)\n",
    "negative[\"rhyme\"] = [0]*len(negative)\n",
    "\n",
    "df = pd.concat([positive, negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_a</th>\n",
       "      <th>word_b</th>\n",
       "      <th>rhyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huse</td>\n",
       "      <td>bruse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>halen</td>\n",
       "      <td>pralen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oksepar</td>\n",
       "      <td>svar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bevare</td>\n",
       "      <td>bare</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ly</td>\n",
       "      <td>våbengny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>støy</td>\n",
       "      <td>brast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20575</th>\n",
       "      <td>meier</td>\n",
       "      <td>kne</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>synger</td>\n",
       "      <td>land</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16537</th>\n",
       "      <td>frukt</td>\n",
       "      <td>sten</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>rett</td>\n",
       "      <td>brente</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14506 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_a    word_b  rhyme\n",
       "0         huse     bruse      1\n",
       "1        halen    pralen      1\n",
       "2      oksepar      svar      1\n",
       "3       bevare      bare      1\n",
       "4           ly  våbengny      1\n",
       "...        ...       ...    ...\n",
       "1757      støy     brast      0\n",
       "20575    meier       kne      0\n",
       "2632    synger      land      0\n",
       "16537    frukt      sten      0\n",
       "2760      rett    brente      0\n",
       "\n",
       "[14506 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create model\n",
    "Copy paste from Pauls notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_inputs(phrase_a, phrase_b, tokenizer):\n",
    "    tokenized_phrases = tokenizer.texts_to_sequences([phrase_a, phrase_b])\n",
    "\n",
    "    # now loop through inputs and pad or reduce size if required\n",
    "    tokenized_phrases_for_output = []\n",
    "    for phrase in tokenized_phrases:\n",
    "        if len(phrase) < MAX_LEN:\n",
    "            length_to_pad = MAX_LEN - len(phrase)\n",
    "            phrase_for_output = ([0] * length_to_pad) + phrase\n",
    "        elif len(phrase) > MAX_LEN:\n",
    "            phrase_for_output = phrase[-MAX_LEN:]\n",
    "        else:\n",
    "            phrase_for_output = phrase\n",
    "        tokenized_phrases_for_output.append(phrase_for_output)\n",
    "\n",
    "    return tf.constant(tokenized_phrases_for_output, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc732ea546634a72aff64355a6fd3333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14506 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 16:33:18.575808: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-07 16:33:18.575836: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-07 16:33:18.575857: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tita-laptop): /proc/driver/nvidia/version does not exist\n",
      "2022-03-07 16:33:18.576094: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(char_level=True, lower=True)\n",
    "tokenizer.fit_on_texts(df['word_a'] + df['word_b'])\n",
    "\n",
    "df['word_tokens'] = df.progress_apply(\n",
    "    lambda row: tokenize_inputs(row['word_a'], row['word_b'], tokenizer), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  \n",
    "    word_a_input_tokens = Input(\n",
    "      shape=(MAX_LEN, 1), name='word_a_input_tokens'\n",
    "      )\n",
    "    word_b_input_tokens = Input(\n",
    "      shape=(MAX_LEN, 1), name='word_b_input_tokens'\n",
    "      )\n",
    "    \n",
    "    # This is the siamese portion of the model \n",
    "    common_lstm = LSTM(64, return_sequences=False, activation=\"relu\", name=\"common_lstm_layer\")\n",
    "\n",
    "    word_a_lstm_output = common_lstm(word_a_input_tokens)\n",
    "    word_b_lstm_output = common_lstm(word_b_input_tokens)\n",
    "\n",
    "    #concatenate_lstm_outputs\n",
    "    concat_layer = Subtract(name=\"concatenate_lstm_outputs\")(\n",
    "      [word_a_lstm_output, word_b_lstm_output]\n",
    "      )\n",
    "    \n",
    "    # dense layers before final classification\n",
    "    dense_layers = Dense(64, activation=\"relu\", name=\"first_dense_layer\")(concat_layer)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    dense_layers = Dense(32, activation=\"relu\", name=\"second_dense_layer\")(dense_layers)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    dense_layers = Dense(8, activation=\"relu\", name=\"third_dense_layer\")(dense_layers)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    classification_layer = Dense(1, activation=\"sigmoid\", name=\"classification_layer\")(dense_layers)\n",
    "    \n",
    "    model = Model(\n",
    "      inputs=[word_a_input_tokens, word_b_input_tokens], \n",
    "      outputs = classification_layer\n",
    "      )\n",
    "\n",
    "    model.compile(\n",
    "      loss=\"binary_crossentropy\",\n",
    "      metrics=[\"accuracy\"],\n",
    "      optimizer=\"Adam\"\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(df['word_tokens']), list(df['rhyme']), stratify=df['rhyme'], \n",
    "    test_size=0.4, random_state=seed\n",
    "    )\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_test, y_test, stratify=y_test, test_size=0.25, random_state=seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "y_val = tf.convert_to_tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8703, 2, 64]), TensorShape([1451, 2, 64]), 4352)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Data set size: Full set: 14506\n",
      "    Train: 8703\n",
      "    Dev: 1451\n",
      "    Test: 4352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    Data set size: Full set: {len(df)}\n",
    "    Train: {len(X_train)}\n",
    "    Dev: {len(X_val)}\n",
    "    Test: {len(X_test)}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Uncomment to train model \n",
    "\n",
    "# model = create_model()\n",
    "\n",
    "# model_checkpoint = ModelCheckpoint(\"models/rhyme_model.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = TerminateOnNaN()\n",
    "# csv_logger = CSVLogger('training.log')\n",
    "\n",
    "# history = model.fit(\n",
    "#     [X_train[:, 0], X_train[:, 1]],\n",
    "#     y_train,\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     callbacks=[model_checkpoint, terminate_on_nan, csv_logger],\n",
    "#     validation_data=([X_val[:, 0], X_val[:, 1]], y_val)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      2176\n",
      "           1       0.97      0.90      0.93      2176\n",
      "\n",
      "    accuracy                           0.94      4352\n",
      "   macro avg       0.94      0.94      0.94      4352\n",
      "weighted avg       0.94      0.94      0.94      4352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model(\"models/rhyme_model.hdf5\")\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "y_pred = y_pred > 0.5\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Kan du ikke se det\n",
      "Sentence 2: Deg skal jeg lede\n",
      "Non-rhyme(0.2574000060558319)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Kaker av alle slag\n",
      "Sentence 2: Her henger Norges flagg\n",
      "Rhyme(0.987500011920929)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Jeg har ikke tid\n",
      "Sentence 2: Til dette svineri\n",
      "Non-rhyme(0.27000001072883606)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Hva har du sagt\n",
      "Sentence 2: Kaken er bakt\n",
      "Rhyme(0.9990000128746033)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Barna er lagt\n",
      "Sentence 2: Kaken er laget\n",
      "Non-rhyme(0.006500000134110451)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Gjorde du det med vilje\n",
      "Sentence 2: Kaken smaker vanilje\n",
      "Rhyme(0.9991000294685364)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Dette vokser\n",
      "Sentence 2: Satans underbukser\n",
      "Rhyme(0.9991000294685364)\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    [\"Kan du ikke se det\", \"Deg skal jeg lede\"], \n",
    "    [\"Kaker av alle slag\", \"Her henger Norges flagg\"], \n",
    "    [\"Jeg har ikke tid\", \"Til dette svineri\"],\n",
    "    [\"Hva har du sagt\", \"Kaken er bakt\"], \n",
    "    [\"Barna er lagt\", \"Kaken er laget\"],\n",
    "    [\"Gjorde du det med vilje\", \"Kaken smaker vanilje\"], \n",
    "    [\"Dette vokser\", \"Satans underbukser\"],\n",
    "]\n",
    "\n",
    "sample_tokens = [tokenize_inputs(lyrics[0], lyrics[1], tokenizer) for lyrics in samples]\n",
    "sample_tokens = tf.convert_to_tensor(sample_tokens)\n",
    "sample_pred = model.predict([sample_tokens[:, 0], sample_tokens[:, 1]])\n",
    "predictions = [round(pred[0], 4) for pred in sample_pred]\n",
    "for i in range(len(samples)):\n",
    "    print(f\"Sentence 1: {samples[i][0]}\")\n",
    "    print(f\"Sentence 2: {samples[i][1]}\")\n",
    "    print(f\"{'Rhyme' if predictions[i] > 0.5 else 'Non-rhyme'}({predictions[i]})\")\n",
    "    print(\"---------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try again with different 2:3 positive to negative ratio\n",
    "Use same test and dev sets, and same tokenizer. Only expand training set.  \n",
    "Train set is already 50/50 positive and negative. We want to make it 40/60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_neg = (len(X_train)//4)\n",
    "new_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 420\n",
    "\n",
    "negative = pd.read_csv(\"../../norwegian_rhyme_scheme_corpus/annotation_tool/negative_rhyme_pairs.tsv\", sep=\"\\t\", names=[\"word_a\", \"word_b\"], header=0)\n",
    "# use same seed, and extract all the pairs already used + the ones we need \n",
    "negative2 = negative.sample(n=len(positive) + new_neg, random_state=seed)\n",
    "negative2[\"rhyme\"] = [0]*len(negative2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_a</th>\n",
       "      <th>word_b</th>\n",
       "      <th>rhyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>fører</td>\n",
       "      <td>inn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12814</th>\n",
       "      <td>skrider</td>\n",
       "      <td>vadested</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11958</th>\n",
       "      <td>trenger</td>\n",
       "      <td>lønn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>vende</td>\n",
       "      <td>snare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>rund</td>\n",
       "      <td>ild</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>sprenger</td>\n",
       "      <td>fanger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21161</th>\n",
       "      <td>flom</td>\n",
       "      <td>lande</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13101</th>\n",
       "      <td>krypet</td>\n",
       "      <td>fred</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15024</th>\n",
       "      <td>fritt</td>\n",
       "      <td>finne</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16566</th>\n",
       "      <td>ve</td>\n",
       "      <td>smil</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2175 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_a    word_b  rhyme\n",
       "6396      fører       inn      0\n",
       "12814   skrider  vadested      0\n",
       "11958   trenger      lønn      0\n",
       "1672      vende     snare      0\n",
       "3198       rund       ild      0\n",
       "...         ...       ...    ...\n",
       "7863   sprenger    fanger      0\n",
       "21161      flom     lande      0\n",
       "13101    krypet      fred      0\n",
       "15024     fritt     finne      0\n",
       "16566        ve      smil      0\n",
       "\n",
       "[2175 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unused_neg = negative2[len(positive):]\n",
    "unused_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dd92f9779c40f5adca1828b7c7b3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171726/1257613138.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unused_neg['word_tokens'] = unused_neg.progress_apply(\n"
     ]
    }
   ],
   "source": [
    "# use same tokenizer as above\n",
    "unused_neg['word_tokens'] = unused_neg.progress_apply(\n",
    "    lambda row: tokenize_inputs(row['word_a'], row['word_b'], tokenizer), axis=1\n",
    ")\n",
    "\n",
    "X_train_new = tf.convert_to_tensor(list(X_train) + list(unused_neg[\"word_tokens\"]))\n",
    "y_train_new = tf.convert_to_tensor(list(y_train) + list(unused_neg[\"rhyme\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "85/85 [==============================] - 5s 44ms/step - loss: 0.6259 - accuracy: 0.5902 - val_loss: 0.5785 - val_accuracy: 0.4997\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.5336 - accuracy: 0.7488 - val_loss: 0.5388 - val_accuracy: 0.8560\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 4s 41ms/step - loss: 0.5019 - accuracy: 0.8578 - val_loss: 0.5108 - val_accuracy: 0.8725\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.4803 - accuracy: 0.8689 - val_loss: 0.4959 - val_accuracy: 0.8773\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.4590 - accuracy: 0.8758 - val_loss: 0.4695 - val_accuracy: 0.8897\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.4341 - accuracy: 0.8798 - val_loss: 0.4630 - val_accuracy: 0.8835\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 3s 39ms/step - loss: 0.4120 - accuracy: 0.8880 - val_loss: 0.4352 - val_accuracy: 0.8904\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.3968 - accuracy: 0.8838 - val_loss: 0.4235 - val_accuracy: 0.8890\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 3s 39ms/step - loss: 0.3837 - accuracy: 0.8833 - val_loss: 0.4199 - val_accuracy: 0.8959\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.3770 - accuracy: 0.8892 - val_loss: 0.3815 - val_accuracy: 0.9070\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.3626 - accuracy: 0.8882 - val_loss: 0.3722 - val_accuracy: 0.9056\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.3518 - accuracy: 0.8933 - val_loss: 0.3743 - val_accuracy: 0.9056\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.3471 - accuracy: 0.8978 - val_loss: 0.3719 - val_accuracy: 0.9063\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.3319 - accuracy: 0.8981 - val_loss: 0.3665 - val_accuracy: 0.9063\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.3314 - accuracy: 0.8947 - val_loss: 0.3486 - val_accuracy: 0.9152\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 4s 41ms/step - loss: 0.3260 - accuracy: 0.8973 - val_loss: 0.3470 - val_accuracy: 0.9214\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.3183 - accuracy: 0.9026 - val_loss: 0.3212 - val_accuracy: 0.9201\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.3103 - accuracy: 0.8985 - val_loss: 0.3438 - val_accuracy: 0.9228\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.3106 - accuracy: 0.9003 - val_loss: 0.3363 - val_accuracy: 0.9166\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 4s 45ms/step - loss: 0.3073 - accuracy: 0.9003 - val_loss: 0.3275 - val_accuracy: 0.9173\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.3031 - accuracy: 0.9049 - val_loss: 0.3179 - val_accuracy: 0.9263\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2906 - accuracy: 0.9021 - val_loss: 0.3175 - val_accuracy: 0.9235\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2919 - accuracy: 0.9072 - val_loss: 0.3157 - val_accuracy: 0.9228\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2915 - accuracy: 0.9050 - val_loss: 0.2945 - val_accuracy: 0.9304\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2911 - accuracy: 0.9026 - val_loss: 0.3062 - val_accuracy: 0.9269\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2806 - accuracy: 0.9089 - val_loss: 0.3014 - val_accuracy: 0.9242\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.2878 - accuracy: 0.9053 - val_loss: 0.3227 - val_accuracy: 0.9290\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 4s 47ms/step - loss: 0.2712 - accuracy: 0.9128 - val_loss: 0.2783 - val_accuracy: 0.9249\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 4s 45ms/step - loss: 0.2736 - accuracy: 0.9085 - val_loss: 0.2772 - val_accuracy: 0.9366\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.2714 - accuracy: 0.9131 - val_loss: 0.3056 - val_accuracy: 0.9304\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2725 - accuracy: 0.9069 - val_loss: 0.2801 - val_accuracy: 0.9359\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2602 - accuracy: 0.9138 - val_loss: 0.2823 - val_accuracy: 0.9318\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2673 - accuracy: 0.9099 - val_loss: 0.2647 - val_accuracy: 0.9394\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2650 - accuracy: 0.9137 - val_loss: 0.2777 - val_accuracy: 0.9338\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2654 - accuracy: 0.9134 - val_loss: 0.2788 - val_accuracy: 0.9276\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2582 - accuracy: 0.9167 - val_loss: 0.2925 - val_accuracy: 0.9400\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 4s 41ms/step - loss: 0.2609 - accuracy: 0.9142 - val_loss: 0.2728 - val_accuracy: 0.9387\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 4s 41ms/step - loss: 0.2458 - accuracy: 0.9190 - val_loss: 0.2676 - val_accuracy: 0.9387\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2524 - accuracy: 0.9171 - val_loss: 0.2680 - val_accuracy: 0.9338\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2335 - accuracy: 0.9248 - val_loss: 0.2618 - val_accuracy: 0.9428\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2521 - accuracy: 0.9176 - val_loss: 0.2483 - val_accuracy: 0.9400\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2493 - accuracy: 0.9182 - val_loss: 0.2885 - val_accuracy: 0.9338\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.2461 - accuracy: 0.9186 - val_loss: 0.2734 - val_accuracy: 0.9338\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 4s 44ms/step - loss: 0.2435 - accuracy: 0.9186 - val_loss: 0.2715 - val_accuracy: 0.9338\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2313 - accuracy: 0.9231 - val_loss: 0.2504 - val_accuracy: 0.9428\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.2235 - accuracy: 0.9265 - val_loss: 0.2829 - val_accuracy: 0.9380\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 4s 41ms/step - loss: 0.2323 - accuracy: 0.9215 - val_loss: 0.2927 - val_accuracy: 0.9359\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2444 - accuracy: 0.9206 - val_loss: 0.2609 - val_accuracy: 0.9380\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 4s 41ms/step - loss: 0.2361 - accuracy: 0.9244 - val_loss: 0.2663 - val_accuracy: 0.9394\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2320 - accuracy: 0.9220 - val_loss: 0.2675 - val_accuracy: 0.9428\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.2213 - accuracy: 0.9270 - val_loss: 0.2539 - val_accuracy: 0.9414\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 4s 41ms/step - loss: 0.2236 - accuracy: 0.9309 - val_loss: 0.2582 - val_accuracy: 0.9414\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 4s 44ms/step - loss: 0.2211 - accuracy: 0.9243 - val_loss: 0.2964 - val_accuracy: 0.9414\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2310 - accuracy: 0.9270 - val_loss: 0.2565 - val_accuracy: 0.9462\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2319 - accuracy: 0.9220 - val_loss: 0.2775 - val_accuracy: 0.9387\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2255 - accuracy: 0.9252 - val_loss: 0.2717 - val_accuracy: 0.9400\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2149 - accuracy: 0.9288 - val_loss: 0.2894 - val_accuracy: 0.9373\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 3s 40ms/step - loss: 0.2214 - accuracy: 0.9255 - val_loss: 0.2886 - val_accuracy: 0.9407\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2209 - accuracy: 0.9289 - val_loss: 0.2583 - val_accuracy: 0.9449\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2174 - accuracy: 0.9285 - val_loss: 0.2870 - val_accuracy: 0.9366\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 4s 46ms/step - loss: 0.2022 - accuracy: 0.9362 - val_loss: 0.2562 - val_accuracy: 0.9449\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 4s 47ms/step - loss: 0.2071 - accuracy: 0.9286 - val_loss: 0.2913 - val_accuracy: 0.9428\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 4s 44ms/step - loss: 0.2009 - accuracy: 0.9329 - val_loss: 0.2737 - val_accuracy: 0.9414\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 4s 46ms/step - loss: 0.2115 - accuracy: 0.9304 - val_loss: 0.2603 - val_accuracy: 0.9490\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.2107 - accuracy: 0.9296 - val_loss: 0.2638 - val_accuracy: 0.9400\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 4s 45ms/step - loss: 0.2080 - accuracy: 0.9339 - val_loss: 0.2947 - val_accuracy: 0.9366\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.2068 - accuracy: 0.9327 - val_loss: 0.2802 - val_accuracy: 0.9435\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.2015 - accuracy: 0.9340 - val_loss: 0.3241 - val_accuracy: 0.9428\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.2059 - accuracy: 0.9367 - val_loss: 0.2514 - val_accuracy: 0.9483\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.2142 - accuracy: 0.9313 - val_loss: 0.2645 - val_accuracy: 0.9414\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.2046 - accuracy: 0.9328 - val_loss: 0.2939 - val_accuracy: 0.9449\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 4s 45ms/step - loss: 0.1924 - accuracy: 0.9367 - val_loss: 0.2982 - val_accuracy: 0.9407\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.2140 - accuracy: 0.9319 - val_loss: 0.2985 - val_accuracy: 0.9442\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 4s 44ms/step - loss: 0.1957 - accuracy: 0.9364 - val_loss: 0.2904 - val_accuracy: 0.9414\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.1998 - accuracy: 0.9330 - val_loss: 0.2917 - val_accuracy: 0.9435\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.1949 - accuracy: 0.9353 - val_loss: 0.2689 - val_accuracy: 0.9490\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 4s 48ms/step - loss: 0.2000 - accuracy: 0.9379 - val_loss: 0.3058 - val_accuracy: 0.9428\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 4s 46ms/step - loss: 0.2000 - accuracy: 0.9345 - val_loss: 0.2638 - val_accuracy: 0.9504\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 4s 46ms/step - loss: 0.1954 - accuracy: 0.9379 - val_loss: 0.2732 - val_accuracy: 0.9380\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 4s 46ms/step - loss: 0.1909 - accuracy: 0.9358 - val_loss: 0.2803 - val_accuracy: 0.9483\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.1840 - accuracy: 0.9402 - val_loss: 0.2760 - val_accuracy: 0.9400\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.1788 - accuracy: 0.9424 - val_loss: 0.2710 - val_accuracy: 0.9518\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.1917 - accuracy: 0.9387 - val_loss: 0.2837 - val_accuracy: 0.9469\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.1820 - accuracy: 0.9393 - val_loss: 0.3122 - val_accuracy: 0.9435\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.1878 - accuracy: 0.9391 - val_loss: 0.2793 - val_accuracy: 0.9504\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.1738 - accuracy: 0.9436 - val_loss: 0.3055 - val_accuracy: 0.9469\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 4s 46ms/step - loss: 0.1878 - accuracy: 0.9398 - val_loss: 0.2895 - val_accuracy: 0.9442\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 4s 46ms/step - loss: 0.1852 - accuracy: 0.9427 - val_loss: 0.3083 - val_accuracy: 0.9476\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 4s 43ms/step - loss: 0.1753 - accuracy: 0.9443 - val_loss: 0.2911 - val_accuracy: 0.9462\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.1842 - accuracy: 0.9422 - val_loss: 0.3105 - val_accuracy: 0.9400\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.1788 - accuracy: 0.9419 - val_loss: 0.2809 - val_accuracy: 0.9476\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 3s 41ms/step - loss: 0.1882 - accuracy: 0.9418 - val_loss: 0.3292 - val_accuracy: 0.9483\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 3s 40ms/step - loss: 0.1746 - accuracy: 0.9430 - val_loss: 0.3349 - val_accuracy: 0.9442\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 4s 44ms/step - loss: 0.1803 - accuracy: 0.9422 - val_loss: 0.3289 - val_accuracy: 0.9476\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 4s 45ms/step - loss: 0.1767 - accuracy: 0.9448 - val_loss: 0.3018 - val_accuracy: 0.9511\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.1664 - accuracy: 0.9467 - val_loss: 0.3194 - val_accuracy: 0.9462\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.1654 - accuracy: 0.9461 - val_loss: 0.2896 - val_accuracy: 0.9456\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.1749 - accuracy: 0.9438 - val_loss: 0.3264 - val_accuracy: 0.9476\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 4s 42ms/step - loss: 0.1780 - accuracy: 0.9472 - val_loss: 0.2849 - val_accuracy: 0.9497\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 4s 44ms/step - loss: 0.1612 - accuracy: 0.9480 - val_loss: 0.3095 - val_accuracy: 0.9504\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to train model\n",
    "model = create_model()\n",
    "                                    # changed model name\n",
    "model_checkpoint = ModelCheckpoint(\"models/rhyme_model_2.hdf5\",monitor=\"val_loss\")\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "csv_logger = CSVLogger('training2.log')\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_new[:, 0], X_train_new[:, 1]],\n",
    "    y_train_new,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    callbacks=[model_checkpoint, terminate_on_nan, csv_logger],\n",
    "    validation_data=([X_val[:, 0], X_val[:, 1]], y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      2176\n",
      "           1       0.95      0.94      0.95      2176\n",
      "\n",
      "    accuracy                           0.95      4352\n",
      "   macro avg       0.95      0.95      0.95      4352\n",
      "weighted avg       0.95      0.95      0.95      4352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model(\"models/rhyme_model_2.hdf5\")\n",
    "\n",
    "y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "y_pred = y_pred > 0.5\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyric 1: Kan du ikke se det\n",
      "Lyric 2: Deg skal jeg lede\n",
      "Non-rhyme(0.27219998836517334)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Kaker av alle slag\n",
      "Lyric 2: Her henger Norges flagg\n",
      "Rhyme(0.6155999898910522)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Jeg har ikke tid\n",
      "Lyric 2: Til dette svineri\n",
      "Non-rhyme(0.36890000104904175)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Hva har du sagt\n",
      "Lyric 2: Kaken er bakt\n",
      "Rhyme(0.9211000204086304)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Barna er lagt\n",
      "Lyric 2: Kaken er laget\n",
      "Non-rhyme(0.0)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Gjorde du det med vilje\n",
      "Lyric 2: Kaken smaker vanilje\n",
      "Rhyme(0.9211000204086304)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Dette vokser\n",
      "Lyric 2: Satans underbukser\n",
      "Rhyme(0.9211000204086304)\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    [\"Kan du ikke se det\", \"Deg skal jeg lede\"], \n",
    "    [\"Kaker av alle slag\", \"Her henger Norges flagg\"], \n",
    "    [\"Jeg har ikke tid\", \"Til dette svineri\"],\n",
    "    [\"Hva har du sagt\", \"Kaken er bakt\"], \n",
    "    [\"Barna er lagt\", \"Kaken er laget\"],\n",
    "    [\"Gjorde du det med vilje\", \"Kaken smaker vanilje\"], \n",
    "    [\"Dette vokser\", \"Satans underbukser\"],\n",
    "]\n",
    "\n",
    "sample_tokens = [tokenize_inputs(lyrics[0], lyrics[1], tokenizer) for lyrics in samples]\n",
    "sample_tokens = tf.convert_to_tensor(sample_tokens)\n",
    "sample_pred = model.predict([sample_tokens[:, 0], sample_tokens[:, 1]])\n",
    "predictions = [round(pred[0], 4) for pred in sample_pred]\n",
    "for i in range(len(samples)):\n",
    "    print(f\"Lyric 1: {samples[i][0]}\")\n",
    "    print(f\"Lyric 2: {samples[i][1]}\")\n",
    "    print(f\"{'Rhyme' if predictions[i] > 0.5 else 'Non-rhyme'}({predictions[i]})\")\n",
    "    print(\"---------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to use whole sentences instead of just word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter, defaultdict\n",
    "# import itertools\n",
    "\n",
    "\n",
    "# seed = 420\n",
    "\n",
    "# def equal_class_numbers(scheme):\n",
    "#     c = Counter(scheme)\n",
    "#     return len(set(c.values())) == 1\n",
    "\n",
    "# df = pd.read_csv(\"../../norwegian_rhyme_scheme_corpus/annotation_tool/tsvs/tita_rhymes_poems.tsv\", sep=\"\\t\")\n",
    "# balanced_schemes_df = df.loc[df[\"rhyme scheme\"].apply(equal_class_numbers)]\n",
    "# balanced_schemes_df\n",
    "\n",
    "# positive = set()\n",
    "# negative = set()\n",
    "\n",
    "# j = 0\n",
    "\n",
    "# for e in balanced_schemes_df.itertuples():\n",
    "#     lines = e.stanza.split(\"\\n\")\n",
    "#     code = e._1\n",
    "#     d = defaultdict(set)\n",
    "#     if \"I\" in code or \"N\" in code or \"T\" in code:\n",
    "#         continue\n",
    "#     for c, line in zip(code, lines):\n",
    "#         d[c].add(line)\n",
    "        \n",
    "#     # Positive examples = all combinations within same rhyme scheme letter\n",
    "#     for s in d.values():\n",
    "#         c = itertools.combinations(s, 2)\n",
    "#         [positive.add(e) for e in c]\n",
    "    \n",
    "#     # Negative examples = all lines with one letter combined with all lines for all other letters\n",
    "#     keys = list(d.keys())\n",
    "#     for i, key in enumerate(keys):\n",
    "#         for j in range(i+1, len(keys)):\n",
    "#             key2 = keys[j]\n",
    "#             for l1 in d[key]:\n",
    "#                 for l2 in d[key2]:\n",
    "#                     negative.add((l1, l2))\n",
    "                    \n",
    "# print(len(positive), len(negative))\n",
    "\n",
    "# positive_df = pd.DataFrame(positive, columns=[\"sent_a\", \"sent_b\"])\n",
    "# negative_df = pd.DataFrame(negative, columns=[\"sent_a\", \"sent_b\"])\n",
    "\n",
    "# negative_df = negative_df.sample(n=len(positive_df), random_state=seed)\n",
    "# positive_df[\"rhyme\"] = [1]*len(positive_df)\n",
    "# negative_df[\"rhyme\"] = [0]*len(negative_df)\n",
    "\n",
    "# df = pd.concat([positive_df, negative_df])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #copy paste from above cells\n",
    "# tokenizer = Tokenizer(char_level=True, lower=True)\n",
    "# tokenizer.fit_on_texts(df['sent_a'] + df['sent_b'])\n",
    "\n",
    "# df['sent_tokens'] = df.progress_apply(\n",
    "#     lambda row: tokenize_inputs(row['sent_a'], row['sent_b'], tokenizer), axis=1\n",
    "# )\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     list(df['sent_tokens']), list(df['rhyme']), stratify=df['rhyme'], \n",
    "#     test_size=0.4, random_state=seed\n",
    "#     )\n",
    "# X_test, X_val, y_test, y_val = train_test_split(\n",
    "#     X_test, y_test, stratify=y_test, test_size=0.25, random_state=seed\n",
    "#     )\n",
    "\n",
    "# X_train = tf.convert_to_tensor(X_train)\n",
    "# y_train = tf.convert_to_tensor(y_train)\n",
    "# X_val = tf.convert_to_tensor(X_val)\n",
    "# y_val = tf.convert_to_tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = create_model()\n",
    "#                                     # changed model name\n",
    "# model_checkpoint = ModelCheckpoint(\"models/rhyme_model_3.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = TerminateOnNaN()\n",
    "# csv_logger = CSVLogger('training3.log')\n",
    "\n",
    "# history = model.fit(\n",
    "#     [X_train[:, 0], X_train[:, 1]],\n",
    "#     y_train,\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     callbacks=[model_checkpoint, terminate_on_nan, csv_logger],\n",
    "#     validation_data=([X_val[:, 0], X_val[:, 1]], y_val)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model\n",
    "# model = load_model(\"models/rhyme_model_3.hdf5\")\n",
    "\n",
    "# X_test = tf.convert_to_tensor(X_test)\n",
    "# y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "# y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "# y_pred = y_pred > 0.5\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = [\n",
    "#     [\"Kan du ikke se det?\", \"Deg skal jeg lede\"], \n",
    "#     [\"Kaker av alle slag\", \"Her henger Norges flagg\"], \n",
    "#     [\"Jeg har ikke tid\", \"Til dette svineri\"],\n",
    "#     [\"Hva har du sagt\", \"Kaken er bakt\"], \n",
    "#     [\"Barna er lagt\", \"Kaken er laget\"],\n",
    "#     [\"Er du sikker på at dette er med vilje?\", \"Hjertet ditt smaker vanilje\"], \n",
    "#     [\"Dette vokser\", \"Satans underbukser\"],\n",
    "# ]\n",
    "\n",
    "# sample_tokens = [tokenize_inputs(lyrics[0], lyrics[1], tokenizer) for lyrics in samples]\n",
    "# sample_tokens = tf.convert_to_tensor(sample_tokens)\n",
    "# sample_pred = model.predict([sample_tokens[:, 0], sample_tokens[:, 1]])\n",
    "# predictions = [round(pred[0], 4) for pred in sample_pred]\n",
    "# for i in range(len(samples)):\n",
    "#     print(f\"Lyric 1: {samples[i][0]}\")\n",
    "#     print(f\"Lyric 2: {samples[i][1]}\")\n",
    "#     print(f\"{'Rhyme' if predictions[i] > 0.5 else 'Non-rhyme'}({predictions[i]})\")\n",
    "#     print(\"---------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

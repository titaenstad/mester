{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://github.com/minoguep/rhyme_detection and https://paulminogue.com/index.php/2021/02/14/using-a-siamese-neural-network-to-create-a-simple-rhyme-detector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Subtract\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TerminateOnNaN, CSVLogger, EarlyStopping\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "MAX_LEN = 64\n",
    "SEED = 420\n",
    "# sets random, np.random and tf.random seed\n",
    "tf.keras.utils.set_random_seed(\n",
    "    SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create dataset\n",
    "We want equally many positive and negative samples of rhyme pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word_a</th>\n",
       "      <th>word_b</th>\n",
       "      <th>rhyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>stall</td>\n",
       "      <td>skrall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ving</td>\n",
       "      <td>ting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>orden</td>\n",
       "      <td>horden</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>taler</td>\n",
       "      <td>svaler</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>juleskikk</td>\n",
       "      <td>blikk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14471</th>\n",
       "      <td>637</td>\n",
       "      <td>hatt</td>\n",
       "      <td>slott</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14472</th>\n",
       "      <td>13030</td>\n",
       "      <td>mur</td>\n",
       "      <td>stund</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14473</th>\n",
       "      <td>1029</td>\n",
       "      <td>hud</td>\n",
       "      <td>mave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14474</th>\n",
       "      <td>16689</td>\n",
       "      <td>dør</td>\n",
       "      <td>sans</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14475</th>\n",
       "      <td>20954</td>\n",
       "      <td>inn</td>\n",
       "      <td>kvist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14476 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     word_a  word_b  rhyme\n",
       "0          0      stall  skrall      1\n",
       "1          1       ving    ting      1\n",
       "2          2      orden  horden      1\n",
       "3          3      taler  svaler      1\n",
       "4          4  juleskikk   blikk      1\n",
       "...      ...        ...     ...    ...\n",
       "14471    637       hatt   slott      0\n",
       "14472  13030        mur   stund      0\n",
       "14473   1029        hud    mave      0\n",
       "14474  16689        dør    sans      0\n",
       "14475  20954        inn   kvist      0\n",
       "\n",
       "[14476 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = pd.read_csv(\"positive_pairs.tsv\", sep=\"\\t\")\n",
    "full_neg = pd.read_csv(\"negative_pairs.tsv\", sep=\"\\t\")\n",
    "neg = full_neg.sample(n=len(pos), random_state=SEED)\n",
    "df = pd.concat([pos, neg])\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"tita_rhymes_poems.tsv\", sep=\"\\t\")\n",
    "\n",
    "all_text = \"\"\n",
    "for e in all_data.stanza:\n",
    "    all_text += e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create model\n",
    "Copy paste from Pauls notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_inputs(phrase_a, phrase_b, tokenizer):\n",
    "    tokenized_phrases = tokenizer.texts_to_sequences([phrase_a, phrase_b])\n",
    "\n",
    "    # now loop through inputs and pad or reduce size if required\n",
    "    tokenized_phrases_for_output = []\n",
    "    for phrase in tokenized_phrases:\n",
    "        if len(phrase) < MAX_LEN:\n",
    "            length_to_pad = MAX_LEN - len(phrase)\n",
    "            phrase_for_output = ([0] * length_to_pad) + phrase\n",
    "        elif len(phrase) > MAX_LEN:\n",
    "            phrase_for_output = phrase[-MAX_LEN:]\n",
    "        else:\n",
    "            phrase_for_output = phrase\n",
    "        tokenized_phrases_for_output.append(phrase_for_output)\n",
    "\n",
    "    return tf.constant(tokenized_phrases_for_output, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b53d21fbed48d3b80e8a59b4ca9c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14476 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(char_level=True, lower=True)\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "\n",
    "df['word_tokens'] = df.progress_apply(\n",
    "    lambda row: tokenize_inputs(row['word_a'], row['word_b'], tokenizer), axis=1\n",
    ")\n",
    "\n",
    "tokenizer_config = tokenizer.to_json()\n",
    "\n",
    "with open('tokenizer_config.json', 'w') as f:\n",
    "    f.write(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  \n",
    "    word_a_input_tokens = Input(\n",
    "      shape=(MAX_LEN, 1), name='word_a_input_tokens'\n",
    "      )\n",
    "    word_b_input_tokens = Input(\n",
    "      shape=(MAX_LEN, 1), name='word_b_input_tokens'\n",
    "      )\n",
    "    \n",
    "    # This is the siamese portion of the model \n",
    "    common_lstm = LSTM(64, return_sequences=False, activation=\"relu\", name=\"common_lstm_layer\")\n",
    "\n",
    "    word_a_lstm_output = common_lstm(word_a_input_tokens)\n",
    "    word_b_lstm_output = common_lstm(word_b_input_tokens)\n",
    "\n",
    "    #concatenate_lstm_outputs\n",
    "    concat_layer = Subtract(name=\"concatenate_lstm_outputs\")(\n",
    "      [word_a_lstm_output, word_b_lstm_output]\n",
    "      )\n",
    "    \n",
    "    # dense layers before final classification\n",
    "    dense_layers = Dense(64, activation=\"relu\", name=\"first_dense_layer\")(concat_layer)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    dense_layers = Dense(32, activation=\"relu\", name=\"second_dense_layer\")(dense_layers)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    dense_layers = Dense(8, activation=\"relu\", name=\"third_dense_layer\")(dense_layers)\n",
    "    dense_layers = Dropout(0.5)(dense_layers)\n",
    "\n",
    "    classification_layer = Dense(1, activation=\"sigmoid\", name=\"classification_layer\")(dense_layers)\n",
    "    \n",
    "    model = Model(\n",
    "      inputs=[word_a_input_tokens, word_b_input_tokens], \n",
    "      outputs = classification_layer\n",
    "      )\n",
    "\n",
    "    model.compile(\n",
    "      loss=\"binary_crossentropy\",\n",
    "      metrics=[\"accuracy\"],\n",
    "      optimizer=\"Adam\"\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indexes, X_test_indexes, y_train, y_test = train_test_split(\n",
    "    list(df.index), list(df['rhyme']), stratify=df['rhyme'], \n",
    "    test_size=0.4, random_state=SEED\n",
    "    )\n",
    "\n",
    "X_test_indexes, X_val_indexes, y_test, y_val = train_test_split(\n",
    "    X_test_indexes, y_test, stratify=y_test, \n",
    "    test_size=0.25, random_state=SEED\n",
    "    )\n",
    "\n",
    "X_train = tf.convert_to_tensor(list(df.loc[X_train_indexes][\"word_tokens\"]))\n",
    "X_val = tf.convert_to_tensor(list(df.loc[X_val_indexes][\"word_tokens\"]))\n",
    "X_test = tf.convert_to_tensor(list(df.loc[X_test_indexes][\"word_tokens\"]))\n",
    "\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_val = tf.convert_to_tensor(y_val)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Data set size: Full set: 14476\n",
      "    Train: 8685\n",
      "    Validation: 1448\n",
      "    Test: 4343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    Data set size: Full set: {len(df)}\n",
    "    Train: {len(X_train)}\n",
    "    Validation: {len(X_val)}\n",
    "    Test: {len(X_test)}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"rhyme_model1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Uncomment to train model \n",
    "\n",
    "# model = create_model()\n",
    "\n",
    "# model_checkpoint = ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = TerminateOnNaN()\n",
    "# csv_logger = CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# history = model.fit(\n",
    "#     [X_train[:, 0], X_train[:, 1]],\n",
    "#     y_train,\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     callbacks=[model_checkpoint, terminate_on_nan, csv_logger, early_stop],\n",
    "#     validation_data=([X_val[:, 0], X_val[:, 1]], y_val)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      2171\n",
      "           1       0.97      0.92      0.95      2172\n",
      "\n",
      "    accuracy                           0.95      4343\n",
      "   macro avg       0.95      0.95      0.95      4343\n",
      "weighted avg       0.95      0.95      0.95      4343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model(f\"models/{model_name}.hdf5\")\n",
    "\n",
    "y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "y_pred = y_pred > 0.5\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 64) (7, 64)\n",
      "Sentence 1: Kan du ikke se det\n",
      "Sentence 2: Deg skal jeg lede\n",
      "Non-rhyme(0.29179999232292175)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Kaker av alle slag\n",
      "Sentence 2: Her henger Norges flagg\n",
      "Rhyme(0.9817000031471252)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Jeg har ikke tid\n",
      "Sentence 2: Til dette svineri\n",
      "Non-rhyme(0.4284999966621399)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Hva har du sagt\n",
      "Sentence 2: Kaken er bakt\n",
      "Rhyme(0.9890000224113464)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Barna er lagt\n",
      "Sentence 2: Kaken er laget\n",
      "Non-rhyme(0.0006000000284984708)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Gjorde du det med vilje\n",
      "Sentence 2: Kaken smaker vanilje\n",
      "Rhyme(0.998199999332428)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Dette vokser\n",
      "Sentence 2: Satans underbukser\n",
      "Rhyme(0.998199999332428)\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    [\"Kan du ikke se det\", \"Deg skal jeg lede\"], \n",
    "    [\"Kaker av alle slag\", \"Her henger Norges flagg\"], \n",
    "    [\"Jeg har ikke tid\", \"Til dette svineri\"],\n",
    "    [\"Hva har du sagt\", \"Kaken er bakt\"], \n",
    "    [\"Barna er lagt\", \"Kaken er laget\"],\n",
    "    [\"Gjorde du det med vilje\", \"Kaken smaker vanilje\"], \n",
    "    [\"Dette vokser\", \"Satans underbukser\"],\n",
    "]\n",
    "\n",
    "sample_tokens = [tokenize_inputs(lyrics[0], lyrics[1], tokenizer) for lyrics in samples]\n",
    "sample_tokens = tf.convert_to_tensor(sample_tokens)\n",
    "\n",
    "print(sample_tokens[:, 0].shape, sample_tokens[:, 1].shape)\n",
    "\n",
    "sample_pred = model.predict([sample_tokens[:, 0], sample_tokens[:, 1]])\n",
    "predictions = [round(pred[0], 4) for pred in sample_pred]\n",
    "for i in range(len(samples)):\n",
    "    print(f\"Sentence 1: {samples[i][0]}\")\n",
    "    print(f\"Sentence 2: {samples[i][1]}\")\n",
    "    print(f\"{'Rhyme' if predictions[i] > 0.5 else 'Non-rhyme'}({predictions[i]})\")\n",
    "    print(\"---------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try again with mirrored examples included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mirrored_df(df):\n",
    "    mirror = pd.DataFrame({\"word_a\": df[\"word_b\"], \n",
    "                           \"word_b\": df[\"word_a\"], \n",
    "                           \"rhyme\": df[\"rhyme\"], \n",
    "                           \"word_tokens\":[(t[1], t[0]) for t in df[\"word_tokens\"]]})\n",
    "    return pd.concat((df, mirror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8685, 1448)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.loc[X_train_indexes]\n",
    "dev_df = df.loc[X_val_indexes]\n",
    "len(train_df), len(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word_a</th>\n",
       "      <th>word_b</th>\n",
       "      <th>rhyme</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13973</th>\n",
       "      <td>18365.0</td>\n",
       "      <td>verdien</td>\n",
       "      <td>fører</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>4141.0</td>\n",
       "      <td>slik</td>\n",
       "      <td>døden</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>4746.0</td>\n",
       "      <td>lanser</td>\n",
       "      <td>stimulanser</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>3150.0</td>\n",
       "      <td>smerte-stønn</td>\n",
       "      <td>bønn</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12056</th>\n",
       "      <td>13514.0</td>\n",
       "      <td>velte</td>\n",
       "      <td>briste</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>NaN</td>\n",
       "      <td>dynker</td>\n",
       "      <td>rynker</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hei</td>\n",
       "      <td>ei</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12693</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sloet</td>\n",
       "      <td>strand</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hud</td>\n",
       "      <td>brud</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>NaN</td>\n",
       "      <td>røs</td>\n",
       "      <td>gården</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17370 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index        word_a       word_b  rhyme  \\\n",
       "13973  18365.0       verdien        fører      0   \n",
       "9981    4141.0          slik        døden      0   \n",
       "4746    4746.0        lanser  stimulanser      1   \n",
       "3150    3150.0  smerte-stønn         bønn      1   \n",
       "12056  13514.0         velte       briste      0   \n",
       "...        ...           ...          ...    ...   \n",
       "4851       NaN        dynker       rynker      1   \n",
       "4356       NaN           hei           ei      1   \n",
       "12693      NaN         sloet       strand      0   \n",
       "4879       NaN           hud         brud      1   \n",
       "7570       NaN           røs       gården      0   \n",
       "\n",
       "                                             word_tokens  \n",
       "13973  ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "9981   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "4746   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "3150   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "12056  ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "...                                                  ...  \n",
       "4851   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "4356   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "12693  ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "4879   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "7570   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "\n",
       "[17370 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_train = get_mirrored_df(train_df)\n",
    "double_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word_a</th>\n",
       "      <th>word_b</th>\n",
       "      <th>rhyme</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>3594.0</td>\n",
       "      <td>beskytte</td>\n",
       "      <td>hytte</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>2736.0</td>\n",
       "      <td>malm</td>\n",
       "      <td>halm</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14351</th>\n",
       "      <td>19166.0</td>\n",
       "      <td>visen</td>\n",
       "      <td>ganger</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5492</th>\n",
       "      <td>5492.0</td>\n",
       "      <td>li</td>\n",
       "      <td>forbi</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>1346.0</td>\n",
       "      <td>ene</td>\n",
       "      <td>borg</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13766</th>\n",
       "      <td>NaN</td>\n",
       "      <td>landet</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>NaN</td>\n",
       "      <td>morgen</td>\n",
       "      <td>hjul</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ferdselsårer</td>\n",
       "      <td>kårer</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>NaN</td>\n",
       "      <td>finne</td>\n",
       "      <td>noensinne</td>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>frem</td>\n",
       "      <td>røk</td>\n",
       "      <td>0</td>\n",
       "      <td>((tf.Tensor(0.0, shape=(), dtype=float64), tf....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2896 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index        word_a     word_b  rhyme  \\\n",
       "3594    3594.0      beskytte      hytte      1   \n",
       "2736    2736.0          malm       halm      1   \n",
       "14351  19166.0         visen     ganger      0   \n",
       "5492    5492.0            li      forbi      1   \n",
       "9140    1346.0           ene       borg      0   \n",
       "...        ...           ...        ...    ...   \n",
       "13766      NaN        landet         en      0   \n",
       "9926       NaN        morgen       hjul      0   \n",
       "1196       NaN  ferdselsårer      kårer      1   \n",
       "6586       NaN         finne  noensinne      1   \n",
       "13290      NaN          frem        røk      0   \n",
       "\n",
       "                                             word_tokens  \n",
       "3594   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "2736   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "14351  ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "5492   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "9140   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "...                                                  ...  \n",
       "13766  ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "9926   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "1196   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "6586   ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "13290  ((tf.Tensor(0.0, shape=(), dtype=float64), tf....  \n",
       "\n",
       "[2896 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_dev = get_mirrored_df(dev_df)\n",
    "double_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(list(double_train[\"word_tokens\"]))\n",
    "X_val = tf.convert_to_tensor(list(double_dev[\"word_tokens\"]))\n",
    "\n",
    "y_train = tf.convert_to_tensor(list(double_train[\"rhyme\"]))\n",
    "y_val = tf.convert_to_tensor(list(double_dev[\"rhyme\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"rhyme_model_mirror\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "136/136 [==============================] - 8s 44ms/step - loss: 0.6717 - accuracy: 0.5553 - val_loss: 0.5675 - val_accuracy: 0.8622\n",
      "Epoch 2/100\n",
      "136/136 [==============================] - 5s 40ms/step - loss: 0.5250 - accuracy: 0.7875 - val_loss: 0.3444 - val_accuracy: 0.8854\n",
      "Epoch 3/100\n",
      "136/136 [==============================] - 5s 40ms/step - loss: 0.4022 - accuracy: 0.8272 - val_loss: 0.2755 - val_accuracy: 0.9088\n",
      "Epoch 4/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.3634 - accuracy: 0.8399 - val_loss: 0.2590 - val_accuracy: 0.9157\n",
      "Epoch 5/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.3433 - accuracy: 0.8440 - val_loss: 0.2539 - val_accuracy: 0.9178\n",
      "Epoch 6/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.3298 - accuracy: 0.8500 - val_loss: 0.2478 - val_accuracy: 0.9147\n",
      "Epoch 7/100\n",
      "136/136 [==============================] - 6s 43ms/step - loss: 0.3147 - accuracy: 0.8936 - val_loss: 0.2485 - val_accuracy: 0.9092\n",
      "Epoch 8/100\n",
      "136/136 [==============================] - 6s 43ms/step - loss: 0.3099 - accuracy: 0.8947 - val_loss: 0.2431 - val_accuracy: 0.9085\n",
      "Epoch 9/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.3008 - accuracy: 0.8923 - val_loss: 0.2422 - val_accuracy: 0.9123\n",
      "Epoch 10/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2979 - accuracy: 0.8959 - val_loss: 0.2394 - val_accuracy: 0.9147\n",
      "Epoch 11/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2930 - accuracy: 0.8986 - val_loss: 0.2394 - val_accuracy: 0.9164\n",
      "Epoch 12/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2845 - accuracy: 0.8993 - val_loss: 0.2370 - val_accuracy: 0.9106\n",
      "Epoch 13/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2818 - accuracy: 0.9008 - val_loss: 0.2307 - val_accuracy: 0.9185\n",
      "Epoch 14/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2817 - accuracy: 0.9018 - val_loss: 0.2312 - val_accuracy: 0.9178\n",
      "Epoch 15/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2820 - accuracy: 0.9017 - val_loss: 0.2315 - val_accuracy: 0.9161\n",
      "Epoch 16/100\n",
      "136/136 [==============================] - 6s 45ms/step - loss: 0.2717 - accuracy: 0.9020 - val_loss: 0.2332 - val_accuracy: 0.9095\n",
      "Epoch 17/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2686 - accuracy: 0.9047 - val_loss: 0.2209 - val_accuracy: 0.9216\n",
      "Epoch 18/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2640 - accuracy: 0.9074 - val_loss: 0.2210 - val_accuracy: 0.9233\n",
      "Epoch 19/100\n",
      "136/136 [==============================] - 6s 40ms/step - loss: 0.2554 - accuracy: 0.9075 - val_loss: 0.2358 - val_accuracy: 0.9189\n",
      "Epoch 20/100\n",
      "136/136 [==============================] - 5s 40ms/step - loss: 0.2606 - accuracy: 0.9056 - val_loss: 0.2214 - val_accuracy: 0.9220\n",
      "Epoch 21/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2555 - accuracy: 0.9087 - val_loss: 0.2181 - val_accuracy: 0.9126\n",
      "Epoch 22/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2468 - accuracy: 0.9143 - val_loss: 0.2188 - val_accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2468 - accuracy: 0.9100 - val_loss: 0.2189 - val_accuracy: 0.9230\n",
      "Epoch 24/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2503 - accuracy: 0.9092 - val_loss: 0.2180 - val_accuracy: 0.9123\n",
      "Epoch 25/100\n",
      "136/136 [==============================] - 5s 40ms/step - loss: 0.2407 - accuracy: 0.9117 - val_loss: 0.2175 - val_accuracy: 0.9192\n",
      "Epoch 26/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2459 - accuracy: 0.9134 - val_loss: 0.2124 - val_accuracy: 0.9206\n",
      "Epoch 27/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2412 - accuracy: 0.9146 - val_loss: 0.2130 - val_accuracy: 0.9258\n",
      "Epoch 28/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2331 - accuracy: 0.9166 - val_loss: 0.2119 - val_accuracy: 0.9192\n",
      "Epoch 29/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2395 - accuracy: 0.9145 - val_loss: 0.2192 - val_accuracy: 0.9144\n",
      "Epoch 30/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2325 - accuracy: 0.9170 - val_loss: 0.2139 - val_accuracy: 0.9195\n",
      "Epoch 31/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2301 - accuracy: 0.9158 - val_loss: 0.2021 - val_accuracy: 0.9244\n",
      "Epoch 32/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2267 - accuracy: 0.9183 - val_loss: 0.1995 - val_accuracy: 0.9261\n",
      "Epoch 33/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2260 - accuracy: 0.9185 - val_loss: 0.2124 - val_accuracy: 0.9151\n",
      "Epoch 34/100\n",
      "136/136 [==============================] - 6s 41ms/step - loss: 0.2262 - accuracy: 0.9179 - val_loss: 0.2149 - val_accuracy: 0.9182\n",
      "Epoch 35/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2266 - accuracy: 0.9161 - val_loss: 0.2049 - val_accuracy: 0.9265\n",
      "Epoch 36/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2223 - accuracy: 0.9196 - val_loss: 0.1939 - val_accuracy: 0.9316\n",
      "Epoch 37/100\n",
      "136/136 [==============================] - 6s 43ms/step - loss: 0.2215 - accuracy: 0.9225 - val_loss: 0.2102 - val_accuracy: 0.9168\n",
      "Epoch 38/100\n",
      "136/136 [==============================] - 6s 43ms/step - loss: 0.2150 - accuracy: 0.9223 - val_loss: 0.1992 - val_accuracy: 0.9306\n",
      "Epoch 39/100\n",
      "136/136 [==============================] - 6s 44ms/step - loss: 0.2132 - accuracy: 0.9250 - val_loss: 0.1997 - val_accuracy: 0.9306\n",
      "Epoch 40/100\n",
      "136/136 [==============================] - 6s 43ms/step - loss: 0.2117 - accuracy: 0.9241 - val_loss: 0.2008 - val_accuracy: 0.9282\n",
      "Epoch 41/100\n",
      "136/136 [==============================] - 6s 43ms/step - loss: 0.2138 - accuracy: 0.9236 - val_loss: 0.2059 - val_accuracy: 0.9240\n",
      "Epoch 42/100\n",
      "136/136 [==============================] - 6s 43ms/step - loss: 0.2160 - accuracy: 0.9208 - val_loss: 0.1985 - val_accuracy: 0.9271\n",
      "Epoch 43/100\n",
      "136/136 [==============================] - 6s 43ms/step - loss: 0.2162 - accuracy: 0.9203 - val_loss: 0.1989 - val_accuracy: 0.9354\n",
      "Epoch 44/100\n",
      "136/136 [==============================] - 6s 45ms/step - loss: 0.2091 - accuracy: 0.9230 - val_loss: 0.1979 - val_accuracy: 0.9289\n",
      "Epoch 45/100\n",
      "136/136 [==============================] - 6s 42ms/step - loss: 0.2140 - accuracy: 0.9201 - val_loss: 0.2127 - val_accuracy: 0.9199\n",
      "Epoch 46/100\n",
      "136/136 [==============================] - 7s 50ms/step - loss: 0.2128 - accuracy: 0.9212 - val_loss: 0.2036 - val_accuracy: 0.9278\n",
      "Epoch 47/100\n",
      "136/136 [==============================] - 6s 48ms/step - loss: 0.2109 - accuracy: 0.9260 - val_loss: 0.1927 - val_accuracy: 0.9278\n",
      "Epoch 48/100\n",
      "136/136 [==============================] - 7s 48ms/step - loss: 0.2114 - accuracy: 0.9227 - val_loss: 0.2001 - val_accuracy: 0.9289\n",
      "Epoch 49/100\n",
      "136/136 [==============================] - 7s 53ms/step - loss: 0.2096 - accuracy: 0.9231 - val_loss: 0.1984 - val_accuracy: 0.9330\n"
     ]
    }
   ],
   "source": [
    "# # Uncomment to train model \n",
    "# model = create_model()\n",
    "\n",
    "# model_checkpoint = ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = TerminateOnNaN()\n",
    "# csv_logger = CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# history = model.fit(\n",
    "#     [X_train[:, 0], X_train[:, 1]],\n",
    "#     y_train,\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     callbacks=[model_checkpoint, terminate_on_nan, csv_logger, early_stop],\n",
    "#     validation_data=([X_val[:, 0], X_val[:, 1]], y_val)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      2171\n",
      "           1       0.97      0.91      0.94      2172\n",
      "\n",
      "    accuracy                           0.94      4343\n",
      "   macro avg       0.94      0.94      0.94      4343\n",
      "weighted avg       0.94      0.94      0.94      4343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model(f\"models/{model_name}.hdf5\")\n",
    "\n",
    "y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "y_pred = y_pred > 0.5\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 64) (7, 64)\n",
      "Sentence 1: Kan du ikke se det\n",
      "Sentence 2: Deg skal jeg lede\n",
      "Non-rhyme(0.16769999265670776)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Kaker av alle slag\n",
      "Sentence 2: Her henger Norges flagg\n",
      "Rhyme(0.9994999766349792)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Jeg har ikke tid\n",
      "Sentence 2: Til dette svineri\n",
      "Non-rhyme(0.4575999975204468)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Hva har du sagt\n",
      "Sentence 2: Kaken er bakt\n",
      "Rhyme(0.9977999925613403)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Barna er lagt\n",
      "Sentence 2: Kaken er laget\n",
      "Non-rhyme(0.009700000286102295)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Gjorde du det med vilje\n",
      "Sentence 2: Kaken smaker vanilje\n",
      "Rhyme(0.9998000264167786)\n",
      "---------------\n",
      "\n",
      "Sentence 1: Dette vokser\n",
      "Sentence 2: Satans underbukser\n",
      "Rhyme(0.9998000264167786)\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    [\"Kan du ikke se det\", \"Deg skal jeg lede\"], \n",
    "    [\"Kaker av alle slag\", \"Her henger Norges flagg\"], \n",
    "    [\"Jeg har ikke tid\", \"Til dette svineri\"],\n",
    "    [\"Hva har du sagt\", \"Kaken er bakt\"], \n",
    "    [\"Barna er lagt\", \"Kaken er laget\"],\n",
    "    [\"Gjorde du det med vilje\", \"Kaken smaker vanilje\"], \n",
    "    [\"Dette vokser\", \"Satans underbukser\"],\n",
    "]\n",
    "\n",
    "sample_tokens = [tokenize_inputs(lyrics[0], lyrics[1], tokenizer) for lyrics in samples]\n",
    "sample_tokens = tf.convert_to_tensor(sample_tokens)\n",
    "\n",
    "print(sample_tokens[:, 0].shape, sample_tokens[:, 1].shape)\n",
    "\n",
    "sample_pred = model.predict([sample_tokens[:, 0], sample_tokens[:, 1]])\n",
    "predictions = [round(pred[0], 4) for pred in sample_pred]\n",
    "for i in range(len(samples)):\n",
    "    print(f\"Sentence 1: {samples[i][0]}\")\n",
    "    print(f\"Sentence 2: {samples[i][1]}\")\n",
    "    print(f\"{'Rhyme' if predictions[i] > 0.5 else 'Non-rhyme'}({predictions[i]})\")\n",
    "    print(\"---------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try again with different 2:3 positive to negative ratio\n",
    "Use same test and dev sets, and same tokenizer. Only expand training set.  \n",
    "Train set is already 50/50 positive and negative. We want to make it 40/60 --> increase negative examples by half of what we already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3619"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_neg = len(neg) // 2\n",
    "new_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same seed, and extract all the pairs already used + the ones we need \n",
    "negative2 = full_neg.sample(n=len(pos) + new_neg, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_a</th>\n",
       "      <th>word_b</th>\n",
       "      <th>rhyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9448</th>\n",
       "      <td>hår</td>\n",
       "      <td>blundet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15651</th>\n",
       "      <td>brenner</td>\n",
       "      <td>skatt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16533</th>\n",
       "      <td>siv</td>\n",
       "      <td>stille</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16219</th>\n",
       "      <td>verdensdommen</td>\n",
       "      <td>kronet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13700</th>\n",
       "      <td>jord</td>\n",
       "      <td>sans</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5654</th>\n",
       "      <td>sine</td>\n",
       "      <td>garn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12379</th>\n",
       "      <td>fløyt</td>\n",
       "      <td>topp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>forenes</td>\n",
       "      <td>ett</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11137</th>\n",
       "      <td>nypegren</td>\n",
       "      <td>vår</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>sider</td>\n",
       "      <td>fårene</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3619 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word_a   word_b  rhyme\n",
       "9448             hår  blundet      0\n",
       "15651        brenner    skatt      0\n",
       "16533            siv   stille      0\n",
       "16219  verdensdommen   kronet      0\n",
       "13700           jord     sans      0\n",
       "...              ...      ...    ...\n",
       "5654            sine     garn      0\n",
       "12379          fløyt     topp      0\n",
       "5668         forenes      ett      0\n",
       "11137       nypegren      vår      0\n",
       "1897           sider   fårene      0\n",
       "\n",
       "[3619 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unused_neg = negative2[len(pos):]\n",
    "unused_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ac73dd532f4865bb684aa230018c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146358/2379011568.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unused_neg['word_tokens'] = unused_neg.progress_apply(\n"
     ]
    }
   ],
   "source": [
    "# use same tokenizer as above\n",
    "unused_neg['word_tokens'] = unused_neg.progress_apply(\n",
    "    lambda row: tokenize_inputs(row['word_a'], row['word_b'], tokenizer), axis=1\n",
    ")\n",
    "\n",
    "unused_neg = get_mirrored_df(unused_neg)\n",
    "\n",
    "X_train_new = tf.convert_to_tensor(list(X_train) + list(unused_neg[\"word_tokens\"]))\n",
    "y_train_new = tf.convert_to_tensor(list(y_train) + list(unused_neg[\"rhyme\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([24608, 2, 64])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"rhyme_model_2_3_ratio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "193/193 [==============================] - 15s 64ms/step - loss: 0.5300 - accuracy: 0.6943 - val_loss: 0.5166 - val_accuracy: 0.8546\n",
      "Epoch 2/100\n",
      "193/193 [==============================] - 12s 60ms/step - loss: 0.4442 - accuracy: 0.8624 - val_loss: 0.4098 - val_accuracy: 0.9037\n",
      "Epoch 3/100\n",
      "193/193 [==============================] - 14s 71ms/step - loss: 0.3762 - accuracy: 0.8787 - val_loss: 0.3426 - val_accuracy: 0.9071\n",
      "Epoch 4/100\n",
      "193/193 [==============================] - 13s 67ms/step - loss: 0.3361 - accuracy: 0.8882 - val_loss: 0.2759 - val_accuracy: 0.9102\n",
      "Epoch 5/100\n",
      "193/193 [==============================] - 11s 59ms/step - loss: 0.3067 - accuracy: 0.8980 - val_loss: 0.2470 - val_accuracy: 0.9088\n",
      "Epoch 6/100\n",
      "193/193 [==============================] - 12s 60ms/step - loss: 0.2935 - accuracy: 0.9000 - val_loss: 0.2307 - val_accuracy: 0.9168\n",
      "Epoch 7/100\n",
      "193/193 [==============================] - 14s 73ms/step - loss: 0.2807 - accuracy: 0.9043 - val_loss: 0.2183 - val_accuracy: 0.9182\n",
      "Epoch 8/100\n",
      "193/193 [==============================] - 11s 58ms/step - loss: 0.2711 - accuracy: 0.9067 - val_loss: 0.2212 - val_accuracy: 0.9240\n",
      "Epoch 9/100\n",
      "193/193 [==============================] - 12s 61ms/step - loss: 0.2573 - accuracy: 0.9128 - val_loss: 0.1980 - val_accuracy: 0.9292\n",
      "Epoch 10/100\n",
      "193/193 [==============================] - 12s 65ms/step - loss: 0.2556 - accuracy: 0.9172 - val_loss: 0.1918 - val_accuracy: 0.9330\n",
      "Epoch 11/100\n",
      "193/193 [==============================] - 12s 64ms/step - loss: 0.2526 - accuracy: 0.9157 - val_loss: 0.1936 - val_accuracy: 0.9378\n",
      "Epoch 12/100\n",
      "193/193 [==============================] - 13s 65ms/step - loss: 0.2454 - accuracy: 0.9181 - val_loss: 0.1909 - val_accuracy: 0.9340\n",
      "Epoch 13/100\n",
      "193/193 [==============================] - 15s 78ms/step - loss: 0.2407 - accuracy: 0.9193 - val_loss: 0.1924 - val_accuracy: 0.9389\n",
      "Epoch 14/100\n",
      "193/193 [==============================] - 15s 77ms/step - loss: 0.2362 - accuracy: 0.9226 - val_loss: 0.2069 - val_accuracy: 0.9278\n",
      "Epoch 15/100\n",
      "193/193 [==============================] - 13s 69ms/step - loss: 0.2337 - accuracy: 0.9223 - val_loss: 0.1901 - val_accuracy: 0.9375\n",
      "Epoch 16/100\n",
      "193/193 [==============================] - 13s 66ms/step - loss: 0.2299 - accuracy: 0.9244 - val_loss: 0.1856 - val_accuracy: 0.9351\n",
      "Epoch 17/100\n",
      "193/193 [==============================] - 13s 69ms/step - loss: 0.2292 - accuracy: 0.9263 - val_loss: 0.1735 - val_accuracy: 0.9416\n",
      "Epoch 18/100\n",
      "193/193 [==============================] - 14s 75ms/step - loss: 0.2265 - accuracy: 0.9282 - val_loss: 0.1771 - val_accuracy: 0.9413\n",
      "Epoch 19/100\n",
      "193/193 [==============================] - 14s 74ms/step - loss: 0.2246 - accuracy: 0.9339 - val_loss: 0.1838 - val_accuracy: 0.9358\n",
      "Epoch 20/100\n",
      "193/193 [==============================] - 13s 66ms/step - loss: 0.2111 - accuracy: 0.9366 - val_loss: 0.1798 - val_accuracy: 0.9406\n",
      "Epoch 21/100\n",
      "193/193 [==============================] - 13s 69ms/step - loss: 0.2070 - accuracy: 0.9390 - val_loss: 0.1793 - val_accuracy: 0.9389\n",
      "Epoch 22/100\n",
      "193/193 [==============================] - 13s 67ms/step - loss: 0.2103 - accuracy: 0.9369 - val_loss: 0.1914 - val_accuracy: 0.9302\n",
      "Epoch 23/100\n",
      "193/193 [==============================] - 12s 64ms/step - loss: 0.2058 - accuracy: 0.9378 - val_loss: 0.1908 - val_accuracy: 0.9316\n",
      "Epoch 24/100\n",
      "193/193 [==============================] - 13s 69ms/step - loss: 0.2023 - accuracy: 0.9396 - val_loss: 0.1750 - val_accuracy: 0.9403\n",
      "Epoch 25/100\n",
      "193/193 [==============================] - 14s 70ms/step - loss: 0.2018 - accuracy: 0.9402 - val_loss: 0.1985 - val_accuracy: 0.9372\n",
      "Epoch 26/100\n",
      "193/193 [==============================] - 14s 72ms/step - loss: 0.1970 - accuracy: 0.9383 - val_loss: 0.1816 - val_accuracy: 0.9382\n",
      "Epoch 27/100\n",
      "193/193 [==============================] - 14s 70ms/step - loss: 0.1983 - accuracy: 0.9403 - val_loss: 0.1916 - val_accuracy: 0.9368\n",
      "Epoch 28/100\n",
      "193/193 [==============================] - 12s 64ms/step - loss: 0.1955 - accuracy: 0.9391 - val_loss: 0.1713 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      "193/193 [==============================] - 14s 70ms/step - loss: 0.1917 - accuracy: 0.9406 - val_loss: 0.1720 - val_accuracy: 0.9441\n",
      "Epoch 30/100\n",
      "193/193 [==============================] - 14s 72ms/step - loss: 0.1957 - accuracy: 0.9418 - val_loss: 0.1745 - val_accuracy: 0.9441\n",
      "Epoch 31/100\n",
      "193/193 [==============================] - 14s 71ms/step - loss: 0.1903 - accuracy: 0.9423 - val_loss: 0.1722 - val_accuracy: 0.9468\n",
      "Epoch 32/100\n",
      "193/193 [==============================] - 13s 66ms/step - loss: 0.1905 - accuracy: 0.9412 - val_loss: 0.1829 - val_accuracy: 0.9372\n",
      "Epoch 33/100\n",
      "193/193 [==============================] - 13s 69ms/step - loss: 0.1908 - accuracy: 0.9412 - val_loss: 0.1817 - val_accuracy: 0.9434\n",
      "Epoch 34/100\n",
      "193/193 [==============================] - 13s 67ms/step - loss: 0.1880 - accuracy: 0.9428 - val_loss: 0.1715 - val_accuracy: 0.9482\n",
      "Epoch 35/100\n",
      "193/193 [==============================] - 14s 75ms/step - loss: 0.1865 - accuracy: 0.9437 - val_loss: 0.1758 - val_accuracy: 0.9410\n",
      "Epoch 36/100\n",
      "193/193 [==============================] - 14s 72ms/step - loss: 0.1902 - accuracy: 0.9430 - val_loss: 0.1714 - val_accuracy: 0.9499\n",
      "Epoch 37/100\n",
      "193/193 [==============================] - 14s 73ms/step - loss: 0.1826 - accuracy: 0.9441 - val_loss: 0.1862 - val_accuracy: 0.9396\n",
      "Epoch 38/100\n",
      "193/193 [==============================] - 13s 70ms/step - loss: 0.1820 - accuracy: 0.9444 - val_loss: 0.1830 - val_accuracy: 0.9437\n",
      "Epoch 39/100\n",
      "193/193 [==============================] - 14s 71ms/step - loss: 0.1824 - accuracy: 0.9454 - val_loss: 0.1906 - val_accuracy: 0.9468\n",
      "Epoch 40/100\n",
      "193/193 [==============================] - 14s 72ms/step - loss: 0.1789 - accuracy: 0.9464 - val_loss: 0.1743 - val_accuracy: 0.9468\n",
      "Epoch 41/100\n",
      "193/193 [==============================] - 13s 66ms/step - loss: 0.1794 - accuracy: 0.9461 - val_loss: 0.1920 - val_accuracy: 0.9420\n",
      "Epoch 42/100\n",
      "193/193 [==============================] - 13s 67ms/step - loss: 0.1780 - accuracy: 0.9455 - val_loss: 0.1815 - val_accuracy: 0.9510\n",
      "Epoch 43/100\n",
      "193/193 [==============================] - 12s 63ms/step - loss: 0.1825 - accuracy: 0.9461 - val_loss: 0.1627 - val_accuracy: 0.9496\n",
      "Epoch 44/100\n",
      "193/193 [==============================] - 13s 66ms/step - loss: 0.1753 - accuracy: 0.9470 - val_loss: 0.1694 - val_accuracy: 0.9523\n",
      "Epoch 45/100\n",
      "193/193 [==============================] - 14s 71ms/step - loss: 0.1785 - accuracy: 0.9480 - val_loss: 0.1782 - val_accuracy: 0.9496\n",
      "Epoch 46/100\n",
      "193/193 [==============================] - 12s 61ms/step - loss: 0.1771 - accuracy: 0.9481 - val_loss: 0.1810 - val_accuracy: 0.9506\n",
      "Epoch 47/100\n",
      "193/193 [==============================] - 14s 70ms/step - loss: 0.1752 - accuracy: 0.9472 - val_loss: 0.1891 - val_accuracy: 0.9448\n",
      "Epoch 48/100\n",
      "193/193 [==============================] - 12s 63ms/step - loss: 0.1751 - accuracy: 0.9477 - val_loss: 0.1609 - val_accuracy: 0.9510\n",
      "Epoch 49/100\n",
      "193/193 [==============================] - 12s 63ms/step - loss: 0.1773 - accuracy: 0.9463 - val_loss: 0.1586 - val_accuracy: 0.9541\n",
      "Epoch 50/100\n",
      "193/193 [==============================] - 13s 68ms/step - loss: 0.1712 - accuracy: 0.9490 - val_loss: 0.1721 - val_accuracy: 0.9541\n",
      "Epoch 51/100\n",
      "193/193 [==============================] - 12s 63ms/step - loss: 0.1744 - accuracy: 0.9486 - val_loss: 0.1736 - val_accuracy: 0.9537\n",
      "Epoch 52/100\n",
      "193/193 [==============================] - 13s 65ms/step - loss: 0.1645 - accuracy: 0.9499 - val_loss: 0.1715 - val_accuracy: 0.9544\n",
      "Epoch 53/100\n",
      "193/193 [==============================] - 12s 64ms/step - loss: 0.1674 - accuracy: 0.9505 - val_loss: 0.1572 - val_accuracy: 0.9541\n",
      "Epoch 54/100\n",
      "193/193 [==============================] - 13s 67ms/step - loss: 0.1646 - accuracy: 0.9507 - val_loss: 0.1778 - val_accuracy: 0.9541\n",
      "Epoch 55/100\n",
      "193/193 [==============================] - 14s 72ms/step - loss: 0.1642 - accuracy: 0.9512 - val_loss: 0.1706 - val_accuracy: 0.9506\n",
      "Epoch 56/100\n",
      "193/193 [==============================] - 13s 68ms/step - loss: 0.1644 - accuracy: 0.9509 - val_loss: 0.1830 - val_accuracy: 0.9558\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 13s 66ms/step - loss: 0.1659 - accuracy: 0.9494 - val_loss: 0.1511 - val_accuracy: 0.9582\n",
      "Epoch 58/100\n",
      "193/193 [==============================] - 13s 65ms/step - loss: 0.1629 - accuracy: 0.9506 - val_loss: 0.1708 - val_accuracy: 0.9510\n",
      "Epoch 59/100\n",
      "193/193 [==============================] - 14s 72ms/step - loss: 0.1621 - accuracy: 0.9506 - val_loss: 0.1718 - val_accuracy: 0.9555\n",
      "Epoch 60/100\n",
      "193/193 [==============================] - 14s 72ms/step - loss: 0.1593 - accuracy: 0.9527 - val_loss: 0.1838 - val_accuracy: 0.9506\n",
      "Epoch 61/100\n",
      "193/193 [==============================] - 14s 74ms/step - loss: 0.1589 - accuracy: 0.9517 - val_loss: 0.1702 - val_accuracy: 0.9572\n",
      "Epoch 62/100\n",
      "193/193 [==============================] - 13s 67ms/step - loss: 0.1584 - accuracy: 0.9522 - val_loss: 0.1830 - val_accuracy: 0.9520\n",
      "Epoch 63/100\n",
      "193/193 [==============================] - 12s 63ms/step - loss: 0.1550 - accuracy: 0.9524 - val_loss: 0.1948 - val_accuracy: 0.9517\n",
      "Epoch 64/100\n",
      "193/193 [==============================] - 12s 64ms/step - loss: 0.1611 - accuracy: 0.9516 - val_loss: 0.1974 - val_accuracy: 0.9499\n",
      "Epoch 65/100\n",
      "193/193 [==============================] - 12s 63ms/step - loss: 0.1521 - accuracy: 0.9564 - val_loss: 0.1722 - val_accuracy: 0.9527\n",
      "Epoch 66/100\n",
      "193/193 [==============================] - 14s 71ms/step - loss: 0.1551 - accuracy: 0.9532 - val_loss: 0.1825 - val_accuracy: 0.9555\n",
      "Epoch 67/100\n",
      "193/193 [==============================] - 13s 68ms/step - loss: 0.1555 - accuracy: 0.9542 - val_loss: 0.1713 - val_accuracy: 0.9579\n",
      "Epoch 68/100\n",
      "193/193 [==============================] - 14s 70ms/step - loss: 0.1550 - accuracy: 0.9550 - val_loss: 0.1750 - val_accuracy: 0.9572\n",
      "Epoch 69/100\n",
      "193/193 [==============================] - 13s 66ms/step - loss: 0.1455 - accuracy: 0.9559 - val_loss: 0.1707 - val_accuracy: 0.9561\n",
      "Epoch 70/100\n",
      "193/193 [==============================] - 13s 70ms/step - loss: 0.1514 - accuracy: 0.9567 - val_loss: 0.1741 - val_accuracy: 0.9534\n",
      "Epoch 71/100\n",
      "193/193 [==============================] - 14s 71ms/step - loss: 0.1529 - accuracy: 0.9553 - val_loss: 0.1798 - val_accuracy: 0.9575\n",
      "Epoch 72/100\n",
      "193/193 [==============================] - 13s 69ms/step - loss: 0.1477 - accuracy: 0.9561 - val_loss: 0.1709 - val_accuracy: 0.9548\n",
      "Epoch 73/100\n",
      "193/193 [==============================] - 13s 68ms/step - loss: 0.1418 - accuracy: 0.9572 - val_loss: 0.2049 - val_accuracy: 0.9479\n",
      "Epoch 74/100\n",
      "193/193 [==============================] - 12s 64ms/step - loss: 0.1483 - accuracy: 0.9544 - val_loss: 0.1834 - val_accuracy: 0.9551\n",
      "Epoch 75/100\n",
      "193/193 [==============================] - 13s 66ms/step - loss: 0.1436 - accuracy: 0.9567 - val_loss: 0.1701 - val_accuracy: 0.9523\n",
      "Epoch 76/100\n",
      "193/193 [==============================] - 12s 65ms/step - loss: 0.1460 - accuracy: 0.9546 - val_loss: 0.2122 - val_accuracy: 0.9451\n",
      "Epoch 77/100\n",
      "193/193 [==============================] - 14s 72ms/step - loss: 0.1454 - accuracy: 0.9567 - val_loss: 0.1751 - val_accuracy: 0.9568\n",
      "Epoch 78/100\n",
      "193/193 [==============================] - 14s 71ms/step - loss: 0.1430 - accuracy: 0.9574 - val_loss: 0.1913 - val_accuracy: 0.9579\n"
     ]
    }
   ],
   "source": [
    "# # Uncomment to train model\n",
    "# model = create_model()\n",
    "\n",
    "# model_checkpoint = ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = TerminateOnNaN()\n",
    "# csv_logger = CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# history = model.fit(\n",
    "#     [X_train_new[:, 0], X_train_new[:, 1]],\n",
    "#     y_train_new,\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     callbacks=[model_checkpoint, terminate_on_nan, csv_logger, early_stop],\n",
    "#     validation_data=([X_val[:, 0], X_val[:, 1]], y_val)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      2171\n",
      "           1       0.97      0.94      0.96      2172\n",
      "\n",
      "    accuracy                           0.96      4343\n",
      "   macro avg       0.96      0.96      0.96      4343\n",
      "weighted avg       0.96      0.96      0.96      4343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model(f\"models/{model_name}.hdf5\")\n",
    "\n",
    "y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "y_pred = y_pred > 0.5\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyric 1: Kan du ikke se det\n",
      "Lyric 2: Deg skal jeg lede\n",
      "Non-rhyme(0.46810001134872437)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Kaker av alle slag\n",
      "Lyric 2: Her henger Norges flagg\n",
      "Rhyme(0.9807000160217285)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Jeg har ikke tid\n",
      "Lyric 2: Til dette svineri\n",
      "Rhyme(0.941100001335144)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Hva har du sagt\n",
      "Lyric 2: Kaken er bakt\n",
      "Rhyme(0.9742000102996826)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Barna er lagt\n",
      "Lyric 2: Kaken er laget\n",
      "Non-rhyme(0.0)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Gjorde du det med vilje\n",
      "Lyric 2: Kaken smaker vanilje\n",
      "Rhyme(0.983299970626831)\n",
      "---------------\n",
      "\n",
      "Lyric 1: Dette vokser\n",
      "Lyric 2: Satans underbukser\n",
      "Rhyme(0.983299970626831)\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    [\"Kan du ikke se det\", \"Deg skal jeg lede\"], \n",
    "    [\"Kaker av alle slag\", \"Her henger Norges flagg\"], \n",
    "    [\"Jeg har ikke tid\", \"Til dette svineri\"],\n",
    "    [\"Hva har du sagt\", \"Kaken er bakt\"], \n",
    "    [\"Barna er lagt\", \"Kaken er laget\"],\n",
    "    [\"Gjorde du det med vilje\", \"Kaken smaker vanilje\"], \n",
    "    [\"Dette vokser\", \"Satans underbukser\"],\n",
    "]\n",
    "\n",
    "sample_tokens = [tokenize_inputs(lyrics[0], lyrics[1], tokenizer) for lyrics in samples]\n",
    "sample_tokens = tf.convert_to_tensor(sample_tokens)\n",
    "sample_pred = model.predict([sample_tokens[:, 0], sample_tokens[:, 1]])\n",
    "predictions = [round(pred[0], 4) for pred in sample_pred]\n",
    "for i in range(len(samples)):\n",
    "    print(f\"Lyric 1: {samples[i][0]}\")\n",
    "    print(f\"Lyric 2: {samples[i][1]}\")\n",
    "    print(f\"{'Rhyme' if predictions[i] > 0.5 else 'Non-rhyme'}({predictions[i]})\")\n",
    "    print(\"---------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use all rhyme pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unused_neg_2 = neg.sample(n=len(neg), random_state=SEED)[len(negative2):]\n",
    "\n",
    "# # use same tokenizer as above\n",
    "# unused_neg_2['word_tokens'] = unused_neg_2.progress_apply(\n",
    "#     lambda row: tokenize_inputs(row['word_a'], row['word_b'], tokenizer), axis=1\n",
    "# )\n",
    "\n",
    "# unused_neg_2 = get_mirrored_df(unused_neg_2)\n",
    "\n",
    "# X_train_new = tf.convert_to_tensor(list(X_train_new) + list(unused_neg_2[\"word_tokens\"]))\n",
    "# y_train_new = tf.convert_to_tensor(list(y_train_new) + list(unused_neg_2[\"rhyme\"]))\n",
    "# X_train_new.shape\n",
    "\n",
    "# model_name = \"rhyme_model_all_pairs\"\n",
    "\n",
    "# # # Uncomment to train model\n",
    "# # model = create_model()\n",
    "\n",
    "# # model_checkpoint = ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# # terminate_on_nan = TerminateOnNaN()\n",
    "# # csv_logger = CSVLogger(f'logs/training_{model_name}.log')\n",
    "# # early_stop = EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# # history = model.fit(\n",
    "# #     [X_train_new[:, 0], X_train_new[:, 1]],\n",
    "# #     y_train_new,\n",
    "# #     batch_size=128,\n",
    "# #     epochs=100,\n",
    "# #     callbacks=[model_checkpoint, terminate_on_nan, csv_logger, early_stop],\n",
    "# #     validation_data=([X_val[:, 0], X_val[:, 1]], y_val)\n",
    "# # )\n",
    "\n",
    "# # load the model\n",
    "# model = load_model(f\"models/{model_name}.hdf5\")\n",
    "\n",
    "# y_pred = model.predict([X_test[:, 0], X_test[:, 1]])\n",
    "# y_pred = y_pred > 0.5\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0acaf0ea",
   "metadata": {},
   "source": [
    "Goal: create a model that on input <word> spits out a bucket of words that rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ae44c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 23:37:21.692662: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-05 23:37:21.692687: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import random\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "SEED = 420\n",
    "\n",
    "tf.keras.utils.set_random_seed(\n",
    "    SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c104eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = len(\"minoritetsladningsbærerdiffusjonskoeffisientmålingsapparatur\")\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0ccc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/good_buckets.pickle\", \"rb\") as f:\n",
    "    good_buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d7bbb8",
   "metadata": {},
   "source": [
    "# Sanity-check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec02625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"rhyme_gen_sanity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639e1499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = [list(b)[:2] for b in good_buckets[:10]]\n",
    "len(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78da55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52486a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_vocab_size = len(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e0b9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_indexer = {w:i for i,b in enumerate(buckets) for w in b}\n",
    "# with open(f\"pickles/{model_name}_bucket_indexer.pickle\", \"wb+\") as f:\n",
    "#     pickle.dump(bucket_indexer, f)\n",
    "\n",
    "with open(f\"pickles/{model_name}_bucket_indexer.pickle\", \"rb\") as f:\n",
    "    bucket_indexer = pickle.load(f)\n",
    "# bucket_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "124eb5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(bucket_indexer.keys())\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2b3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True, lower=True)\n",
    "# char_tokenizer.fit_on_texts(vocab)\n",
    "\n",
    "# tokenizer_config = char_tokenizer.to_json()\n",
    "# with open(f\"{model_name}_char_tokenizer_config.json\", 'w') as f:\n",
    "#     f.write(tokenizer_config)\n",
    "\n",
    "with open(f\"{model_name}_char_tokenizer_config.json\") as f:\n",
    "    tokenizer_config = f.read()\n",
    "\n",
    "char_tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce3b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buckets_to_data(words, char_tokenizer, bucket_indexer):\n",
    "    x = char_tokenizer.texts_to_sequences(words)    \n",
    "    x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=MAX_LEN, padding=\"post\", value=0) \n",
    "    \n",
    "    no_of_buckets = len(set(bucket_indexer.values()))\n",
    "    y = np.zeros((len(words), no_of_buckets))\n",
    "    for i, w in enumerate(words):\n",
    "        y[i][bucket_indexer[w]] = 1\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def X_to_words(X, char_tokenizer):\n",
    "    words = [\"\".join(word.split()) for word in char_tokenizer.sequences_to_texts(X)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5161df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = buckets_to_data(vocab, char_tokenizer, bucket_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95300c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 60), (20, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29673bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 23:37:23.483584: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-05 23:37:23.483606: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-05 23:37:23.483622: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tita-laptop): /proc/driver/nvidia/version does not exist\n",
      "2022-05-05 23:37:23.483793: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# # Uncomment to train\n",
    "# model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Embedding(input_dim=MAX_LEN, output_dim=128, mask_zero=True),\n",
    "#             tf.keras.layers.LSTM(units=128),\n",
    "#             tf.keras.layers.Dense(bucket_vocab_size, activation=\"softmax\"),\n",
    "#         ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "# csv_logger = tf.keras.callbacks.CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# history = model.fit(X, y,\n",
    "#           batch_size=1,\n",
    "#           epochs=30,\n",
    "#           callbacks=[model_checkpoint, terminate_on_nan, early_stop, csv_logger])\n",
    "\n",
    "model = tf.keras.models.load_model(f\"models/{model_name}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96394545",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X)\n",
    "X_words = char_tokenizer.sequences_to_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a97c3ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marmortrinn\n",
      "Predicted to rhyme with bucket 0:\n",
      "['søndenvind', 'ditinn'] \n",
      "\n",
      "ditinn\n",
      "Predicted to rhyme with bucket 0:\n",
      "['søndenvind', 'ditinn'] \n",
      "\n",
      "trang\n",
      "Predicted to rhyme with bucket 1:\n",
      "['svang', 'tonetrang'] \n",
      "\n",
      "vingefang\n",
      "Predicted to rhyme with bucket 1:\n",
      "['svang', 'tonetrang'] \n",
      "\n",
      "vinter-natt\n",
      "Predicted to rhyme with bucket 2:\n",
      "['tatt', 'natt'] \n",
      "\n",
      "betatt\n",
      "Predicted to rhyme with bucket 2:\n",
      "['tatt', 'natt'] \n",
      "\n",
      "spill\n",
      "Predicted to rhyme with bucket 3:\n",
      "['vil', 'bil'] \n",
      "\n",
      "kil\n",
      "Predicted to rhyme with bucket 3:\n",
      "['vil', 'bil'] \n",
      "\n",
      "munn\n",
      "Predicted to rhyme with bucket 4:\n",
      "['bunn', 'funn'] \n",
      "\n",
      "blomstergrunn\n",
      "Predicted to rhyme with bucket 4:\n",
      "['bunn', 'funn'] \n",
      "\n",
      "spott\n",
      "Predicted to rhyme with bucket 5:\n",
      "['stått', 'brott'] \n",
      "\n",
      "slått\n",
      "Predicted to rhyme with bucket 5:\n",
      "['stått', 'brott'] \n",
      "\n",
      "spy\n",
      "Predicted to rhyme with bucket 6:\n",
      "['fly', 'hedningeby'] \n",
      "\n",
      "krigerby\n",
      "Predicted to rhyme with bucket 6:\n",
      "['fly', 'hedningeby'] \n",
      "\n",
      "solskinnsglans\n",
      "Predicted to rhyme with bucket 7:\n",
      "['Sanktehans', 'seierskrans'] \n",
      "\n",
      "vanns\n",
      "Predicted to rhyme with bucket 7:\n",
      "['Sanktehans', 'seierskrans'] \n",
      "\n",
      "milevidt\n",
      "Predicted to rhyme with bucket 8:\n",
      "['granitt', 'milevidt'] \n",
      "\n",
      "kreditt\n",
      "Predicted to rhyme with bucket 8:\n",
      "['granitt', 'milevidt'] \n",
      "\n",
      "sjal\n",
      "Predicted to rhyme with bucket 9:\n",
      "['pral', 'gal'] \n",
      "\n",
      "kanal\n",
      "Predicted to rhyme with bucket 9:\n",
      "['pral', 'gal'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w, p in zip(X_words, preds):\n",
    "    print(\"\".join(w.split()))\n",
    "    i = np.argmax(p)\n",
    "    print(f\"Predicted to rhyme with bucket {i}:\")\n",
    "    print(buckets[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a01827",
   "metadata": {},
   "source": [
    "## Successfully overfitted on training data ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10c1bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_more = [\"flang\", \"gorlang\", \"blatt\", \"knatt\", \"pril\", \n",
    "             \"glunn\", \"svans\", \"stritt\", \"hjal\", \"sta\", \"plirk\", \"coll\"]\n",
    "\n",
    "for w in some_more:\n",
    "    if w in vocab:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "048f0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_some_more = char_tokenizer.texts_to_sequences(some_more)\n",
    "test_some_more =  tf.keras.preprocessing.sequence.pad_sequences(test_some_more, maxlen=MAX_LEN, padding=\"post\", value=0) \n",
    "more_preds = model.predict(test_some_more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "766123f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: flang\n",
      "['svang', 'tonetrang']\n",
      "\n",
      "Word: gorlang\n",
      "['pral', 'gal']\n",
      "\n",
      "Word: blatt\n",
      "['stått', 'brott']\n",
      "\n",
      "Word: knatt\n",
      "['tatt', 'natt']\n",
      "\n",
      "Word: pril\n",
      "['vil', 'bil']\n",
      "\n",
      "Word: glunn\n",
      "['bunn', 'funn']\n",
      "\n",
      "Word: svans\n",
      "['Sanktehans', 'seierskrans']\n",
      "\n",
      "Word: stritt\n",
      "['tatt', 'natt']\n",
      "\n",
      "Word: hjal\n",
      "['pral', 'gal']\n",
      "\n",
      "Word: sta\n",
      "['stått', 'brott']\n",
      "\n",
      "Word: plirk\n",
      "['vil', 'bil']\n",
      "\n",
      "Word: coll\n",
      "['vil', 'bil']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w, p in zip(some_more, more_preds):\n",
    "    print(f\"Word: {w}\")\n",
    "    i = np.argmax(p)\n",
    "    print(buckets[i][:5])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327347e",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8cfaace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_vowel(char):\n",
    "    return char in ['e', 'a', 'i', 'o', 'u', 'å', 'ø', 'y', 'æ', 'é', 'ö', 'ä', 'á', 'à']\n",
    "\n",
    "def last_letters(word):\n",
    "    for i in range(len(word)-1, -1, -1):\n",
    "        if is_vowel(word[i]):\n",
    "            break\n",
    "    return word[i:]\n",
    "\n",
    "def words_rhyme(word_a, word_b):\n",
    "    return last_letters(word_a) == last_letters(word_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f3735f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_bucket(word, buckets):\n",
    "    for i, b in enumerate(buckets):\n",
    "        word2 = b[0]\n",
    "        if words_rhyme(word, word2):\n",
    "            return i\n",
    "    return random.choice(range(len(buckets)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc4597",
   "metadata": {},
   "source": [
    "## NoRSC v1 annotations manual graph clustering buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b612729",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/manual_repair_buckets.pickle\", \"rb\") as f:\n",
    "    manual_buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f22596ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = good_buckets + manual_buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169cc527",
   "metadata": {},
   "source": [
    "### Looking at the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ecc1209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 8.083892617449665\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = [len(b) for b in buckets]\n",
    "c = Counter(l)\n",
    "l2 = sorted(c.items(), key=lambda x: x[0])\n",
    "words, counts = zip(*l2)\n",
    "print(np.median(l), np.mean(l))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,5))\n",
    "\n",
    "ax.bar(x=words, height=counts, color=\"green\")\n",
    "ax.set_xticks(words)\n",
    "ax.set_ylabel('Number of buckets')\n",
    "ax.set_xlabel('Number of words in bucket')\n",
    "\n",
    "plt.savefig(\"figs/words_buckets_norsc.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08dbab2",
   "metadata": {},
   "source": [
    "# Use all classes \n",
    "Ensure one example from each bucket of the small ones, separate the rest with the given ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d7cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_name = \"good+manual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f6d3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_indexer = {w:i for i,b in enumerate(buckets) for w in b}\n",
    "# with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"wb+\") as f:\n",
    "#     pickle.dump(bucket_indexer, f)\n",
    "\n",
    "with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"rb\") as f:\n",
    "    bucket_indexer = pickle.load(f)\n",
    "\n",
    "bucket_vocab_size = len(set(bucket_indexer.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4d8f642",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4818"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(bucket_indexer.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ea7edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True, lower=True)\n",
    "# char_tokenizer.fit_on_texts(vocab)\n",
    "\n",
    "# tokenizer_config = char_tokenizer.to_json()\n",
    "# with open(f\"{buckets_name}_char_tokenizer_config.json\", 'w') as f:\n",
    "#     f.write(tokenizer_config)\n",
    "\n",
    "with open(f\"{buckets_name}_char_tokenizer_config.json\") as f:\n",
    "    tokenizer_config = f.read()\n",
    "\n",
    "char_tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e3a5dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 322)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smol = [list(b) for b in buckets if len(b) < 5]\n",
    "big = [list(b) for b in buckets if len(b) >= 5]\n",
    "\n",
    "len(smol), len(big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c0f987a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 3889)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smol_voc = [w for b in smol for w in b]\n",
    "big_voc = [w for b in big for w in b]\n",
    "\n",
    "len(smol_voc), len(big_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ed6e627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_s, y_s = buckets_to_data(smol_voc, char_tokenizer, bucket_indexer)\n",
    "X_b, y_b = buckets_to_data(big_voc, char_tokenizer, bucket_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1e61ef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((929, 60), (929, 596))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_s.shape, y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1931e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3889, 60), (3889, 596))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b.shape, y_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3685cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way there is at least 1 example per class in each of train, dev, test\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_s, y_s, test_size=0.6, stratify=y_s, random_state=SEED)\n",
    "X_dev_s, X_test_s, y_dev_s, y_test_s = train_test_split(X_test_s, y_test_s, test_size=0.5, stratify=y_test_s, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79d994d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set test size to 0.4 so there is at least one example from each class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y_b, test_size=0.4, stratify=y_b, random_state=SEED)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c0e14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, X_train_s))\n",
    "X_dev = np.concatenate((X_dev, X_dev_s))\n",
    "X_test = np.concatenate((X_test, X_test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79a3d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_train, y_train_s))\n",
    "y_dev = np.concatenate((y_dev, y_dev_s))\n",
    "y_test = np.concatenate((y_test, y_test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55c178bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2704, 60), (1057, 60), (1057, 60))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_dev.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56c84797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2704, 596), (1057, 596), (1057, 596))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_dev.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92975374",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"rhyme_gen_add_smol_b\"\n",
    "\n",
    "# # Uncomment to train\n",
    "# model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Embedding(input_dim=MAX_LEN, output_dim=128, mask_zero=True),\n",
    "#             tf.keras.layers.LSTM(units=128),\n",
    "#             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(bucket_vocab_size, activation=\"softmax\"),\n",
    "#         ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "# csv_logger = tf.keras.callbacks.CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=100,\n",
    "#                     validation_data = (X_dev, y_dev),\n",
    "#                     callbacks=[model_checkpoint, terminate_on_nan, early_stop, csv_logger])\n",
    "\n",
    "model = tf.keras.models.load_model(f\"models/{model_name}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc93dcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1057, 596), (1057, 596))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "y_test.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd83bd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1057,), (1057,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.argmax(preds, axis=1)\n",
    "y_t = np.argmax(y_test, axis=1)\n",
    "p.shape, y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cac06aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "279 of 596 buckets are missing from predictions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{len(set(y_t) - set(p))} of {len(set(y_t))} buckets are missing from predictions. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0545c428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.30      0.40        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.54      0.88      0.67         8\n",
      "           3       0.67      0.25      0.36         8\n",
      "           4       0.35      1.00      0.52         7\n",
      "           5       0.50      0.71      0.59         7\n",
      "           6       0.75      1.00      0.86         6\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.33      0.20      0.25         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       0.71      1.00      0.83         5\n",
      "          11       0.27      0.80      0.40         5\n",
      "          12       0.67      1.00      0.80         4\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       0.25      0.20      0.22         5\n",
      "          15       0.33      0.25      0.29         4\n",
      "          16       0.50      1.00      0.67         4\n",
      "          17       1.00      0.60      0.75         5\n",
      "          18       0.71      1.00      0.83         5\n",
      "          19       0.75      0.75      0.75         4\n",
      "          20       0.80      1.00      0.89         4\n",
      "          21       1.00      0.67      0.80         3\n",
      "          22       0.40      1.00      0.57         4\n",
      "          23       0.60      1.00      0.75         3\n",
      "          24       0.33      0.25      0.29         4\n",
      "          25       0.67      0.67      0.67         3\n",
      "          26       0.00      0.00      0.00         3\n",
      "          27       0.27      1.00      0.43         3\n",
      "          28       0.50      1.00      0.67         3\n",
      "          29       0.50      0.67      0.57         3\n",
      "          30       0.43      1.00      0.60         3\n",
      "          31       0.50      1.00      0.67         4\n",
      "          32       0.60      1.00      0.75         3\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       0.67      0.67      0.67         3\n",
      "          36       0.67      0.67      0.67         3\n",
      "          37       0.60      1.00      0.75         3\n",
      "          38       0.33      0.67      0.44         3\n",
      "          39       0.67      0.67      0.67         3\n",
      "          40       1.00      0.67      0.80         3\n",
      "          41       0.75      1.00      0.86         3\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.75      1.00      0.86         3\n",
      "          44       1.00      0.67      0.80         3\n",
      "          45       0.50      1.00      0.67         3\n",
      "          46       0.33      1.00      0.50         2\n",
      "          47       0.50      0.50      0.50         2\n",
      "          48       0.67      1.00      0.80         2\n",
      "          49       0.75      1.00      0.86         3\n",
      "          50       0.50      0.67      0.57         3\n",
      "          51       0.50      1.00      0.67         2\n",
      "          52       0.50      0.67      0.57         3\n",
      "          53       0.50      1.00      0.67         3\n",
      "          54       0.67      1.00      0.80         2\n",
      "          55       0.60      1.00      0.75         3\n",
      "          56       0.00      0.00      0.00         3\n",
      "          57       0.60      1.00      0.75         3\n",
      "          58       0.60      1.00      0.75         3\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       1.00      0.50      0.67         2\n",
      "          62       0.29      1.00      0.44         2\n",
      "          63       0.50      1.00      0.67         2\n",
      "          64       0.50      1.00      0.67         2\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.67      1.00      0.80         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.67      1.00      0.80         2\n",
      "          71       0.67      1.00      0.80         2\n",
      "          72       0.50      1.00      0.67         2\n",
      "          73       0.40      1.00      0.57         2\n",
      "          74       1.00      1.00      1.00         2\n",
      "          75       0.67      1.00      0.80         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       0.00      0.00      0.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       0.67      1.00      0.80         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       0.50      0.50      0.50         2\n",
      "          84       0.40      1.00      0.57         2\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       0.40      1.00      0.57         2\n",
      "          87       0.50      1.00      0.67         2\n",
      "          88       0.00      0.00      0.00         2\n",
      "          89       0.67      1.00      0.80         2\n",
      "          90       0.67      1.00      0.80         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       0.20      0.50      0.29         2\n",
      "          93       0.50      1.00      0.67         2\n",
      "          94       1.00      0.50      0.67         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       0.40      1.00      0.57         2\n",
      "          97       0.40      1.00      0.57         2\n",
      "          98       1.00      1.00      1.00         2\n",
      "          99       1.00      0.50      0.67         2\n",
      "         100       0.67      1.00      0.80         2\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.50      1.00      0.67         2\n",
      "         104       1.00      1.00      1.00         2\n",
      "         105       0.33      1.00      0.50         1\n",
      "         106       0.00      0.00      0.00         2\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.25      1.00      0.40         1\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       1.00      1.00      1.00         1\n",
      "         111       0.29      1.00      0.44         2\n",
      "         112       0.00      0.00      0.00         2\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.29      1.00      0.44         2\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.20      1.00      0.33         1\n",
      "         117       1.00      1.00      1.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       1.00      1.00      1.00         1\n",
      "         123       1.00      0.50      0.67         2\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       1.00      1.00      1.00         1\n",
      "         126       0.50      1.00      0.67         1\n",
      "         127       0.33      1.00      0.50         2\n",
      "         128       0.00      0.00      0.00         2\n",
      "         129       0.33      1.00      0.50         1\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         2\n",
      "         132       0.67      1.00      0.80         2\n",
      "         133       1.00      0.50      0.67         2\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.67      1.00      0.80         2\n",
      "         136       1.00      1.00      1.00         2\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       1.00      1.00      1.00         1\n",
      "         139       0.67      1.00      0.80         2\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.50      1.00      0.67         2\n",
      "         143       0.50      1.00      0.67         1\n",
      "         144       0.40      1.00      0.57         2\n",
      "         145       0.33      1.00      0.50         1\n",
      "         146       0.50      1.00      0.67         1\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.50      1.00      0.67         2\n",
      "         150       0.00      0.00      0.00         2\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.67      1.00      0.80         2\n",
      "         153       0.67      1.00      0.80         2\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.50      1.00      0.67         1\n",
      "         156       0.50      1.00      0.67         1\n",
      "         157       0.33      1.00      0.50         1\n",
      "         158       0.20      1.00      0.33         1\n",
      "         159       1.00      1.00      1.00         1\n",
      "         160       0.25      1.00      0.40         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       0.25      1.00      0.40         1\n",
      "         165       1.00      1.00      1.00         1\n",
      "         166       0.00      0.00      0.00         1\n",
      "         167       0.00      0.00      0.00         1\n",
      "         168       0.50      1.00      0.67         1\n",
      "         169       0.50      1.00      0.67         1\n",
      "         170       0.50      1.00      0.67         1\n",
      "         171       0.50      1.00      0.67         1\n",
      "         172       0.50      1.00      0.67         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       0.50      1.00      0.67         1\n",
      "         175       0.25      1.00      0.40         1\n",
      "         176       1.00      1.00      1.00         1\n",
      "         177       0.50      1.00      0.67         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       1.00      1.00      1.00         1\n",
      "         181       0.17      1.00      0.29         1\n",
      "         182       0.50      1.00      0.67         1\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       0.50      1.00      0.67         1\n",
      "         185       0.00      0.00      0.00         1\n",
      "         186       0.14      1.00      0.25         1\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       0.50      1.00      0.67         1\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       1.00      1.00      1.00         1\n",
      "         192       1.00      1.00      1.00         1\n",
      "         193       0.09      1.00      0.17         1\n",
      "         194       0.25      1.00      0.40         1\n",
      "         195       0.50      1.00      0.67         1\n",
      "         196       0.00      0.00      0.00         1\n",
      "         197       0.00      0.00      0.00         1\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       1.00      1.00      1.00         1\n",
      "         200       1.00      1.00      1.00         1\n",
      "         201       0.00      0.00      0.00         1\n",
      "         202       0.50      1.00      0.67         1\n",
      "         203       0.50      1.00      0.67         1\n",
      "         204       0.50      1.00      0.67         1\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       1.00      1.00      1.00         1\n",
      "         208       1.00      1.00      1.00         1\n",
      "         209       0.50      1.00      0.67         1\n",
      "         210       0.50      1.00      0.67         1\n",
      "         211       0.00      0.00      0.00         1\n",
      "         212       1.00      1.00      1.00         1\n",
      "         213       0.50      1.00      0.67         1\n",
      "         214       0.50      1.00      0.67         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       0.33      1.00      0.50         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       1.00      1.00      1.00         1\n",
      "         220       0.50      1.00      0.67         1\n",
      "         221       0.00      0.00      0.00         1\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       0.00      0.00      0.00         1\n",
      "         225       1.00      1.00      1.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.33      1.00      0.50         1\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         1\n",
      "         231       0.00      0.00      0.00         1\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.00      0.00      0.00         1\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.50      1.00      0.67         1\n",
      "         237       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         1\n",
      "         240       1.00      1.00      1.00         1\n",
      "         241       1.00      1.00      1.00         2\n",
      "         242       0.33      1.00      0.50         1\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       0.50      1.00      0.67         1\n",
      "         246       0.50      1.00      0.67         1\n",
      "         247       0.00      0.00      0.00         1\n",
      "         248       0.00      0.00      0.00         1\n",
      "         249       0.00      0.00      0.00         1\n",
      "         250       1.00      1.00      1.00         1\n",
      "         251       0.00      0.00      0.00         1\n",
      "         252       0.00      0.00      0.00         1\n",
      "         253       0.50      1.00      0.67         1\n",
      "         254       0.00      0.00      0.00         1\n",
      "         255       0.00      0.00      0.00         1\n",
      "         256       0.00      0.00      0.00         1\n",
      "         257       1.00      1.00      1.00         1\n",
      "         258       0.00      0.00      0.00         1\n",
      "         259       0.00      0.00      0.00         1\n",
      "         260       1.00      1.00      1.00         1\n",
      "         261       0.00      0.00      0.00         1\n",
      "         262       1.00      1.00      1.00         1\n",
      "         263       0.00      0.00      0.00         1\n",
      "         264       1.00      1.00      1.00         1\n",
      "         265       1.00      1.00      1.00         1\n",
      "         266       1.00      1.00      1.00         1\n",
      "         267       1.00      1.00      1.00         1\n",
      "         268       0.50      1.00      0.67         1\n",
      "         269       0.50      1.00      0.67         1\n",
      "         270       0.00      0.00      0.00         1\n",
      "         271       0.00      0.00      0.00         1\n",
      "         272       0.00      0.00      0.00         1\n",
      "         273       0.00      0.00      0.00         1\n",
      "         274       0.00      0.00      0.00         2\n",
      "         275       0.00      0.00      0.00         1\n",
      "         276       0.00      0.00      0.00         1\n",
      "         277       0.00      0.00      0.00         1\n",
      "         278       0.50      1.00      0.67         1\n",
      "         279       1.00      1.00      1.00         1\n",
      "         280       0.00      0.00      0.00         1\n",
      "         281       1.00      1.00      1.00         1\n",
      "         282       1.00      1.00      1.00         1\n",
      "         283       0.00      0.00      0.00         1\n",
      "         284       1.00      1.00      1.00         1\n",
      "         285       0.00      0.00      0.00         1\n",
      "         286       0.33      1.00      0.50         1\n",
      "         287       1.00      1.00      1.00         1\n",
      "         288       0.00      0.00      0.00         1\n",
      "         289       0.00      0.00      0.00         2\n",
      "         290       0.00      0.00      0.00         1\n",
      "         291       0.00      0.00      0.00         1\n",
      "         292       0.00      0.00      0.00         1\n",
      "         293       0.00      0.00      0.00         1\n",
      "         294       0.00      0.00      0.00         1\n",
      "         295       1.00      1.00      1.00         1\n",
      "         296       0.50      1.00      0.67         1\n",
      "         297       0.00      0.00      0.00         1\n",
      "         298       1.00      1.00      1.00         1\n",
      "         299       0.25      1.00      0.40         1\n",
      "         300       0.00      0.00      0.00         1\n",
      "         301       1.00      1.00      1.00         1\n",
      "         302       0.00      0.00      0.00         1\n",
      "         303       1.00      1.00      1.00         1\n",
      "         304       0.00      0.00      0.00         1\n",
      "         305       1.00      1.00      1.00         1\n",
      "         306       0.00      0.00      0.00         1\n",
      "         307       0.00      0.00      0.00         1\n",
      "         308       0.00      0.00      0.00         1\n",
      "         309       0.00      0.00      0.00         1\n",
      "         310       0.00      0.00      0.00         1\n",
      "         311       0.00      0.00      0.00         1\n",
      "         312       0.00      0.00      0.00         1\n",
      "         313       0.00      0.00      0.00         1\n",
      "         314       0.00      0.00      0.00         1\n",
      "         315       0.00      0.00      0.00         2\n",
      "         316       0.00      0.00      0.00         1\n",
      "         317       0.00      0.00      0.00         1\n",
      "         318       0.00      0.00      0.00         1\n",
      "         319       1.00      1.00      1.00         1\n",
      "         320       0.00      0.00      0.00         1\n",
      "         321       0.00      0.00      0.00         1\n",
      "         322       0.50      1.00      0.67         1\n",
      "         323       1.00      1.00      1.00         1\n",
      "         324       0.00      0.00      0.00         1\n",
      "         325       0.00      0.00      0.00         1\n",
      "         326       0.00      0.00      0.00         1\n",
      "         327       0.00      0.00      0.00         1\n",
      "         328       0.00      0.00      0.00         1\n",
      "         329       0.00      0.00      0.00         1\n",
      "         330       1.00      1.00      1.00         1\n",
      "         331       0.00      0.00      0.00         1\n",
      "         332       0.00      0.00      0.00         1\n",
      "         333       0.00      0.00      0.00         1\n",
      "         334       0.00      0.00      0.00         1\n",
      "         335       0.00      0.00      0.00         1\n",
      "         336       0.00      0.00      0.00         2\n",
      "         337       0.00      0.00      0.00         1\n",
      "         338       0.00      0.00      0.00         1\n",
      "         339       0.00      0.00      0.00         1\n",
      "         340       0.00      0.00      0.00         1\n",
      "         341       0.00      0.00      0.00         1\n",
      "         342       0.00      0.00      0.00         1\n",
      "         343       0.00      0.00      0.00         1\n",
      "         344       0.00      0.00      0.00         1\n",
      "         345       0.00      0.00      0.00         1\n",
      "         346       0.50      1.00      0.67         1\n",
      "         347       0.00      0.00      0.00         1\n",
      "         348       0.00      0.00      0.00         1\n",
      "         349       0.00      0.00      0.00         1\n",
      "         350       0.00      0.00      0.00         1\n",
      "         351       0.00      0.00      0.00         1\n",
      "         352       0.00      0.00      0.00         1\n",
      "         353       0.00      0.00      0.00         1\n",
      "         354       0.00      0.00      0.00         1\n",
      "         355       0.00      0.00      0.00         1\n",
      "         356       0.00      0.00      0.00         1\n",
      "         357       0.00      0.00      0.00         1\n",
      "         358       0.00      0.00      0.00         1\n",
      "         359       0.00      0.00      0.00         1\n",
      "         360       0.00      0.00      0.00         1\n",
      "         361       1.00      1.00      1.00         1\n",
      "         362       0.00      0.00      0.00         1\n",
      "         363       1.00      1.00      1.00         1\n",
      "         364       0.00      0.00      0.00         1\n",
      "         365       0.00      0.00      0.00         1\n",
      "         366       0.00      0.00      0.00         1\n",
      "         367       0.50      1.00      0.67         1\n",
      "         368       0.00      0.00      0.00         1\n",
      "         369       0.00      0.00      0.00         1\n",
      "         370       0.00      0.00      0.00         1\n",
      "         371       0.00      0.00      0.00         1\n",
      "         372       0.00      0.00      0.00         1\n",
      "         373       0.00      0.00      0.00         1\n",
      "         374       0.00      0.00      0.00         1\n",
      "         375       0.00      0.00      0.00         1\n",
      "         376       1.00      1.00      1.00         1\n",
      "         377       0.00      0.00      0.00         1\n",
      "         378       0.00      0.00      0.00         1\n",
      "         379       0.00      0.00      0.00         1\n",
      "         380       0.00      0.00      0.00         1\n",
      "         381       1.00      1.00      1.00         1\n",
      "         382       0.00      0.00      0.00         1\n",
      "         383       0.00      0.00      0.00         1\n",
      "         384       0.00      0.00      0.00         1\n",
      "         385       0.00      0.00      0.00         1\n",
      "         386       0.00      0.00      0.00         1\n",
      "         387       0.00      0.00      0.00         1\n",
      "         388       0.00      0.00      0.00         1\n",
      "         389       1.00      1.00      1.00         1\n",
      "         390       0.00      0.00      0.00         1\n",
      "         391       0.00      0.00      0.00         1\n",
      "         392       0.00      0.00      0.00         1\n",
      "         393       0.00      0.00      0.00         1\n",
      "         394       0.00      0.00      0.00         1\n",
      "         395       0.00      0.00      0.00         1\n",
      "         396       0.00      0.00      0.00         1\n",
      "         397       0.00      0.00      0.00         1\n",
      "         398       0.00      0.00      0.00         1\n",
      "         399       0.00      0.00      0.00         1\n",
      "         400       1.00      1.00      1.00         1\n",
      "         401       0.00      0.00      0.00         1\n",
      "         402       0.00      0.00      0.00         1\n",
      "         403       0.00      0.00      0.00         1\n",
      "         404       0.00      0.00      0.00         1\n",
      "         405       0.50      1.00      0.67         1\n",
      "         406       0.00      0.00      0.00         1\n",
      "         407       0.00      0.00      0.00         1\n",
      "         408       0.00      0.00      0.00         1\n",
      "         409       0.00      0.00      0.00         1\n",
      "         410       0.00      0.00      0.00         1\n",
      "         411       0.00      0.00      0.00         1\n",
      "         412       0.00      0.00      0.00         1\n",
      "         413       0.00      0.00      0.00         1\n",
      "         414       1.00      1.00      1.00         1\n",
      "         415       1.00      1.00      1.00         1\n",
      "         416       1.00      1.00      1.00         1\n",
      "         417       0.00      0.00      0.00         1\n",
      "         418       0.00      0.00      0.00         1\n",
      "         419       0.00      0.00      0.00         1\n",
      "         420       0.00      0.00      0.00         1\n",
      "         421       0.00      0.00      0.00         1\n",
      "         422       0.00      0.00      0.00         1\n",
      "         423       0.00      0.00      0.00         1\n",
      "         424       0.00      0.00      0.00         1\n",
      "         425       0.00      0.00      0.00         1\n",
      "         426       0.00      0.00      0.00         1\n",
      "         427       0.00      0.00      0.00         1\n",
      "         428       0.00      0.00      0.00         1\n",
      "         429       1.00      1.00      1.00         1\n",
      "         430       0.00      0.00      0.00         1\n",
      "         431       0.00      0.00      0.00         1\n",
      "         432       1.00      1.00      1.00         1\n",
      "         433       0.00      0.00      0.00         1\n",
      "         434       0.00      0.00      0.00         1\n",
      "         435       0.00      0.00      0.00         1\n",
      "         436       0.00      0.00      0.00         1\n",
      "         437       0.00      0.00      0.00         1\n",
      "         438       0.00      0.00      0.00         1\n",
      "         439       0.00      0.00      0.00         1\n",
      "         440       0.00      0.00      0.00         1\n",
      "         441       1.00      1.00      1.00         1\n",
      "         442       0.00      0.00      0.00         1\n",
      "         443       1.00      1.00      1.00         1\n",
      "         444       0.00      0.00      0.00         1\n",
      "         445       0.00      0.00      0.00         1\n",
      "         446       1.00      1.00      1.00         1\n",
      "         447       0.00      0.00      0.00         1\n",
      "         448       0.00      0.00      0.00         1\n",
      "         449       0.00      0.00      0.00         1\n",
      "         450       0.00      0.00      0.00         1\n",
      "         451       0.00      0.00      0.00         1\n",
      "         452       0.00      0.00      0.00         1\n",
      "         453       0.00      0.00      0.00         1\n",
      "         454       0.00      0.00      0.00         1\n",
      "         455       0.00      0.00      0.00         1\n",
      "         456       0.00      0.00      0.00         1\n",
      "         457       0.00      0.00      0.00         1\n",
      "         458       0.00      0.00      0.00         1\n",
      "         459       0.00      0.00      0.00         1\n",
      "         460       0.00      0.00      0.00         1\n",
      "         461       0.00      0.00      0.00         1\n",
      "         462       0.00      0.00      0.00         1\n",
      "         463       0.00      0.00      0.00         1\n",
      "         464       0.00      0.00      0.00         1\n",
      "         465       0.00      0.00      0.00         1\n",
      "         466       0.00      0.00      0.00         1\n",
      "         467       0.00      0.00      0.00         1\n",
      "         468       0.00      0.00      0.00         1\n",
      "         469       0.00      0.00      0.00         1\n",
      "         470       0.00      0.00      0.00         1\n",
      "         471       0.00      0.00      0.00         1\n",
      "         472       0.00      0.00      0.00         1\n",
      "         473       0.00      0.00      0.00         1\n",
      "         474       0.00      0.00      0.00         1\n",
      "         475       0.00      0.00      0.00         1\n",
      "         476       0.00      0.00      0.00         1\n",
      "         477       0.00      0.00      0.00         1\n",
      "         478       0.00      0.00      0.00         1\n",
      "         479       0.00      0.00      0.00         1\n",
      "         480       1.00      1.00      1.00         1\n",
      "         481       0.00      0.00      0.00         1\n",
      "         482       0.00      0.00      0.00         1\n",
      "         483       0.00      0.00      0.00         1\n",
      "         484       0.00      0.00      0.00         1\n",
      "         485       0.00      0.00      0.00         1\n",
      "         486       0.00      0.00      0.00         1\n",
      "         487       1.00      1.00      1.00         1\n",
      "         488       0.00      0.00      0.00         1\n",
      "         489       0.00      0.00      0.00         1\n",
      "         490       0.00      0.00      0.00         1\n",
      "         491       0.00      0.00      0.00         1\n",
      "         492       0.00      0.00      0.00         1\n",
      "         493       0.00      0.00      0.00         1\n",
      "         494       1.00      1.00      1.00         1\n",
      "         495       0.00      0.00      0.00         1\n",
      "         496       0.00      0.00      0.00         1\n",
      "         497       1.00      1.00      1.00         1\n",
      "         498       0.00      0.00      0.00         1\n",
      "         499       0.00      0.00      0.00         1\n",
      "         500       0.00      0.00      0.00         1\n",
      "         501       0.00      0.00      0.00         1\n",
      "         502       0.25      1.00      0.40         1\n",
      "         503       0.00      0.00      0.00         1\n",
      "         504       0.00      0.00      0.00         1\n",
      "         505       0.00      0.00      0.00         2\n",
      "         506       0.25      1.00      0.40         1\n",
      "         507       1.00      1.00      1.00         2\n",
      "         508       1.00      1.00      1.00         1\n",
      "         509       0.60      1.00      0.75         3\n",
      "         510       0.50      1.00      0.67         1\n",
      "         511       0.00      0.00      0.00         1\n",
      "         512       0.50      1.00      0.67         1\n",
      "         513       1.00      1.00      1.00         1\n",
      "         514       1.00      1.00      1.00         2\n",
      "         515       0.00      0.00      0.00         1\n",
      "         516       0.00      0.00      0.00         2\n",
      "         517       0.40      1.00      0.57         2\n",
      "         518       0.00      0.00      0.00         2\n",
      "         519       1.00      1.00      1.00         2\n",
      "         520       0.40      1.00      0.57         2\n",
      "         521       0.00      0.00      0.00         2\n",
      "         522       1.00      1.00      1.00         2\n",
      "         523       0.60      1.00      0.75         3\n",
      "         524       0.00      0.00      0.00         2\n",
      "         525       0.40      1.00      0.57         2\n",
      "         526       0.50      0.67      0.57         3\n",
      "         527       0.00      0.00      0.00         3\n",
      "         528       0.50      0.33      0.40         3\n",
      "         529       0.33      1.00      0.50         1\n",
      "         530       0.50      1.00      0.67         4\n",
      "         531       1.00      0.50      0.67         4\n",
      "         532       0.00      0.00      0.00         1\n",
      "         533       0.80      1.00      0.89         4\n",
      "         534       0.40      1.00      0.57         2\n",
      "         535       1.00      1.00      1.00         2\n",
      "         536       0.00      0.00      0.00         1\n",
      "         537       1.00      1.00      1.00         3\n",
      "         538       0.62      1.00      0.77         5\n",
      "         539       0.62      1.00      0.77         5\n",
      "         540       0.60      1.00      0.75         3\n",
      "         541       1.00      1.00      1.00         2\n",
      "         542       1.00      0.20      0.33         5\n",
      "         543       0.67      1.00      0.80         2\n",
      "         544       0.00      0.00      0.00         2\n",
      "         545       0.82      1.00      0.90         9\n",
      "         546       0.50      1.00      0.67         2\n",
      "         547       0.83      1.00      0.91         5\n",
      "         548       0.67      0.80      0.73         5\n",
      "         549       0.75      1.00      0.86         3\n",
      "         550       0.00      0.00      0.00         1\n",
      "         551       0.60      0.50      0.55         6\n",
      "         552       1.00      0.67      0.80         3\n",
      "         553       1.00      0.50      0.67         2\n",
      "         554       0.00      0.00      0.00         1\n",
      "         555       0.00      0.00      0.00         1\n",
      "         556       0.40      1.00      0.57         2\n",
      "         557       1.00      0.67      0.80         9\n",
      "         558       1.00      1.00      1.00         1\n",
      "         559       1.00      1.00      1.00         8\n",
      "         560       0.56      0.71      0.63         7\n",
      "         561       0.75      1.00      0.86         3\n",
      "         562       0.80      0.80      0.80         5\n",
      "         563       1.00      1.00      1.00         9\n",
      "         564       1.00      0.75      0.86         8\n",
      "         565       0.00      0.00      0.00         1\n",
      "         566       0.00      0.00      0.00         4\n",
      "         567       0.00      0.00      0.00         1\n",
      "         568       1.00      1.00      1.00         1\n",
      "         569       1.00      1.00      1.00         1\n",
      "         570       0.33      0.75      0.46         4\n",
      "         571       1.00      1.00      1.00         2\n",
      "         572       0.87      1.00      0.93        13\n",
      "         573       1.00      1.00      1.00         2\n",
      "         574       0.83      0.71      0.77         7\n",
      "         575       0.50      1.00      0.67         1\n",
      "         576       0.62      0.89      0.73         9\n",
      "         577       1.00      0.90      0.95        10\n",
      "         578       0.60      1.00      0.75         3\n",
      "         579       0.50      1.00      0.67         2\n",
      "         580       1.00      1.00      1.00         4\n",
      "         581       1.00      1.00      1.00         1\n",
      "         582       0.60      0.75      0.67         4\n",
      "         583       0.00      0.00      0.00         2\n",
      "         584       0.00      0.00      0.00         1\n",
      "         585       0.00      0.00      0.00         3\n",
      "         586       0.50      1.00      0.67         1\n",
      "         587       1.00      1.00      1.00         2\n",
      "         588       0.77      1.00      0.87        10\n",
      "         589       0.91      0.83      0.87        12\n",
      "         590       1.00      1.00      1.00         3\n",
      "         591       0.70      0.78      0.74         9\n",
      "         592       0.40      1.00      0.57         2\n",
      "         593       0.80      0.80      0.80         5\n",
      "         594       0.00      0.00      0.00         1\n",
      "         595       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.60      1057\n",
      "   macro avg       0.36      0.47      0.39      1057\n",
      "weighted avg       0.49      0.60      0.52      1057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "r = classification_report(y_true=y_t, y_pred=p)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ef9f4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.80      0.50      0.62         8\n",
      "           3       0.67      0.50      0.57         8\n",
      "           4       1.00      0.43      0.60         7\n",
      "           5       1.00      0.43      0.60         7\n",
      "           6       0.75      1.00      0.86         6\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.80      0.80      0.80         5\n",
      "           9       0.71      1.00      0.83         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       0.02      1.00      0.05         5\n",
      "          12       0.02      1.00      0.04         4\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       1.00      0.60      0.75         5\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       0.00      0.00      0.00         5\n",
      "          18       0.00      0.00      0.00         5\n",
      "          19       1.00      1.00      1.00         4\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         4\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       0.75      1.00      0.86         3\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       0.03      1.00      0.07         3\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       0.05      1.00      0.10         3\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       1.00      0.67      0.80         3\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       1.00      1.00      1.00         3\n",
      "          46       0.67      1.00      0.80         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         3\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       0.43      1.00      0.60         3\n",
      "          53       0.00      0.00      0.00         3\n",
      "          54       1.00      0.50      0.67         2\n",
      "          55       0.00      0.00      0.00         3\n",
      "          56       1.00      0.67      0.80         3\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.00      0.00      0.00         3\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       0.67      1.00      0.80         2\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       0.00      0.00      0.00         2\n",
      "          90       0.00      0.00      0.00         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         2\n",
      "          99       1.00      0.50      0.67         2\n",
      "         100       0.67      1.00      0.80         2\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         2\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         2\n",
      "         107       1.00      1.00      1.00         1\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         2\n",
      "         112       0.00      0.00      0.00         2\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         2\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       1.00      1.00      1.00         2\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       0.00      0.00      0.00         1\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         2\n",
      "         128       0.00      0.00      0.00         2\n",
      "         129       0.00      0.00      0.00         1\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       1.00      1.00      1.00         2\n",
      "         132       0.12      1.00      0.21         2\n",
      "         133       0.00      0.00      0.00         2\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.40      1.00      0.57         2\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         2\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         2\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         2\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.67      1.00      0.80         2\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         2\n",
      "         153       0.67      1.00      0.80         2\n",
      "         154       1.00      1.00      1.00         1\n",
      "         155       0.50      1.00      0.67         1\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         1\n",
      "         159       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         1\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       1.00      1.00      1.00         1\n",
      "         167       0.00      0.00      0.00         1\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.17      1.00      0.29         1\n",
      "         170       1.00      1.00      1.00         1\n",
      "         171       0.50      1.00      0.67         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       1.00      1.00      1.00         1\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       1.00      1.00      1.00         1\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         1\n",
      "         181       0.00      0.00      0.00         1\n",
      "         182       1.00      1.00      1.00         1\n",
      "         183       0.00      0.00      0.00         1\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         1\n",
      "         186       0.00      0.00      0.00         1\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       0.00      0.00      0.00         1\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         1\n",
      "         192       0.50      1.00      0.67         1\n",
      "         193       0.00      0.00      0.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       1.00      1.00      1.00         1\n",
      "         196       0.00      0.00      0.00         1\n",
      "         197       1.00      1.00      1.00         1\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         1\n",
      "         200       0.00      0.00      0.00         1\n",
      "         201       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         1\n",
      "         204       1.00      1.00      1.00         1\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         1\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00         1\n",
      "         211       0.00      0.00      0.00         1\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       0.00      0.00      0.00         1\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       0.50      1.00      0.67         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       1.00      1.00      1.00         1\n",
      "         220       0.50      1.00      0.67         1\n",
      "         221       1.00      1.00      1.00         1\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       1.00      1.00      1.00         1\n",
      "         225       1.00      1.00      1.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         1\n",
      "         231       1.00      1.00      1.00         1\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.00      0.00      0.00         1\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       1.00      1.00      1.00         1\n",
      "         237       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         1\n",
      "         240       0.00      0.00      0.00         1\n",
      "         241       1.00      1.00      1.00         2\n",
      "         242       0.00      0.00      0.00         1\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       0.00      0.00      0.00         1\n",
      "         246       0.00      0.00      0.00         1\n",
      "         247       0.00      0.00      0.00         1\n",
      "         248       0.00      0.00      0.00         1\n",
      "         249       0.00      0.00      0.00         1\n",
      "         250       0.00      0.00      0.00         1\n",
      "         251       1.00      1.00      1.00         1\n",
      "         252       0.00      0.00      0.00         1\n",
      "         253       0.00      0.00      0.00         1\n",
      "         254       0.00      0.00      0.00         1\n",
      "         255       1.00      1.00      1.00         1\n",
      "         256       0.00      0.00      0.00         1\n",
      "         257       0.00      0.00      0.00         1\n",
      "         258       0.00      0.00      0.00         1\n",
      "         259       0.00      0.00      0.00         1\n",
      "         260       1.00      1.00      1.00         1\n",
      "         261       0.00      0.00      0.00         1\n",
      "         262       0.00      0.00      0.00         1\n",
      "         263       0.00      0.00      0.00         1\n",
      "         264       0.00      0.00      0.00         1\n",
      "         265       0.00      0.00      0.00         1\n",
      "         266       1.00      1.00      1.00         1\n",
      "         267       0.00      0.00      0.00         1\n",
      "         268       0.00      0.00      0.00         1\n",
      "         269       0.00      0.00      0.00         1\n",
      "         270       0.00      0.00      0.00         1\n",
      "         271       0.00      0.00      0.00         1\n",
      "         272       0.00      0.00      0.00         1\n",
      "         273       0.00      0.00      0.00         1\n",
      "         274       0.00      0.00      0.00         2\n",
      "         275       1.00      1.00      1.00         1\n",
      "         276       0.00      0.00      0.00         1\n",
      "         277       1.00      1.00      1.00         1\n",
      "         278       0.00      0.00      0.00         1\n",
      "         279       0.50      1.00      0.67         1\n",
      "         280       0.00      0.00      0.00         1\n",
      "         281       0.00      0.00      0.00         1\n",
      "         282       0.00      0.00      0.00         1\n",
      "         283       0.00      0.00      0.00         1\n",
      "         284       0.00      0.00      0.00         1\n",
      "         285       0.00      0.00      0.00         1\n",
      "         286       0.00      0.00      0.00         1\n",
      "         287       0.00      0.00      0.00         1\n",
      "         288       1.00      1.00      1.00         1\n",
      "         289       0.00      0.00      0.00         2\n",
      "         290       0.00      0.00      0.00         1\n",
      "         291       0.00      0.00      0.00         1\n",
      "         292       0.00      0.00      0.00         1\n",
      "         293       0.00      0.00      0.00         1\n",
      "         294       0.00      0.00      0.00         1\n",
      "         295       0.50      1.00      0.67         1\n",
      "         296       0.00      0.00      0.00         1\n",
      "         297       0.00      0.00      0.00         1\n",
      "         298       0.00      0.00      0.00         1\n",
      "         299       0.00      0.00      0.00         1\n",
      "         300       0.00      0.00      0.00         1\n",
      "         301       0.00      0.00      0.00         1\n",
      "         302       0.00      0.00      0.00         1\n",
      "         303       0.00      0.00      0.00         1\n",
      "         304       0.00      0.00      0.00         1\n",
      "         305       0.00      0.00      0.00         1\n",
      "         306       0.00      0.00      0.00         1\n",
      "         307       0.00      0.00      0.00         1\n",
      "         308       0.00      0.00      0.00         1\n",
      "         309       0.00      0.00      0.00         1\n",
      "         310       0.00      0.00      0.00         1\n",
      "         311       0.00      0.00      0.00         1\n",
      "         312       0.00      0.00      0.00         1\n",
      "         313       0.00      0.00      0.00         1\n",
      "         314       0.00      0.00      0.00         1\n",
      "         315       0.00      0.00      0.00         2\n",
      "         316       0.00      0.00      0.00         1\n",
      "         317       1.00      1.00      1.00         1\n",
      "         318       0.00      0.00      0.00         1\n",
      "         319       0.00      0.00      0.00         1\n",
      "         320       0.00      0.00      0.00         1\n",
      "         321       1.00      1.00      1.00         1\n",
      "         322       0.00      0.00      0.00         1\n",
      "         323       0.00      0.00      0.00         1\n",
      "         324       0.00      0.00      0.00         1\n",
      "         325       0.00      0.00      0.00         1\n",
      "         326       0.00      0.00      0.00         1\n",
      "         327       0.00      0.00      0.00         1\n",
      "         328       1.00      1.00      1.00         1\n",
      "         329       0.00      0.00      0.00         1\n",
      "         330       0.00      0.00      0.00         1\n",
      "         331       0.00      0.00      0.00         1\n",
      "         332       0.00      0.00      0.00         1\n",
      "         333       0.00      0.00      0.00         1\n",
      "         334       0.00      0.00      0.00         1\n",
      "         335       0.00      0.00      0.00         1\n",
      "         336       0.00      0.00      0.00         2\n",
      "         337       0.08      1.00      0.14         1\n",
      "         338       0.00      0.00      0.00         1\n",
      "         339       0.00      0.00      0.00         1\n",
      "         340       0.00      0.00      0.00         1\n",
      "         341       0.00      0.00      0.00         1\n",
      "         342       0.00      0.00      0.00         1\n",
      "         343       1.00      1.00      1.00         1\n",
      "         344       0.33      1.00      0.50         1\n",
      "         345       0.00      0.00      0.00         1\n",
      "         346       1.00      1.00      1.00         1\n",
      "         347       1.00      1.00      1.00         1\n",
      "         348       0.00      0.00      0.00         1\n",
      "         349       1.00      1.00      1.00         1\n",
      "         350       0.00      0.00      0.00         1\n",
      "         351       0.00      0.00      0.00         1\n",
      "         352       1.00      1.00      1.00         1\n",
      "         353       0.00      0.00      0.00         1\n",
      "         354       0.00      0.00      0.00         1\n",
      "         355       1.00      1.00      1.00         1\n",
      "         356       0.00      0.00      0.00         1\n",
      "         357       0.00      0.00      0.00         1\n",
      "         358       0.00      0.00      0.00         1\n",
      "         359       0.00      0.00      0.00         1\n",
      "         360       1.00      1.00      1.00         1\n",
      "         361       0.00      0.00      0.00         1\n",
      "         362       0.00      0.00      0.00         1\n",
      "         363       0.00      0.00      0.00         1\n",
      "         364       0.00      0.00      0.00         1\n",
      "         365       0.00      0.00      0.00         1\n",
      "         366       1.00      1.00      1.00         1\n",
      "         367       1.00      1.00      1.00         1\n",
      "         368       0.00      0.00      0.00         1\n",
      "         369       0.00      0.00      0.00         1\n",
      "         370       0.00      0.00      0.00         1\n",
      "         371       0.00      0.00      0.00         1\n",
      "         372       0.00      0.00      0.00         1\n",
      "         373       0.00      0.00      0.00         1\n",
      "         374       0.00      0.00      0.00         1\n",
      "         375       0.00      0.00      0.00         1\n",
      "         376       0.00      0.00      0.00         1\n",
      "         377       0.00      0.00      0.00         1\n",
      "         378       0.00      0.00      0.00         1\n",
      "         379       1.00      1.00      1.00         1\n",
      "         380       0.00      0.00      0.00         1\n",
      "         381       0.00      0.00      0.00         1\n",
      "         382       0.00      0.00      0.00         1\n",
      "         383       0.00      0.00      0.00         1\n",
      "         384       0.00      0.00      0.00         1\n",
      "         385       0.00      0.00      0.00         1\n",
      "         386       0.00      0.00      0.00         1\n",
      "         387       0.00      0.00      0.00         1\n",
      "         388       0.00      0.00      0.00         1\n",
      "         389       1.00      1.00      1.00         1\n",
      "         390       1.00      1.00      1.00         1\n",
      "         391       0.00      0.00      0.00         1\n",
      "         392       0.17      1.00      0.29         1\n",
      "         393       0.00      0.00      0.00         1\n",
      "         394       0.33      1.00      0.50         1\n",
      "         395       0.00      0.00      0.00         1\n",
      "         396       0.14      1.00      0.25         1\n",
      "         397       0.00      0.00      0.00         1\n",
      "         398       0.00      0.00      0.00         1\n",
      "         399       0.00      0.00      0.00         1\n",
      "         400       0.00      0.00      0.00         1\n",
      "         401       0.00      0.00      0.00         1\n",
      "         402       0.00      0.00      0.00         1\n",
      "         403       0.00      0.00      0.00         1\n",
      "         404       0.00      0.00      0.00         1\n",
      "         405       0.00      0.00      0.00         1\n",
      "         406       0.00      0.00      0.00         1\n",
      "         407       0.00      0.00      0.00         1\n",
      "         408       0.00      0.00      0.00         1\n",
      "         409       0.00      0.00      0.00         1\n",
      "         410       0.00      0.00      0.00         1\n",
      "         411       0.00      0.00      0.00         1\n",
      "         412       0.00      0.00      0.00         1\n",
      "         413       1.00      1.00      1.00         1\n",
      "         414       0.00      0.00      0.00         1\n",
      "         415       0.00      0.00      0.00         1\n",
      "         416       0.00      0.00      0.00         1\n",
      "         417       0.00      0.00      0.00         1\n",
      "         418       0.00      0.00      0.00         1\n",
      "         419       0.00      0.00      0.00         1\n",
      "         420       0.00      0.00      0.00         1\n",
      "         421       1.00      1.00      1.00         1\n",
      "         422       0.00      0.00      0.00         1\n",
      "         423       0.00      0.00      0.00         1\n",
      "         424       0.00      0.00      0.00         1\n",
      "         425       0.00      0.00      0.00         1\n",
      "         426       0.00      0.00      0.00         1\n",
      "         427       0.00      0.00      0.00         1\n",
      "         428       0.00      0.00      0.00         1\n",
      "         429       0.00      0.00      0.00         1\n",
      "         430       0.00      0.00      0.00         1\n",
      "         431       0.00      0.00      0.00         1\n",
      "         432       0.25      1.00      0.40         1\n",
      "         433       0.00      0.00      0.00         1\n",
      "         434       0.00      0.00      0.00         1\n",
      "         435       0.00      0.00      0.00         1\n",
      "         436       0.00      0.00      0.00         1\n",
      "         437       0.00      0.00      0.00         1\n",
      "         438       0.00      0.00      0.00         1\n",
      "         439       0.00      0.00      0.00         1\n",
      "         440       0.00      0.00      0.00         1\n",
      "         441       0.00      0.00      0.00         1\n",
      "         442       0.00      0.00      0.00         1\n",
      "         443       1.00      1.00      1.00         1\n",
      "         444       0.00      0.00      0.00         1\n",
      "         445       0.00      0.00      0.00         1\n",
      "         446       0.00      0.00      0.00         1\n",
      "         447       0.00      0.00      0.00         1\n",
      "         448       0.00      0.00      0.00         1\n",
      "         449       1.00      1.00      1.00         1\n",
      "         450       0.00      0.00      0.00         1\n",
      "         451       0.00      0.00      0.00         1\n",
      "         452       0.00      0.00      0.00         1\n",
      "         453       0.00      0.00      0.00         1\n",
      "         454       1.00      1.00      1.00         1\n",
      "         455       0.00      0.00      0.00         1\n",
      "         456       0.00      0.00      0.00         1\n",
      "         457       0.00      0.00      0.00         1\n",
      "         458       0.00      0.00      0.00         1\n",
      "         459       0.00      0.00      0.00         1\n",
      "         460       0.00      0.00      0.00         1\n",
      "         461       0.00      0.00      0.00         1\n",
      "         462       0.00      0.00      0.00         1\n",
      "         463       0.14      1.00      0.25         1\n",
      "         464       0.00      0.00      0.00         1\n",
      "         465       1.00      1.00      1.00         1\n",
      "         466       0.00      0.00      0.00         1\n",
      "         467       0.00      0.00      0.00         1\n",
      "         468       0.00      0.00      0.00         1\n",
      "         469       0.00      0.00      0.00         1\n",
      "         470       0.00      0.00      0.00         1\n",
      "         471       0.00      0.00      0.00         1\n",
      "         472       0.00      0.00      0.00         1\n",
      "         473       0.00      0.00      0.00         1\n",
      "         474       0.00      0.00      0.00         1\n",
      "         475       0.33      1.00      0.50         1\n",
      "         476       0.00      0.00      0.00         1\n",
      "         477       1.00      1.00      1.00         1\n",
      "         478       0.00      0.00      0.00         1\n",
      "         479       0.00      0.00      0.00         1\n",
      "         480       0.00      0.00      0.00         1\n",
      "         481       0.00      0.00      0.00         1\n",
      "         482       0.00      0.00      0.00         1\n",
      "         483       0.00      0.00      0.00         1\n",
      "         484       0.00      0.00      0.00         1\n",
      "         485       0.00      0.00      0.00         1\n",
      "         486       0.00      0.00      0.00         1\n",
      "         487       0.00      0.00      0.00         1\n",
      "         488       0.33      1.00      0.50         1\n",
      "         489       0.00      0.00      0.00         1\n",
      "         490       0.00      0.00      0.00         1\n",
      "         491       0.00      0.00      0.00         1\n",
      "         492       0.00      0.00      0.00         1\n",
      "         493       0.00      0.00      0.00         1\n",
      "         494       1.00      1.00      1.00         1\n",
      "         495       0.00      0.00      0.00         1\n",
      "         496       0.00      0.00      0.00         1\n",
      "         497       0.50      1.00      0.67         1\n",
      "         498       0.00      0.00      0.00         1\n",
      "         499       0.00      0.00      0.00         1\n",
      "         500       0.00      0.00      0.00         1\n",
      "         501       0.00      0.00      0.00         1\n",
      "         502       0.00      0.00      0.00         1\n",
      "         503       0.00      0.00      0.00         1\n",
      "         504       0.00      0.00      0.00         1\n",
      "         505       0.00      0.00      0.00         2\n",
      "         506       0.00      0.00      0.00         1\n",
      "         507       0.00      0.00      0.00         2\n",
      "         508       0.00      0.00      0.00         1\n",
      "         509       0.00      0.00      0.00         3\n",
      "         510       0.00      0.00      0.00         1\n",
      "         511       0.00      0.00      0.00         1\n",
      "         512       0.00      0.00      0.00         1\n",
      "         513       1.00      1.00      1.00         1\n",
      "         514       0.00      0.00      0.00         2\n",
      "         515       0.00      0.00      0.00         1\n",
      "         516       0.00      0.00      0.00         2\n",
      "         517       0.00      0.00      0.00         2\n",
      "         518       0.00      0.00      0.00         2\n",
      "         519       0.00      0.00      0.00         2\n",
      "         520       0.00      0.00      0.00         2\n",
      "         521       0.00      0.00      0.00         2\n",
      "         522       0.00      0.00      0.00         2\n",
      "         523       1.00      1.00      1.00         3\n",
      "         524       0.00      0.00      0.00         2\n",
      "         525       0.00      0.00      0.00         2\n",
      "         526       0.00      0.00      0.00         3\n",
      "         527       0.00      0.00      0.00         3\n",
      "         528       0.00      0.00      0.00         3\n",
      "         529       0.00      0.00      0.00         1\n",
      "         530       1.00      0.75      0.86         4\n",
      "         531       1.00      1.00      1.00         4\n",
      "         532       0.00      0.00      0.00         1\n",
      "         533       1.00      1.00      1.00         4\n",
      "         534       0.00      0.00      0.00         2\n",
      "         535       1.00      1.00      1.00         2\n",
      "         536       1.00      1.00      1.00         1\n",
      "         537       1.00      1.00      1.00         3\n",
      "         538       0.00      0.00      0.00         5\n",
      "         539       0.80      0.80      0.80         5\n",
      "         540       0.60      1.00      0.75         3\n",
      "         541       1.00      1.00      1.00         2\n",
      "         542       0.00      0.00      0.00         5\n",
      "         543       1.00      1.00      1.00         2\n",
      "         544       1.00      1.00      1.00         2\n",
      "         545       1.00      0.33      0.50         9\n",
      "         546       0.00      0.00      0.00         2\n",
      "         547       1.00      1.00      1.00         5\n",
      "         548       0.00      0.00      0.00         5\n",
      "         549       0.00      0.00      0.00         3\n",
      "         550       0.00      0.00      0.00         1\n",
      "         551       0.00      0.00      0.00         6\n",
      "         552       1.00      0.33      0.50         3\n",
      "         553       0.00      0.00      0.00         2\n",
      "         554       0.00      0.00      0.00         1\n",
      "         555       0.00      0.00      0.00         1\n",
      "         556       0.00      0.00      0.00         2\n",
      "         557       1.00      0.33      0.50         9\n",
      "         558       1.00      1.00      1.00         1\n",
      "         559       0.89      1.00      0.94         8\n",
      "         560       0.00      0.00      0.00         7\n",
      "         561       0.00      0.00      0.00         3\n",
      "         562       0.00      0.00      0.00         5\n",
      "         563       1.00      1.00      1.00         9\n",
      "         564       0.86      0.75      0.80         8\n",
      "         565       0.00      0.00      0.00         1\n",
      "         566       0.60      0.75      0.67         4\n",
      "         567       0.00      0.00      0.00         1\n",
      "         568       1.00      1.00      1.00         1\n",
      "         569       1.00      1.00      1.00         1\n",
      "         570       0.00      0.00      0.00         4\n",
      "         571       0.00      0.00      0.00         2\n",
      "         572       1.00      0.62      0.76        13\n",
      "         573       0.00      0.00      0.00         2\n",
      "         574       0.00      0.00      0.00         7\n",
      "         575       0.00      0.00      0.00         1\n",
      "         576       0.00      0.00      0.00         9\n",
      "         577       0.00      0.00      0.00        10\n",
      "         578       0.00      0.00      0.00         3\n",
      "         579       1.00      1.00      1.00         2\n",
      "         580       0.00      0.00      0.00         4\n",
      "         581       0.00      0.00      0.00         1\n",
      "         582       0.00      0.00      0.00         4\n",
      "         583       1.00      1.00      1.00         2\n",
      "         584       0.00      0.00      0.00         1\n",
      "         585       0.00      0.00      0.00         3\n",
      "         586       0.00      0.00      0.00         1\n",
      "         587       1.00      1.00      1.00         2\n",
      "         588       1.00      0.50      0.67        10\n",
      "         589       1.00      0.42      0.59        12\n",
      "         590       1.00      1.00      1.00         3\n",
      "         591       0.88      0.78      0.82         9\n",
      "         592       0.00      0.00      0.00         2\n",
      "         593       0.00      0.00      0.00         5\n",
      "         594       0.50      1.00      0.67         1\n",
      "         595       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32      1057\n",
      "   macro avg       0.23      0.25      0.22      1057\n",
      "weighted avg       0.34      0.32      0.31      1057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_words = X_to_words(X_test, char_tokenizer)\n",
    "baseline_pred = [assign_bucket(word, buckets) for word in test_words]\n",
    "r = classification_report(y_true=y_t, y_pred=baseline_pred)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2cf9fa26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: flang\n",
      "['svang', 'tonetrang', 'jubelklang', 'rang', 'sang']\n",
      "\n",
      "Word: gorlang\n",
      "['svang', 'tonetrang', 'jubelklang', 'rang', 'sang']\n",
      "\n",
      "Word: blatt\n",
      "['tatt', 'natt', 'Natt', 'sommernatt', 'matt']\n",
      "\n",
      "Word: knatt\n",
      "['tatt', 'natt', 'Natt', 'sommernatt', 'matt']\n",
      "\n",
      "Word: pril\n",
      "['sol', 'stol', 'Kongestol', 'metropol', 'herskerstol']\n",
      "\n",
      "Word: glunn\n",
      "['bunn', 'funn', 'flammemunn', 'odelsgrunn', 'kun']\n",
      "\n",
      "Word: svans\n",
      "['Sanktehans', 'seierskrans', 'Hans', 'stans', 'krans']\n",
      "\n",
      "Word: stritt\n",
      "['klut', 'slut', 'sønderskutt', 'forskutt', 'stut']\n",
      "\n",
      "Word: hjal\n",
      "['pral', 'gal', 'sjal', 'Cheval', 'ritual']\n",
      "\n",
      "Word: sta\n",
      "['glad', 'la', 'da', 'fra', 'gjenoppta']\n",
      "\n",
      "Word: plirk\n",
      "['mørk', 'bjørk', 'dørk', 'ørk']\n",
      "\n",
      "Word: coll\n",
      "['lunefull', 'fangehull', 'vemodsfull', 'tryllerull', 'Bull']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_some_more = char_tokenizer.texts_to_sequences(some_more)\n",
    "test_some_more =  tf.keras.preprocessing.sequence.pad_sequences(test_some_more, maxlen=MAX_LEN, padding=\"post\", value=0) \n",
    "more_preds = model.predict(test_some_more)\n",
    "more_preds = np.argmax(more_preds, axis=1)\n",
    "\n",
    "for w, i in zip(some_more, more_preds):\n",
    "    print(f\"Word: {w}\")\n",
    "    print(buckets[i][:5])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e3ab46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../rhyme_modelling/good+manual_char_tokenizer_config.json\") as f:\n",
    "    tokenizer_config = f.read()\n",
    "\n",
    "char_tokenizer1 = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0b7c92cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x7f3733f12610>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d84d0019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "står\n",
      "['sjelesår', 'forslår', 'slavekår', 'forgår', 'trengselskår']\n",
      "\n",
      "vind\n",
      "['fro', 'bero', 'go', 'avgrunnsbro', 'Co.']\n",
      "\n",
      "spinn\n",
      "['utkåret', 'hundreåret', 'såret', 'båret', 'året']\n",
      "\n",
      "spe\n",
      "['avsted', 'geled', 'skje', 'galgetre', 'tre']\n",
      "\n",
      "tent\n",
      "['edelsten', 'pen', 'hverdagsfenomen', 'sken', 'en']\n",
      "\n",
      "støttepunkt\n",
      "['tegn', 'grein', 'tilregn', 'kampestein', 'klippeegn']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def words_to_buckets(words):\n",
    "    x = char_tokenizer1.texts_to_sequences(words)    \n",
    "    x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=60, padding=\"post\", value=0) \n",
    "    preds = model.predict(x)\n",
    "    p = np.argmax(preds, axis=1)\n",
    "    return [buckets[i] for i in p]\n",
    "\n",
    "wo = [\"står\", \"vind\", \"spinn\", \"spe\", \"tent\", \"støttepunkt\"]\n",
    "\n",
    "for w, b in zip(wo, words_to_buckets(wo)):\n",
    "    print(w)\n",
    "    print(b[:5])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467114f",
   "metadata": {},
   "source": [
    "## Only use buckets with >4 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3eb6d1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = [b for b in buckets if len(b) > 4]\n",
    "bucket_vocab_size = len(buckets)\n",
    "bucket_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1252bc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.0, 12.077639751552795)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [len(b) for b in buckets]\n",
    "np.median(l), np.mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d83b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_name = \"big_5_buckets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d440844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"pickles/{buckets_name}.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(buckets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff4683d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_indexer = {w:i for i,b in enumerate(buckets) for w in b}\n",
    "\n",
    "# with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"wb+\") as f:\n",
    "#     pickle.dump(bucket_indexer, f)\n",
    "\n",
    "with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"rb\") as f:\n",
    "    bucket_indexer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a5026ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3889"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(bucket_indexer.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36467130",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = buckets_to_data(vocab, char_tokenizer, bucket_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2939caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set test size to 0.4 so there is at least one example from each class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y, random_state=SEED)\n",
    "\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c75da29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2333, 60), (778, 60), (778, 60))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_dev.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7bff96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_is = np.argmax(y_train, axis=1)\n",
    "# least_common_train = Counter(y_train_is).most_common()[-1][1]\n",
    "\n",
    "# y_dev_is = np.argmax(y_dev, axis=1)\n",
    "# least_common_dev = Counter(y_dev_is).most_common()[-1][1]\n",
    "\n",
    "# y_test_is = np.argmax(y_test, axis=1)\n",
    "# least_common_test = Counter(y_test_is).most_common()[-1][1]\n",
    "\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The smallest class in training data has {least_common_train} occurences\n",
    "# The smallest class in dev data has {least_common_dev} occurences\n",
    "# The smallest class in test data has {least_common_test} occurences\n",
    "# \"\"\")\n",
    "\n",
    "# c = Counter(y_dev_is)\n",
    "# ones = sum(count==1 for _, count in c.items())\n",
    "# twos = sum(count==2 for _, count in c.items())\n",
    "# threes = sum(count==3 for _, count in c.items())\n",
    "# ones, twos, threes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2981a",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "187b3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"rhyme_gen_norsc_big_5_buckets\"\n",
    "\n",
    "# # Uncomment to train\n",
    "# model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Embedding(input_dim=MAX_LEN, output_dim=128, mask_zero=True),\n",
    "#             tf.keras.layers.LSTM(units=128),\n",
    "#             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(bucket_vocab_size, activation=\"softmax\"),\n",
    "#         ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "# csv_logger = tf.keras.callbacks.CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=100,\n",
    "#                     validation_data = (X_dev, y_dev),\n",
    "#                     callbacks=[model_checkpoint, terminate_on_nan, early_stop, csv_logger])\n",
    "\n",
    "model = tf.keras.models.load_model(f\"models/{model_name}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19ae7c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((778, 322), (778, 322))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "y_test.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c148f355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((778,), (778,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.argmax(preds, axis=1)\n",
    "y_t = np.argmax(y_test, axis=1)\n",
    "p.shape, y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83ed8f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23 of 322 buckets are missing from predictions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{len(set(y_t) - set(p))} of {len(set(y_t))} buckets are missing from predictions. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ddae794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       0.88      1.00      0.93         7\n",
      "           5       1.00      0.86      0.92         7\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       0.40      0.80      0.53         5\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       0.83      1.00      0.91         5\n",
      "          15       1.00      0.75      0.86         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       0.83      1.00      0.91         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      1.00      1.00         4\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       0.75      1.00      0.86         3\n",
      "          24       1.00      1.00      1.00         4\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       0.60      1.00      0.75         3\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       0.75      1.00      0.86         3\n",
      "          31       1.00      1.00      1.00         4\n",
      "          32       1.00      1.00      1.00         3\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       1.00      0.67      0.80         3\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       1.00      1.00      1.00         3\n",
      "          39       1.00      0.67      0.80         3\n",
      "          40       1.00      1.00      1.00         3\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.75      1.00      0.86         3\n",
      "          44       1.00      1.00      1.00         3\n",
      "          45       1.00      1.00      1.00         3\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       0.75      1.00      0.86         3\n",
      "          50       1.00      1.00      1.00         3\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      0.33      0.50         3\n",
      "          53       1.00      1.00      1.00         3\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         3\n",
      "          56       1.00      0.67      0.80         3\n",
      "          57       1.00      1.00      1.00         3\n",
      "          58       1.00      1.00      1.00         3\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         3\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       0.67      1.00      0.80         2\n",
      "          66       1.00      1.00      1.00         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      0.50      0.67         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       0.50      1.00      0.67         2\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       1.00      1.00      1.00         2\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      0.50      0.67         2\n",
      "          84       1.00      1.00      1.00         2\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       0.67      1.00      0.80         2\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       1.00      1.00      1.00         2\n",
      "          90       1.00      1.00      1.00         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       0.50      0.50      0.50         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       0.00      0.00      0.00         2\n",
      "          99       1.00      0.50      0.67         2\n",
      "         100       1.00      1.00      1.00         2\n",
      "         101       0.67      1.00      0.80         2\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       1.00      1.00      1.00         2\n",
      "         104       0.67      1.00      0.80         2\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       1.00      1.00      1.00         1\n",
      "         108       1.00      1.00      1.00         1\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       1.00      1.00      1.00         1\n",
      "         111       1.00      1.00      1.00         2\n",
      "         112       0.00      0.00      0.00         2\n",
      "         113       1.00      1.00      1.00         1\n",
      "         114       1.00      1.00      1.00         2\n",
      "         115       1.00      1.00      1.00         1\n",
      "         116       1.00      1.00      1.00         1\n",
      "         117       1.00      1.00      1.00         1\n",
      "         118       1.00      1.00      1.00         1\n",
      "         119       1.00      0.50      0.67         2\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       1.00      1.00      1.00         2\n",
      "         124       1.00      1.00      1.00         2\n",
      "         125       1.00      1.00      1.00         1\n",
      "         126       1.00      1.00      1.00         1\n",
      "         127       1.00      1.00      1.00         2\n",
      "         128       1.00      1.00      1.00         2\n",
      "         129       1.00      1.00      1.00         1\n",
      "         130       1.00      1.00      1.00         1\n",
      "         131       0.67      1.00      0.80         2\n",
      "         132       1.00      1.00      1.00         2\n",
      "         133       0.00      0.00      0.00         2\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       1.00      1.00      1.00         2\n",
      "         136       1.00      1.00      1.00         2\n",
      "         137       1.00      1.00      1.00         2\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       1.00      1.00      1.00         2\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.50      1.00      0.67         1\n",
      "         142       1.00      1.00      1.00         2\n",
      "         143       1.00      1.00      1.00         1\n",
      "         144       1.00      1.00      1.00         2\n",
      "         145       1.00      1.00      1.00         1\n",
      "         146       1.00      1.00      1.00         1\n",
      "         147       0.50      1.00      0.67         1\n",
      "         148       1.00      1.00      1.00         1\n",
      "         149       1.00      1.00      1.00         2\n",
      "         150       1.00      1.00      1.00         2\n",
      "         151       1.00      1.00      1.00         1\n",
      "         152       1.00      0.50      0.67         2\n",
      "         153       1.00      1.00      1.00         2\n",
      "         154       1.00      1.00      1.00         1\n",
      "         155       1.00      1.00      1.00         1\n",
      "         156       1.00      1.00      1.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       1.00      1.00      1.00         1\n",
      "         159       1.00      1.00      1.00         1\n",
      "         160       1.00      1.00      1.00         1\n",
      "         161       1.00      1.00      1.00         1\n",
      "         162       1.00      1.00      1.00         1\n",
      "         163       1.00      1.00      1.00         1\n",
      "         164       1.00      1.00      1.00         1\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       1.00      1.00      1.00         1\n",
      "         167       0.00      0.00      0.00         1\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       1.00      1.00      1.00         1\n",
      "         170       1.00      1.00      1.00         1\n",
      "         171       1.00      1.00      1.00         1\n",
      "         172       1.00      1.00      1.00         1\n",
      "         173       1.00      1.00      1.00         1\n",
      "         174       1.00      1.00      1.00         1\n",
      "         175       1.00      1.00      1.00         1\n",
      "         176       1.00      1.00      1.00         1\n",
      "         177       1.00      1.00      1.00         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       1.00      1.00      1.00         1\n",
      "         181       1.00      1.00      1.00         1\n",
      "         182       1.00      1.00      1.00         1\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       1.00      1.00      1.00         1\n",
      "         185       1.00      1.00      1.00         1\n",
      "         186       1.00      1.00      1.00         1\n",
      "         187       0.20      1.00      0.33         1\n",
      "         188       1.00      1.00      1.00         1\n",
      "         189       1.00      1.00      1.00         1\n",
      "         190       1.00      1.00      1.00         1\n",
      "         191       1.00      1.00      1.00         1\n",
      "         192       1.00      1.00      1.00         1\n",
      "         193       1.00      1.00      1.00         1\n",
      "         194       0.33      1.00      0.50         1\n",
      "         195       1.00      1.00      1.00         1\n",
      "         196       1.00      1.00      1.00         1\n",
      "         197       0.33      1.00      0.50         1\n",
      "         198       1.00      1.00      1.00         1\n",
      "         199       1.00      1.00      1.00         1\n",
      "         200       1.00      1.00      1.00         1\n",
      "         201       0.50      1.00      0.67         1\n",
      "         202       1.00      1.00      1.00         1\n",
      "         203       1.00      1.00      1.00         1\n",
      "         204       1.00      1.00      1.00         1\n",
      "         205       1.00      1.00      1.00         1\n",
      "         206       1.00      1.00      1.00         1\n",
      "         207       1.00      1.00      1.00         1\n",
      "         208       1.00      1.00      1.00         1\n",
      "         209       1.00      1.00      1.00         1\n",
      "         210       1.00      1.00      1.00         1\n",
      "         211       1.00      1.00      1.00         1\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       1.00      1.00      1.00         1\n",
      "         214       1.00      1.00      1.00         1\n",
      "         215       1.00      1.00      1.00         1\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       1.00      1.00      1.00         1\n",
      "         218       1.00      1.00      1.00         1\n",
      "         219       1.00      1.00      1.00         1\n",
      "         220       1.00      1.00      1.00         1\n",
      "         221       1.00      1.00      1.00         1\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       1.00      1.00      1.00         1\n",
      "         225       1.00      1.00      1.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       1.00      1.00      1.00         1\n",
      "         228       1.00      1.00      1.00         1\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       1.00      1.00      1.00         1\n",
      "         231       1.00      1.00      1.00         1\n",
      "         232       1.00      1.00      1.00         1\n",
      "         233       0.00      0.00      0.00         1\n",
      "         234       1.00      1.00      1.00         1\n",
      "         235       1.00      1.00      1.00         1\n",
      "         236       1.00      1.00      1.00         1\n",
      "         237       1.00      1.00      1.00         1\n",
      "         238       1.00      1.00      1.00         1\n",
      "         239       1.00      1.00      1.00         1\n",
      "         240       0.67      1.00      0.80         2\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       1.00      1.00      1.00         2\n",
      "         243       1.00      1.00      1.00         3\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       1.00      1.00      1.00         1\n",
      "         246       1.00      1.00      1.00         1\n",
      "         247       1.00      1.00      1.00         2\n",
      "         248       1.00      1.00      1.00         1\n",
      "         249       1.00      1.00      1.00         2\n",
      "         250       1.00      1.00      1.00         2\n",
      "         251       1.00      1.00      1.00         2\n",
      "         252       0.00      0.00      0.00         2\n",
      "         253       0.00      0.00      0.00         2\n",
      "         254       0.00      0.00      0.00         2\n",
      "         255       0.00      0.00      0.00         2\n",
      "         256       1.00      1.00      1.00         3\n",
      "         257       1.00      1.00      1.00         2\n",
      "         258       1.00      1.00      1.00         2\n",
      "         259       1.00      1.00      1.00         3\n",
      "         260       0.75      1.00      0.86         3\n",
      "         261       0.75      1.00      0.86         3\n",
      "         262       0.00      0.00      0.00         1\n",
      "         263       0.00      0.00      0.00         4\n",
      "         264       1.00      1.00      1.00         4\n",
      "         265       1.00      1.00      1.00         1\n",
      "         266       0.00      0.00      0.00         4\n",
      "         267       1.00      0.50      0.67         2\n",
      "         268       0.00      0.00      0.00         2\n",
      "         269       0.00      0.00      0.00         3\n",
      "         270       0.00      0.00      0.00         5\n",
      "         271       0.83      1.00      0.91         5\n",
      "         272       1.00      0.67      0.80         3\n",
      "         273       1.00      1.00      1.00         2\n",
      "         274       0.00      0.00      0.00         5\n",
      "         275       0.00      0.00      0.00         2\n",
      "         276       0.00      0.00      0.00         2\n",
      "         277       1.00      1.00      1.00         9\n",
      "         278       1.00      1.00      1.00         2\n",
      "         279       0.00      0.00      0.00         5\n",
      "         280       0.00      0.00      0.00         5\n",
      "         281       1.00      1.00      1.00         3\n",
      "         282       0.62      0.83      0.71         6\n",
      "         283       1.00      0.67      0.80         3\n",
      "         284       1.00      1.00      1.00         2\n",
      "         285       1.00      1.00      1.00         1\n",
      "         286       0.00      0.00      0.00         1\n",
      "         287       0.50      1.00      0.67         2\n",
      "         288       0.00      0.00      0.00         9\n",
      "         289       0.00      0.00      0.00         8\n",
      "         290       0.00      0.00      0.00         7\n",
      "         291       0.00      0.00      0.00         3\n",
      "         292       0.00      0.00      0.00         5\n",
      "         293       0.00      0.00      0.00         9\n",
      "         294       0.00      0.00      0.00         8\n",
      "         295       0.00      0.00      0.00         4\n",
      "         296       0.50      1.00      0.67         1\n",
      "         297       0.00      0.00      0.00         1\n",
      "         298       0.00      0.00      0.00         1\n",
      "         299       0.00      0.00      0.00         4\n",
      "         300       0.00      0.00      0.00         2\n",
      "         301       0.00      0.00      0.00        13\n",
      "         302       0.00      0.00      0.00         2\n",
      "         303       0.00      0.00      0.00         7\n",
      "         304       0.00      0.00      0.00         1\n",
      "         305       0.00      0.00      0.00         9\n",
      "         306       0.00      0.00      0.00        10\n",
      "         307       0.00      0.00      0.00         3\n",
      "         308       0.00      0.00      0.00         2\n",
      "         309       0.00      0.00      0.00         4\n",
      "         310       0.00      0.00      0.00         1\n",
      "         311       1.00      0.75      0.86         4\n",
      "         312       0.00      0.00      0.00         2\n",
      "         313       0.00      0.00      0.00         3\n",
      "         314       0.00      0.00      0.00         2\n",
      "         315       1.00      1.00      1.00        10\n",
      "         316       0.00      0.00      0.00        12\n",
      "         317       0.00      0.00      0.00         3\n",
      "         318       0.00      0.00      0.00         9\n",
      "         319       1.00      1.00      1.00         2\n",
      "         320       0.00      0.00      0.00         5\n",
      "         321       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.69       778\n",
      "   macro avg       0.76      0.77      0.76       778\n",
      "weighted avg       0.68      0.69      0.68       778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "r = classification_report(y_true=y_t, y_pred=p)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eed1472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       1.00      0.50      0.67         8\n",
      "           3       0.67      0.50      0.57         8\n",
      "           4       1.00      0.43      0.60         7\n",
      "           5       1.00      0.43      0.60         7\n",
      "           6       0.75      1.00      0.86         6\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      0.80      0.89         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       0.03      1.00      0.07         5\n",
      "          12       0.03      1.00      0.06         4\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       1.00      0.60      0.75         5\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       0.00      0.00      0.00         5\n",
      "          18       0.00      0.00      0.00         5\n",
      "          19       0.80      1.00      0.89         4\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         4\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       0.07      1.00      0.14         3\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       0.09      1.00      0.16         3\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       0.75      1.00      0.86         3\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       1.00      0.67      0.80         3\n",
      "          36       0.75      1.00      0.86         3\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.75      1.00      0.86         3\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         3\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       0.60      1.00      0.75         3\n",
      "          53       0.00      0.00      0.00         3\n",
      "          54       0.50      0.50      0.50         2\n",
      "          55       0.00      0.00      0.00         3\n",
      "          56       0.67      0.67      0.67         3\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.00      0.00      0.00         3\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.50      1.00      0.67         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.40      1.00      0.57         2\n",
      "          71       0.67      1.00      0.80         2\n",
      "          72       0.50      1.00      0.67         2\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       0.00      0.00      0.00         2\n",
      "          90       0.00      0.00      0.00         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         2\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         2\n",
      "          99       1.00      0.50      0.67         2\n",
      "         100       1.00      1.00      1.00         2\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         2\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         2\n",
      "         107       1.00      1.00      1.00         1\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         2\n",
      "         112       0.00      0.00      0.00         2\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         2\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.50      1.00      0.67         2\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       1.00      1.00      1.00         2\n",
      "         124       0.00      0.00      0.00         2\n",
      "         125       0.00      0.00      0.00         1\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         2\n",
      "         128       0.00      0.00      0.00         2\n",
      "         129       0.00      0.00      0.00         1\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.50      1.00      0.67         2\n",
      "         132       0.29      1.00      0.44         2\n",
      "         133       0.00      0.00      0.00         2\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       1.00      1.00      1.00         2\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         2\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         2\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         2\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.67      1.00      0.80         2\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         2\n",
      "         153       1.00      1.00      1.00         2\n",
      "         154       1.00      1.00      1.00         1\n",
      "         155       0.50      1.00      0.67         1\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         1\n",
      "         159       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         1\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       1.00      1.00      1.00         1\n",
      "         167       0.00      0.00      0.00         1\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.20      1.00      0.33         1\n",
      "         170       1.00      1.00      1.00         1\n",
      "         171       1.00      1.00      1.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       1.00      1.00      1.00         1\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       1.00      1.00      1.00         1\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         1\n",
      "         181       0.00      0.00      0.00         1\n",
      "         182       1.00      1.00      1.00         1\n",
      "         183       0.00      0.00      0.00         1\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         1\n",
      "         186       0.00      0.00      0.00         1\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       0.00      0.00      0.00         1\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         1\n",
      "         192       0.50      1.00      0.67         1\n",
      "         193       0.00      0.00      0.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       1.00      1.00      1.00         1\n",
      "         196       0.00      0.00      0.00         1\n",
      "         197       1.00      1.00      1.00         1\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         1\n",
      "         200       0.00      0.00      0.00         1\n",
      "         201       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         1\n",
      "         204       1.00      1.00      1.00         1\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         1\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00         1\n",
      "         211       0.00      0.00      0.00         1\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       0.00      0.00      0.00         1\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       0.50      1.00      0.67         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       1.00      1.00      1.00         1\n",
      "         220       1.00      1.00      1.00         1\n",
      "         221       0.50      1.00      0.67         1\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       0.50      1.00      0.67         1\n",
      "         225       1.00      1.00      1.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         1\n",
      "         231       1.00      1.00      1.00         1\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.00      0.00      0.00         1\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       1.00      1.00      1.00         1\n",
      "         237       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         1\n",
      "         240       0.00      0.00      0.00         2\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         2\n",
      "         243       0.00      0.00      0.00         3\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       0.00      0.00      0.00         1\n",
      "         246       1.00      1.00      1.00         1\n",
      "         247       0.00      0.00      0.00         2\n",
      "         248       0.00      0.00      0.00         1\n",
      "         249       0.00      0.00      0.00         2\n",
      "         250       0.00      0.00      0.00         2\n",
      "         251       0.00      0.00      0.00         2\n",
      "         252       0.00      0.00      0.00         2\n",
      "         253       0.00      0.00      0.00         2\n",
      "         254       0.00      0.00      0.00         2\n",
      "         255       0.00      0.00      0.00         2\n",
      "         256       1.00      1.00      1.00         3\n",
      "         257       0.00      0.00      0.00         2\n",
      "         258       0.00      0.00      0.00         2\n",
      "         259       0.50      1.00      0.67         3\n",
      "         260       0.00      0.00      0.00         3\n",
      "         261       0.00      0.00      0.00         3\n",
      "         262       0.00      0.00      0.00         1\n",
      "         263       1.00      0.75      0.86         4\n",
      "         264       1.00      1.00      1.00         4\n",
      "         265       0.00      0.00      0.00         1\n",
      "         266       1.00      1.00      1.00         4\n",
      "         267       0.00      0.00      0.00         2\n",
      "         268       0.67      1.00      0.80         2\n",
      "         269       1.00      1.00      1.00         3\n",
      "         270       0.00      0.00      0.00         5\n",
      "         271       1.00      0.80      0.89         5\n",
      "         272       1.00      1.00      1.00         3\n",
      "         273       0.67      1.00      0.80         2\n",
      "         274       0.18      0.40      0.25         5\n",
      "         275       0.67      1.00      0.80         2\n",
      "         276       0.67      1.00      0.80         2\n",
      "         277       0.75      0.33      0.46         9\n",
      "         278       0.00      0.00      0.00         2\n",
      "         279       1.00      1.00      1.00         5\n",
      "         280       0.00      0.00      0.00         5\n",
      "         281       0.00      0.00      0.00         3\n",
      "         282       0.00      0.00      0.00         6\n",
      "         283       1.00      0.33      0.50         3\n",
      "         284       0.00      0.00      0.00         2\n",
      "         285       0.00      0.00      0.00         1\n",
      "         286       0.00      0.00      0.00         1\n",
      "         287       0.00      0.00      0.00         2\n",
      "         288       1.00      0.33      0.50         9\n",
      "         289       0.89      1.00      0.94         8\n",
      "         290       0.00      0.00      0.00         7\n",
      "         291       0.00      0.00      0.00         3\n",
      "         292       1.00      1.00      1.00         5\n",
      "         293       1.00      1.00      1.00         9\n",
      "         294       0.86      0.75      0.80         8\n",
      "         295       0.75      0.75      0.75         4\n",
      "         296       0.00      0.00      0.00         1\n",
      "         297       1.00      1.00      1.00         1\n",
      "         298       1.00      1.00      1.00         1\n",
      "         299       0.00      0.00      0.00         4\n",
      "         300       0.00      0.00      0.00         2\n",
      "         301       1.00      0.62      0.76        13\n",
      "         302       0.00      0.00      0.00         2\n",
      "         303       0.00      0.00      0.00         7\n",
      "         304       0.00      0.00      0.00         1\n",
      "         305       0.00      0.00      0.00         9\n",
      "         306       0.00      0.00      0.00        10\n",
      "         307       0.00      0.00      0.00         3\n",
      "         308       1.00      1.00      1.00         2\n",
      "         309       0.00      0.00      0.00         4\n",
      "         310       0.00      0.00      0.00         1\n",
      "         311       0.00      0.00      0.00         4\n",
      "         312       1.00      1.00      1.00         2\n",
      "         313       0.00      0.00      0.00         3\n",
      "         314       1.00      1.00      1.00         2\n",
      "         315       0.83      0.50      0.62        10\n",
      "         316       1.00      0.42      0.59        12\n",
      "         317       0.75      1.00      0.86         3\n",
      "         318       0.88      0.78      0.82         9\n",
      "         319       0.00      0.00      0.00         2\n",
      "         320       0.00      0.00      0.00         5\n",
      "         321       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.39       778\n",
      "   macro avg       0.30      0.32      0.29       778\n",
      "weighted avg       0.42      0.39      0.38       778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_words = X_to_words(X_test, char_tokenizer)\n",
    "baseline_pred = [assign_bucket(word, buckets) for word in test_words]\n",
    "r = classification_report(y_true=y_t, y_pred=baseline_pred)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "191bd9ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: flang\n",
      "['svang', 'tonetrang', 'jubelklang', 'rang', 'sang']\n",
      "\n",
      "Word: gorlang\n",
      "['svang', 'tonetrang', 'jubelklang', 'rang', 'sang']\n",
      "\n",
      "Word: blatt\n",
      "['tatt', 'natt', 'Natt', 'sommernatt', 'matt']\n",
      "\n",
      "Word: knatt\n",
      "['tatt', 'natt', 'Natt', 'sommernatt', 'matt']\n",
      "\n",
      "Word: pril\n",
      "['vil', 'bil', 'renkespill', 'fløytespill', 'il']\n",
      "\n",
      "Word: glunn\n",
      "['bunn', 'funn', 'flammemunn', 'odelsgrunn', 'kun']\n",
      "\n",
      "Word: svans\n",
      "['Sanktehans', 'seierskrans', 'Hans', 'stans', 'krans']\n",
      "\n",
      "Word: stritt\n",
      "['granitt', 'milevidt', 'fritt', 'lidt', 'profitt']\n",
      "\n",
      "Word: hjal\n",
      "['pral', 'gal', 'sjal', 'Cheval', 'ritual']\n",
      "\n",
      "Word: sta\n",
      "['tonehav', 'hyrdestav', 'murstensgrav', 'skyttergrav', 'bispestav']\n",
      "\n",
      "Word: plirk\n",
      "['flokk', 'lokk', 'klippeblokk', 'fnokk', 'nok']\n",
      "\n",
      "Word: coll\n",
      "['lunefull', 'fangehull', 'vemodsfull', 'tryllerull', 'Bull']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_some_more = char_tokenizer.texts_to_sequences(some_more)\n",
    "test_some_more =  tf.keras.preprocessing.sequence.pad_sequences(test_some_more, maxlen=MAX_LEN, padding=\"post\", value=0) \n",
    "more_preds = model.predict(test_some_more)\n",
    "more_preds = np.argmax(more_preds, axis=1)\n",
    "\n",
    "for w, i in zip(some_more, more_preds):\n",
    "    print(f\"Word: {w}\")\n",
    "    print(buckets[i][:5])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0260de0",
   "metadata": {},
   "source": [
    "# Buckets >9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aae7775a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = good_buckets + manual_buckets\n",
    "buckets = [b for b in buckets if len(b) > 9]\n",
    "bucket_vocab_size = len(buckets)\n",
    "bucket_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2ada05b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.0, 18.714285714285715)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [len(b) for b in buckets]\n",
    "np.median(l), np.mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "991f5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_name = \"rhyme_gen_norsc_big_9_buckets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4a94a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"pickles/{buckets_name}.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(buckets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "22157956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_indexer = {w:i for i,b in enumerate(buckets) for w in b}\n",
    "\n",
    "# with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"wb+\") as f:\n",
    "#     pickle.dump(bucket_indexer, f)\n",
    "\n",
    "with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"rb\") as f:\n",
    "    bucket_indexer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ffb78cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2751"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(bucket_indexer.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "21318cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = buckets_to_data(vocab, char_tokenizer, bucket_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bfe7e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "44566171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1925, 60), (413, 60), (413, 60))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_dev.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "08ca660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 6s 96ms/step - loss: 0.4208 - val_loss: 0.0802\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0646 - val_loss: 0.0455\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0441 - val_loss: 0.0419\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0420 - val_loss: 0.0409\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0412 - val_loss: 0.0404\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0409 - val_loss: 0.0402\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0407 - val_loss: 0.0400\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0405 - val_loss: 0.0399\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0404 - val_loss: 0.0399\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0403 - val_loss: 0.0398\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0402 - val_loss: 0.0398\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0403 - val_loss: 0.0398\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.0402 - val_loss: 0.0397\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0402 - val_loss: 0.0397\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.0401 - val_loss: 0.0397\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 0.0400 - val_loss: 0.0396\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 3s 82ms/step - loss: 0.0400 - val_loss: 0.0396\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 2s 76ms/step - loss: 0.0400 - val_loss: 0.0395\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.0398 - val_loss: 0.0394\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0397 - val_loss: 0.0393\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0396 - val_loss: 0.0391\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0394 - val_loss: 0.0388\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 2s 76ms/step - loss: 0.0390 - val_loss: 0.0383\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 2s 80ms/step - loss: 0.0383 - val_loss: 0.0375\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0373 - val_loss: 0.0362\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0359 - val_loss: 0.0347\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0344 - val_loss: 0.0331\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0330 - val_loss: 0.0319\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0318 - val_loss: 0.0308\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0309 - val_loss: 0.0299\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0301 - val_loss: 0.0292\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0294 - val_loss: 0.0283\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0285 - val_loss: 0.0274\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0276 - val_loss: 0.0266\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0268 - val_loss: 0.0256\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0258 - val_loss: 0.0248\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0249 - val_loss: 0.0238\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0238 - val_loss: 0.0228\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0228 - val_loss: 0.0216\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0218 - val_loss: 0.0207\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0208 - val_loss: 0.0198\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0199 - val_loss: 0.0191\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0192 - val_loss: 0.0183\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0176 - val_loss: 0.0167\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.0167 - val_loss: 0.0161\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0161 - val_loss: 0.0153\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0148 - val_loss: 0.0142\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 2s 72ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0011 - val_loss: 0.0029\n"
     ]
    }
   ],
   "source": [
    "model_name = buckets_name\n",
    "\n",
    "# # Uncomment to train\n",
    "# model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Embedding(input_dim=MAX_LEN, output_dim=128, mask_zero=True),\n",
    "#             tf.keras.layers.LSTM(units=128),\n",
    "#             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(bucket_vocab_size, activation=\"softmax\"),\n",
    "#         ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "# csv_logger = tf.keras.callbacks.CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=100,\n",
    "#                     validation_data = (X_dev, y_dev),\n",
    "#                     callbacks=[model_checkpoint, terminate_on_nan, early_stop, csv_logger])\n",
    "\n",
    "model = tf.keras.models.load_model(f\"models/{model_name}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8311dc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((413, 147), (413, 147))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "y_test.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d149e0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((413,), (413,))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.argmax(preds, axis=1)\n",
    "y_t = np.argmax(y_test, axis=1)\n",
    "p.shape, y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2b917697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of 147 buckets are missing from predictions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{len(set(y_t) - set(p))} of {len(set(y_t))} buckets are missing from predictions. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fa3df6f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00         6\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      0.50      0.67         4\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.80      1.00      0.89         4\n",
      "           8       1.00      1.00      1.00         4\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         3\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       0.80      1.00      0.89         4\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00         3\n",
      "          17       0.75      1.00      0.86         3\n",
      "          18       1.00      1.00      1.00         3\n",
      "          19       1.00      0.67      0.80         3\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       0.67      1.00      0.80         2\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       0.40      0.67      0.50         3\n",
      "          25       0.75      1.00      0.86         3\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         3\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       1.00      1.00      1.00         3\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      0.50      0.67         2\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      1.00      1.00         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       0.50      0.50      0.50         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       0.50      1.00      0.67         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      0.50      0.67         2\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         1\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         1\n",
      "          66       1.00      1.00      1.00         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       1.00      1.00      1.00         1\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         1\n",
      "          78       1.00      1.00      1.00         2\n",
      "          79       1.00      1.00      1.00         1\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         1\n",
      "          82       1.00      1.00      1.00         1\n",
      "          83       1.00      1.00      1.00         1\n",
      "          84       1.00      1.00      1.00         2\n",
      "          85       1.00      1.00      1.00         1\n",
      "          86       1.00      1.00      1.00         1\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       1.00      1.00      1.00         1\n",
      "          89       1.00      1.00      1.00         2\n",
      "          90       1.00      1.00      1.00         1\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         1\n",
      "          94       1.00      1.00      1.00         1\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       1.00      1.00      1.00         1\n",
      "          97       1.00      1.00      1.00         1\n",
      "          98       1.00      1.00      1.00         2\n",
      "          99       1.00      1.00      1.00         1\n",
      "         100       1.00      1.00      1.00         2\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       1.00      1.00      1.00         2\n",
      "         103       1.00      1.00      1.00         2\n",
      "         104       1.00      1.00      1.00         2\n",
      "         105       1.00      1.00      1.00         2\n",
      "         106       1.00      1.00      1.00         3\n",
      "         107       1.00      1.00      1.00         3\n",
      "         108       1.00      1.00      1.00         2\n",
      "         109       1.00      1.00      1.00         2\n",
      "         110       1.00      1.00      1.00         4\n",
      "         111       1.00      1.00      1.00         4\n",
      "         112       1.00      1.00      1.00         2\n",
      "         113       1.00      1.00      1.00         3\n",
      "         114       1.00      1.00      1.00         2\n",
      "         115       0.88      1.00      0.93         7\n",
      "         116       1.00      1.00      1.00         2\n",
      "         117       1.00      1.00      1.00         4\n",
      "         118       1.00      1.00      1.00         4\n",
      "         119       1.00      1.00      1.00         2\n",
      "         120       0.67      1.00      0.80         4\n",
      "         121       1.00      0.33      0.50         3\n",
      "         122       1.00      1.00      1.00         7\n",
      "         123       1.00      1.00      1.00         6\n",
      "         124       1.00      1.00      1.00         6\n",
      "         125       1.00      1.00      1.00         2\n",
      "         126       1.00      1.00      1.00         4\n",
      "         127       1.00      1.00      1.00         7\n",
      "         128       1.00      1.00      1.00         5\n",
      "         129       1.00      1.00      1.00         3\n",
      "         130       1.00      1.00      1.00         3\n",
      "         131       1.00      1.00      1.00        10\n",
      "         132       1.00      1.00      1.00         2\n",
      "         133       1.00      1.00      1.00         5\n",
      "         134       1.00      1.00      1.00         7\n",
      "         135       0.80      0.57      0.67         7\n",
      "         136       1.00      1.00      1.00         2\n",
      "         137       1.00      1.00      1.00         2\n",
      "         138       1.00      1.00      1.00         4\n",
      "         139       1.00      1.00      1.00         2\n",
      "         140       1.00      1.00      1.00         2\n",
      "         141       1.00      1.00      1.00         7\n",
      "         142       1.00      0.89      0.94         9\n",
      "         143       1.00      1.00      1.00         2\n",
      "         144       1.00      1.00      1.00         6\n",
      "         145       1.00      1.00      1.00         2\n",
      "         146       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.96       413\n",
      "   macro avg       0.97      0.97      0.96       413\n",
      "weighted avg       0.97      0.96      0.96       413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "r = classification_report(y_true=y_t, y_pred=p)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d97d5a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.43      0.55         7\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      0.83      0.91         6\n",
      "           3       1.00      0.60      0.75         5\n",
      "           4       1.00      0.80      0.89         5\n",
      "           5       0.40      0.50      0.44         4\n",
      "           6       0.71      1.00      0.83         5\n",
      "           7       0.80      1.00      0.89         4\n",
      "           8       1.00      0.50      0.67         4\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       0.04      1.00      0.09         3\n",
      "          12       0.05      1.00      0.09         3\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       1.00      0.50      0.67         4\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.75      1.00      0.86         3\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       1.00      1.00      1.00         3\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.75      1.00      0.86         3\n",
      "          22       0.67      1.00      0.80         2\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.75      1.00      0.86         3\n",
      "          26       0.75      1.00      0.86         3\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       0.18      1.00      0.30         3\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       0.25      1.00      0.40         3\n",
      "          31       0.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       0.00      0.00      0.00         3\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       0.00      0.00      0.00         2\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       0.50      0.50      0.50         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       1.00      0.50      0.67         2\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         2\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.50      0.50      0.50         2\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       0.00      0.00      0.00         2\n",
      "          61       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         1\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       0.50      1.00      0.67         1\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         2\n",
      "          77       1.00      1.00      1.00         1\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       0.50      1.00      0.67         1\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.50      1.00      0.67         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       1.00      1.00      1.00         1\n",
      "          89       0.00      0.00      0.00         2\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.67      1.00      0.80         2\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         1\n",
      "          94       0.33      1.00      0.50         1\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         2\n",
      "          99       0.00      0.00      0.00         1\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       1.00      1.00      1.00         2\n",
      "         104       0.00      0.00      0.00         2\n",
      "         105       0.00      0.00      0.00         2\n",
      "         106       0.50      0.33      0.40         3\n",
      "         107       0.75      1.00      0.86         3\n",
      "         108       0.50      1.00      0.67         2\n",
      "         109       0.67      1.00      0.80         2\n",
      "         110       0.00      0.00      0.00         4\n",
      "         111       0.75      0.75      0.75         4\n",
      "         112       1.00      1.00      1.00         2\n",
      "         113       0.00      0.00      0.00         3\n",
      "         114       0.50      1.00      0.67         2\n",
      "         115       1.00      0.14      0.25         7\n",
      "         116       0.00      0.00      0.00         2\n",
      "         117       1.00      1.00      1.00         4\n",
      "         118       0.00      0.00      0.00         4\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.00      0.00      0.00         4\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       1.00      0.57      0.73         7\n",
      "         123       0.86      1.00      0.92         6\n",
      "         124       0.00      0.00      0.00         6\n",
      "         125       0.00      0.00      0.00         2\n",
      "         126       0.80      1.00      0.89         4\n",
      "         127       0.88      1.00      0.93         7\n",
      "         128       1.00      0.80      0.89         5\n",
      "         129       1.00      1.00      1.00         3\n",
      "         130       0.00      0.00      0.00         3\n",
      "         131       1.00      0.80      0.89        10\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         5\n",
      "         134       0.00      0.00      0.00         7\n",
      "         135       0.00      0.00      0.00         7\n",
      "         136       0.00      0.00      0.00         2\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       0.00      0.00      0.00         4\n",
      "         139       1.00      1.00      1.00         2\n",
      "         140       0.00      0.00      0.00         2\n",
      "         141       1.00      0.29      0.44         7\n",
      "         142       0.50      0.11      0.18         9\n",
      "         143       1.00      1.00      1.00         2\n",
      "         144       1.00      0.83      0.91         6\n",
      "         145       0.00      0.00      0.00         2\n",
      "         146       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.45       413\n",
      "   macro avg       0.38      0.41      0.37       413\n",
      "weighted avg       0.46      0.45      0.42       413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_words = X_to_words(X_test, char_tokenizer)\n",
    "baseline_pred = [assign_bucket(word, buckets) for word in test_words]\n",
    "r = classification_report(y_true=y_t, y_pred=baseline_pred)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7140f78b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: flang\n",
      "['svang', 'tonetrang', 'jubelklang', 'rang', 'sang']\n",
      "\n",
      "Word: gorlang\n",
      "['svang', 'tonetrang', 'jubelklang', 'rang', 'sang']\n",
      "\n",
      "Word: blatt\n",
      "['tatt', 'natt', 'Natt', 'sommernatt', 'matt']\n",
      "\n",
      "Word: knatt\n",
      "['tatt', 'natt', 'Natt', 'sommernatt', 'matt']\n",
      "\n",
      "Word: pril\n",
      "['vil', 'bil', 'renkespill', 'fløytespill', 'il']\n",
      "\n",
      "Word: glunn\n",
      "['bunn', 'funn', 'flammemunn', 'odelsgrunn', 'kun']\n",
      "\n",
      "Word: svans\n",
      "['Sanktehans', 'seierskrans', 'Hans', 'stans', 'krans']\n",
      "\n",
      "Word: stritt\n",
      "['granitt', 'milevidt', 'fritt', 'lidt', 'profitt']\n",
      "\n",
      "Word: hjal\n",
      "['pral', 'gal', 'sjal', 'Cheval', 'ritual']\n",
      "\n",
      "Word: sta\n",
      "['glad', 'la', 'da', 'fra', 'gjenoppta']\n",
      "\n",
      "Word: plirk\n",
      "['ombord', 'ror', 'Eginafjord', 'varselsord', 'sjungekor']\n",
      "\n",
      "Word: coll\n",
      "['skjold', 'vold', 'fold', 'kold', 'gold']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_some_more = char_tokenizer.texts_to_sequences(some_more)\n",
    "test_some_more =  tf.keras.preprocessing.sequence.pad_sequences(test_some_more, maxlen=MAX_LEN, padding=\"post\", value=0) \n",
    "more_preds = model.predict(test_some_more)\n",
    "more_preds = np.argmax(more_preds, axis=1)\n",
    "\n",
    "for w, i in zip(some_more, more_preds):\n",
    "    print(f\"Word: {w}\")\n",
    "    print(buckets[i][:5])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ba1d9",
   "metadata": {},
   "source": [
    "# Wiktionary buckets\n",
    "Only use those with 5 or more words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db47e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/wiktionary_buckets_merge_almost_rhymes.pickle\", \"rb\") as f:\n",
    "    buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "128b4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 3), (2, 4), (3, 1), (4, 1), (12, 1), (15, 2), (16, 1), (17, 1), (28, 1), (37, 1), (42, 1), (48, 1), (49, 1), (68, 1), (80, 1), (87, 1), (90, 1), (119, 1), (140, 1), (306, 1), (310, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55.44444444444444, 17.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [len(b) for b in buckets]\n",
    "\n",
    "c = Counter(l)\n",
    "l2 = sorted(c.items(), key=lambda x: x[0])\n",
    "print(l2)\n",
    "np.mean(l), np.median(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b39c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_name = \"wiktionary_big_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a949a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = [b for b in buckets if len(b) > 4]\n",
    "bucket_vocab_size = len(buckets)\n",
    "bucket_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6b6abde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48.5, 82.16666666666667, 18)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [len(b) for b in buckets]\n",
    "np.median(l), np.mean(l), len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "555b6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_indexer = {w:i for i,b in enumerate(buckets) for w in b}\n",
    "\n",
    "# with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"wb+\") as f:\n",
    "#     pickle.dump(bucket_indexer, f)\n",
    "\n",
    "with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"rb\") as f:\n",
    "    bucket_indexer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aff46323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_indexer[buckets[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0642df05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1366"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = [w for w in bucket_indexer.keys()]\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ac577321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True, lower=True)\n",
    "# char_tokenizer.fit_on_texts(vocab)\n",
    "\n",
    "# tokenizer_config = char_tokenizer.to_json()\n",
    "# with open(f\"{buckets_name}_char_tokenizer_config.json\", 'w') as f:\n",
    "#     f.write(tokenizer_config)\n",
    "\n",
    "with open(f\"{buckets_name}_char_tokenizer_config.json\") as f:\n",
    "    tokenizer_config = f.read()\n",
    "\n",
    "char_tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8eef1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = buckets_to_data(vocab, char_tokenizer, bucket_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1f54307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1366, 60), (1366, 18))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc991064",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4050811f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((956, 60), (956, 18), (205, 60), (205, 18))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9704e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"rhyme_gen_wiktionary_big_5\"\n",
    "\n",
    "# # Uncomment to train\n",
    "# model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Embedding(input_dim=MAX_LEN, output_dim=128, mask_zero=True),\n",
    "#             tf.keras.layers.LSTM(units=128),\n",
    "#             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(bucket_vocab_size, activation=\"softmax\"),\n",
    "#         ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "# csv_logger = tf.keras.callbacks.CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=100,\n",
    "#                     validation_data = (X_dev, y_dev),\n",
    "#                     callbacks=[model_checkpoint, terminate_on_nan, early_stop, csv_logger])\n",
    "\n",
    "model = tf.keras.models.load_model(f\"models/{model_name}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f32676d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((205, 18), (205, 18))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "y_test.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7be02573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((205,), (205,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.argmax(preds, axis=1)\n",
    "y_t = np.argmax(y_test, axis=1)\n",
    "p.shape, y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27e350ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 of 18 buckets are missing from predictions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{len(set(y_t) - set(p))} of {len(set(y_t))} buckets are missing from predictions. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "172661c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       0.77      1.00      0.87        10\n",
      "           2       0.80      0.57      0.67         7\n",
      "           3       1.00      1.00      1.00         6\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       1.00      1.00      1.00        13\n",
      "           6       0.86      0.86      0.86         7\n",
      "           7       0.95      0.90      0.93        21\n",
      "           8       1.00      0.97      0.99        36\n",
      "           9       0.50      0.50      0.50         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         7\n",
      "          12       1.00      0.67      0.80         3\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       0.80      0.92      0.86        13\n",
      "          15       1.00      1.00      1.00         6\n",
      "          16       1.00      1.00      1.00        18\n",
      "          17       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       205\n",
      "   macro avg       0.93      0.91      0.91       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = classification_report(y_true=y_t, y_pred=p)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "327e4748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.50      0.33         2\n",
      "           1       0.44      0.40      0.42        10\n",
      "           2       0.35      1.00      0.52         7\n",
      "           3       1.00      1.00      1.00         6\n",
      "           4       0.90      0.57      0.69        46\n",
      "           5       0.50      0.08      0.13        13\n",
      "           6       0.62      0.71      0.67         7\n",
      "           7       0.78      1.00      0.88        21\n",
      "           8       0.83      0.94      0.88        36\n",
      "           9       0.50      1.00      0.67         2\n",
      "          10       0.17      0.50      0.25         2\n",
      "          11       0.64      1.00      0.78         7\n",
      "          12       0.38      1.00      0.55         3\n",
      "          13       0.57      1.00      0.73         4\n",
      "          14       0.00      0.00      0.00        13\n",
      "          15       0.86      1.00      0.92         6\n",
      "          16       0.80      0.44      0.57        18\n",
      "          17       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.67       205\n",
      "   macro avg       0.56      0.73      0.59       205\n",
      "weighted avg       0.69      0.67      0.64       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_words = X_to_words(X_test, char_tokenizer)\n",
    "baseline_pred = [assign_bucket(word, buckets) for word in test_words]\n",
    "r = classification_report(y_true=y_t, y_pred=baseline_pred)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b7f3cf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: flang\n",
      "['hasj', 'mars', 'stakkars', 'tsjuvasj', 'vintage']\n",
      "\n",
      "Word: gorlang\n",
      "['hasj', 'mars', 'stakkars', 'tsjuvasj', 'vintage']\n",
      "\n",
      "Word: blatt\n",
      "['firt', 'flirt', 'girt', 'glirt', 'hirt']\n",
      "\n",
      "Word: knatt\n",
      "['bært', 'fælt', 'gjært', 'hælt', 'kjælt']\n",
      "\n",
      "Word: pril\n",
      "['bil', 'fil', 'hvil', 'kil', 'kvil']\n",
      "\n",
      "Word: glunn\n",
      "['føn', 'gjøn', 'kjøn', 'skrøn', 'obskøn']\n",
      "\n",
      "Word: svans\n",
      "['føn', 'gjøn', 'kjøn', 'skrøn', 'obskøn']\n",
      "\n",
      "Word: stritt\n",
      "['firt', 'flirt', 'girt', 'glirt', 'hirt']\n",
      "\n",
      "Word: hjal\n",
      "['bil', 'fil', 'hvil', 'kil', 'kvil']\n",
      "\n",
      "Word: sta\n",
      "['bi', 'bli', 'blid', 'de', 'di']\n",
      "\n",
      "Word: plirk\n",
      "['hasj', 'mars', 'stakkars', 'tsjuvasj', 'vintage']\n",
      "\n",
      "Word: coll\n",
      "['bul', 'fugl', 'ful', 'gul', 'hjul']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_some_more = char_tokenizer.texts_to_sequences(some_more)\n",
    "test_some_more =  tf.keras.preprocessing.sequence.pad_sequences(test_some_more, maxlen=MAX_LEN, padding=\"post\", value=0) \n",
    "more_preds = model.predict(test_some_more)\n",
    "more_preds = np.argmax(more_preds, axis=1)\n",
    "\n",
    "for w, i in zip(some_more, more_preds):\n",
    "    print(f\"Word: {w}\")\n",
    "    print(buckets[i][:5])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a5962",
   "metadata": {},
   "source": [
    "# Merged buckets\n",
    "## All larger than 4\n",
    "Train size = 60 %  \n",
    "Dev, test = 20 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95202c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/merged_wiktionary_almost_rhyme_and_norsc_buckets.pickle','rb') as f:\n",
    "    buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cfc18b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = [b for b in buckets if len(b) > 4]\n",
    "bucket_vocab_size = len(buckets)\n",
    "bucket_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14a4e28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.0, 15.610271903323262)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [len(b) for b in buckets]\n",
    "np.median(l), np.mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f12e75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_name = \"merged_big_4\"\n",
    "\n",
    "# bucket_indexer = {w:i for i,b in enumerate(buckets) for w in b}\n",
    "\n",
    "# with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"wb+\") as f:\n",
    "#     pickle.dump(bucket_indexer, f)\n",
    "\n",
    "with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"rb\") as f:\n",
    "    bucket_indexer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2490032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_indexer[buckets[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e94586e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5162"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(bucket_indexer.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39be52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True, lower=True)\n",
    "# char_tokenizer.fit_on_texts(vocab)\n",
    "\n",
    "# tokenizer_config = char_tokenizer.to_json()\n",
    "# with open(f\"{buckets_name}_char_tokenizer_config.json\", 'w') as f:\n",
    "#     f.write(tokenizer_config)\n",
    "buckets_name = \"merged_big_4\"\n",
    "\n",
    "with open(f\"{buckets_name}_char_tokenizer_config.json\") as f:\n",
    "    tokenizer_config = f.read()\n",
    "\n",
    "char_tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b0604fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5162, 60), (5162, 331))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = buckets_to_data(vocab, char_tokenizer, bucket_indexer)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3635fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y, random_state=SEED)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1cf7797e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3097, 60), (1032, 60), (1033, 60))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_dev.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6c3ee879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"rhyme_gen_merged_big_4\"\n",
    "\n",
    "# # # Uncomment to train\n",
    "# model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Embedding(input_dim=MAX_LEN, output_dim=128, mask_zero=True),\n",
    "#             tf.keras.layers.LSTM(units=128),\n",
    "#             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(bucket_vocab_size, activation=\"softmax\"),\n",
    "#         ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "# csv_logger = tf.keras.callbacks.CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=100,\n",
    "#                     validation_data = (X_dev, y_dev),\n",
    "#                     callbacks=[model_checkpoint, terminate_on_nan, early_stop, csv_logger])\n",
    "\n",
    "model = tf.keras.models.load_model(f\"models/{model_name}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4ad7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "p = np.argmax(preds, axis=1)\n",
    "y_t = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad551c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13 of 331 buckets are missing from predictions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{len(set(y_t))-len(set(p))} of {len(set(y_t))} buckets are missing from predictions. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e655927b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       0.93      1.00      0.97        28\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       0.80      1.00      0.89         8\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        10\n",
      "           8       1.00      1.00      1.00         9\n",
      "           9       1.00      1.00      1.00         8\n",
      "          10       1.00      1.00      1.00         7\n",
      "          11       1.00      0.86      0.92         7\n",
      "          12       1.00      1.00      1.00         6\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       1.00      0.80      0.89         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         5\n",
      "          17       1.00      0.80      0.89         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      1.00      1.00         5\n",
      "          20       1.00      1.00      1.00         5\n",
      "          21       1.00      1.00      1.00         5\n",
      "          22       0.71      1.00      0.83         5\n",
      "          23       1.00      1.00      1.00         5\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       1.00      1.00      1.00         4\n",
      "          26       1.00      1.00      1.00         4\n",
      "          27       1.00      1.00      1.00         4\n",
      "          28       1.00      1.00      1.00         4\n",
      "          29       1.00      1.00      1.00         4\n",
      "          30       0.50      1.00      0.67         4\n",
      "          31       0.80      1.00      0.89         4\n",
      "          32       0.80      1.00      0.89         4\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       1.00      1.00      1.00         3\n",
      "          36       1.00      1.00      1.00         4\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       1.00      1.00      1.00         3\n",
      "          39       1.00      1.00      1.00         3\n",
      "          40       1.00      1.00      1.00         3\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       1.00      1.00      1.00         3\n",
      "          45       1.00      0.67      0.80         3\n",
      "          46       1.00      1.00      1.00         3\n",
      "          47       0.60      1.00      0.75         3\n",
      "          48       1.00      1.00      1.00         3\n",
      "          49       1.00      1.00      1.00         3\n",
      "          50       1.00      1.00      1.00         3\n",
      "          51       1.00      1.00      1.00         3\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         3\n",
      "          54       1.00      1.00      1.00         3\n",
      "          55       1.00      1.00      1.00         3\n",
      "          56       1.00      1.00      1.00         3\n",
      "          57       1.00      1.00      1.00         3\n",
      "          58       1.00      1.00      1.00         3\n",
      "          59       0.75      1.00      0.86         3\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         3\n",
      "          62       1.00      1.00      1.00         3\n",
      "          63       0.75      1.00      0.86         3\n",
      "          64       1.00      1.00      1.00         3\n",
      "          65       1.00      1.00      1.00         3\n",
      "          66       1.00      0.50      0.67         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      0.50      0.67         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       0.67      1.00      0.80         2\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       1.00      1.00      1.00         2\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       1.00      1.00      1.00         2\n",
      "          87       0.67      1.00      0.80         2\n",
      "          88       0.67      1.00      0.80         2\n",
      "          89       1.00      1.00      1.00         2\n",
      "          90       1.00      1.00      1.00         2\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       0.67      1.00      0.80         2\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       1.00      1.00      1.00         2\n",
      "          99       1.00      1.00      1.00         2\n",
      "         100       1.00      1.00      1.00         2\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       1.00      1.00      1.00         2\n",
      "         103       1.00      1.00      1.00         2\n",
      "         104       0.67      1.00      0.80         2\n",
      "         105       1.00      1.00      1.00         2\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       1.00      1.00      1.00         1\n",
      "         108       1.00      1.00      1.00         1\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       1.00      1.00      1.00         1\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       1.00      1.00      1.00         1\n",
      "         115       1.00      1.00      1.00         1\n",
      "         116       1.00      1.00      1.00         1\n",
      "         117       1.00      1.00      1.00         1\n",
      "         118       1.00      1.00      1.00         1\n",
      "         119       1.00      1.00      1.00         1\n",
      "         120       1.00      1.00      1.00         1\n",
      "         121       1.00      1.00      1.00         1\n",
      "         122       1.00      1.00      1.00         1\n",
      "         123       1.00      1.00      1.00         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       1.00      1.00      1.00         1\n",
      "         126       1.00      1.00      1.00         1\n",
      "         127       1.00      1.00      1.00         1\n",
      "         128       1.00      1.00      1.00         1\n",
      "         129       1.00      1.00      1.00         1\n",
      "         130       1.00      1.00      1.00         1\n",
      "         131       0.50      1.00      0.67         1\n",
      "         132       1.00      1.00      1.00         1\n",
      "         133       1.00      1.00      1.00         1\n",
      "         134       1.00      1.00      1.00         1\n",
      "         135       1.00      1.00      1.00         1\n",
      "         136       1.00      1.00      1.00         1\n",
      "         137       1.00      1.00      1.00         1\n",
      "         138       1.00      1.00      1.00         1\n",
      "         139       1.00      1.00      1.00         1\n",
      "         140       1.00      1.00      1.00         1\n",
      "         141       1.00      1.00      1.00         1\n",
      "         142       1.00      1.00      1.00         1\n",
      "         143       1.00      1.00      1.00         1\n",
      "         144       1.00      1.00      1.00         1\n",
      "         145       1.00      1.00      1.00         1\n",
      "         146       1.00      1.00      1.00         1\n",
      "         147       1.00      1.00      1.00         1\n",
      "         148       1.00      1.00      1.00         1\n",
      "         149       1.00      1.00      1.00         1\n",
      "         150       1.00      1.00      1.00         1\n",
      "         151       1.00      1.00      1.00         1\n",
      "         152       1.00      1.00      1.00         1\n",
      "         153       1.00      1.00      1.00         1\n",
      "         154       1.00      1.00      1.00         1\n",
      "         155       1.00      1.00      1.00         1\n",
      "         156       1.00      1.00      1.00         1\n",
      "         157       1.00      1.00      1.00         1\n",
      "         158       0.50      1.00      0.67         1\n",
      "         159       1.00      1.00      1.00         1\n",
      "         160       0.50      1.00      0.67         1\n",
      "         161       1.00      1.00      1.00         1\n",
      "         162       1.00      1.00      1.00         1\n",
      "         163       1.00      1.00      1.00         1\n",
      "         164       0.50      1.00      0.67         1\n",
      "         165       1.00      1.00      1.00         1\n",
      "         166       1.00      1.00      1.00         1\n",
      "         167       1.00      1.00      1.00         1\n",
      "         168       1.00      1.00      1.00         1\n",
      "         169       1.00      1.00      1.00         1\n",
      "         170       0.50      1.00      0.67         1\n",
      "         171       0.00      0.00      0.00         1\n",
      "         172       1.00      1.00      1.00         1\n",
      "         173       1.00      1.00      1.00         1\n",
      "         174       1.00      1.00      1.00         1\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.50      1.00      0.67         1\n",
      "         177       1.00      1.00      1.00         1\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       1.00      1.00      1.00         1\n",
      "         181       1.00      1.00      1.00         1\n",
      "         182       1.00      1.00      1.00         1\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       1.00      1.00      1.00         1\n",
      "         185       1.00      1.00      1.00         1\n",
      "         186       1.00      1.00      1.00         1\n",
      "         187       1.00      1.00      1.00         1\n",
      "         188       0.50      1.00      0.67         1\n",
      "         189       0.50      1.00      0.67         1\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       1.00      1.00      1.00         1\n",
      "         192       1.00      1.00      1.00         1\n",
      "         193       1.00      1.00      1.00         1\n",
      "         194       1.00      1.00      1.00         1\n",
      "         195       1.00      1.00      1.00         1\n",
      "         196       0.50      1.00      0.67         1\n",
      "         197       1.00      1.00      1.00         1\n",
      "         198       1.00      1.00      1.00         1\n",
      "         199       1.00      1.00      1.00         1\n",
      "         200       0.00      0.00      0.00         1\n",
      "         201       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       1.00      1.00      1.00         1\n",
      "         204       1.00      1.00      1.00         1\n",
      "         205       1.00      1.00      1.00         1\n",
      "         206       1.00      1.00      1.00         1\n",
      "         207       1.00      1.00      1.00         1\n",
      "         208       1.00      1.00      1.00         1\n",
      "         209       1.00      1.00      1.00         1\n",
      "         210       1.00      1.00      1.00         1\n",
      "         211       1.00      1.00      1.00         1\n",
      "         212       1.00      1.00      1.00         1\n",
      "         213       1.00      1.00      1.00         1\n",
      "         214       1.00      1.00      1.00         1\n",
      "         215       1.00      1.00      1.00         1\n",
      "         216       1.00      1.00      1.00         1\n",
      "         217       0.50      1.00      0.67         1\n",
      "         218       1.00      1.00      1.00         1\n",
      "         219       1.00      1.00      1.00         1\n",
      "         220       0.50      1.00      0.67         1\n",
      "         221       1.00      1.00      1.00         1\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       1.00      1.00      1.00         1\n",
      "         224       1.00      1.00      1.00         1\n",
      "         225       1.00      1.00      1.00         1\n",
      "         226       1.00      1.00      1.00         1\n",
      "         227       1.00      1.00      1.00         1\n",
      "         228       1.00      1.00      1.00         1\n",
      "         229       1.00      1.00      1.00         1\n",
      "         230       1.00      1.00      1.00         1\n",
      "         231       1.00      1.00      1.00         1\n",
      "         232       1.00      1.00      1.00         1\n",
      "         233       1.00      1.00      1.00         1\n",
      "         234       1.00      1.00      1.00         1\n",
      "         235       1.00      1.00      1.00         1\n",
      "         236       1.00      1.00      1.00         1\n",
      "         237       1.00      1.00      1.00         1\n",
      "         238       1.00      1.00      1.00         1\n",
      "         239       1.00      1.00      1.00         1\n",
      "         240       1.00      1.00      1.00         1\n",
      "         241       1.00      1.00      1.00         1\n",
      "         242       0.00      0.00      0.00         1\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       1.00      1.00      1.00         2\n",
      "         245       1.00      1.00      1.00         3\n",
      "         246       0.00      0.00      0.00         1\n",
      "         247       1.00      1.00      1.00         1\n",
      "         248       1.00      1.00      1.00         2\n",
      "         249       1.00      1.00      1.00         1\n",
      "         250       1.00      1.00      1.00         2\n",
      "         251       1.00      1.00      1.00         3\n",
      "         252       1.00      1.00      1.00         1\n",
      "         253       1.00      1.00      1.00         2\n",
      "         254       1.00      1.00      1.00         2\n",
      "         255       1.00      1.00      1.00         3\n",
      "         256       1.00      1.00      1.00         2\n",
      "         257       0.00      0.00      0.00         3\n",
      "         258       0.25      1.00      0.40         1\n",
      "         259       1.00      1.00      1.00         2\n",
      "         260       1.00      1.00      1.00         3\n",
      "         261       1.00      1.00      1.00         3\n",
      "         262       1.00      1.00      1.00         3\n",
      "         263       0.80      1.00      0.89         4\n",
      "         264       1.00      1.00      1.00         1\n",
      "         265       1.00      1.00      1.00         5\n",
      "         266       0.00      0.00      0.00         1\n",
      "         267       0.67      1.00      0.80         2\n",
      "         268       1.00      1.00      1.00         2\n",
      "         269       1.00      1.00      1.00         4\n",
      "         270       0.83      1.00      0.91         5\n",
      "         271       1.00      1.00      1.00         4\n",
      "         272       1.00      1.00      1.00         5\n",
      "         273       1.00      1.00      1.00         3\n",
      "         274       1.00      1.00      1.00         2\n",
      "         275       1.00      1.00      1.00         1\n",
      "         276       1.00      1.00      1.00         3\n",
      "         277       1.00      1.00      1.00        10\n",
      "         278       1.00      1.00      1.00         2\n",
      "         279       1.00      0.80      0.89         5\n",
      "         280       1.00      1.00      1.00         5\n",
      "         281       1.00      1.00      1.00         3\n",
      "         282       1.00      0.50      0.67         6\n",
      "         283       1.00      1.00      1.00         4\n",
      "         284       1.00      1.00      1.00         2\n",
      "         285       1.00      1.00      1.00         1\n",
      "         286       0.83      1.00      0.91        10\n",
      "         287       0.00      0.00      0.00         2\n",
      "         288       1.00      1.00      1.00         1\n",
      "         289       1.00      1.00      1.00         3\n",
      "         290       1.00      0.89      0.94         9\n",
      "         291       1.00      1.00      1.00         7\n",
      "         292       1.00      1.00      1.00         8\n",
      "         293       0.60      0.75      0.67         4\n",
      "         294       1.00      0.67      0.80         6\n",
      "         295       1.00      0.89      0.94         9\n",
      "         296       0.50      1.00      0.67         1\n",
      "         297       1.00      1.00      1.00         1\n",
      "         298       0.50      1.00      0.67         1\n",
      "         299       1.00      0.71      0.83         7\n",
      "         300       1.00      1.00      1.00         1\n",
      "         301       0.80      1.00      0.89         4\n",
      "         302       1.00      1.00      1.00         2\n",
      "         303       1.00      1.00      1.00         2\n",
      "         304       0.33      1.00      0.50         1\n",
      "         305       1.00      1.00      1.00         4\n",
      "         306       1.00      1.00      1.00         3\n",
      "         307       1.00      0.80      0.89        10\n",
      "         308       1.00      0.60      0.75         5\n",
      "         309       1.00      1.00      1.00         1\n",
      "         310       1.00      1.00      1.00         3\n",
      "         311       1.00      1.00      1.00        12\n",
      "         312       1.00      0.90      0.95        10\n",
      "         313       0.75      1.00      0.86         3\n",
      "         314       1.00      0.67      0.80         9\n",
      "         315       1.00      0.67      0.80         6\n",
      "         316       1.00      1.00      1.00         3\n",
      "         317       1.00      1.00      1.00         1\n",
      "         318       1.00      1.00      1.00         3\n",
      "         319       0.80      0.80      0.80         5\n",
      "         320       0.45      0.50      0.48        10\n",
      "         321       0.69      0.61      0.65        18\n",
      "         322       1.00      0.95      0.97        20\n",
      "         323       0.96      0.98      0.97        51\n",
      "         324       0.82      0.74      0.78        19\n",
      "         325       1.00      1.00      1.00         4\n",
      "         326       1.00      1.00      1.00         7\n",
      "         327       1.00      1.00      1.00        65\n",
      "         328       1.00      1.00      1.00        24\n",
      "         329       1.00      0.86      0.92        14\n",
      "         330       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.93      1033\n",
      "   macro avg       0.91      0.93      0.91      1033\n",
      "weighted avg       0.93      0.93      0.93      1033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "r = classification_report(y_true=y_t, y_pred=p)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5dc36b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       0.82      1.00      0.90        28\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      0.40      0.57        10\n",
      "           8       1.00      1.00      1.00         9\n",
      "           9       1.00      0.62      0.77         8\n",
      "          10       1.00      0.29      0.44         7\n",
      "          11       1.00      0.43      0.60         7\n",
      "          12       0.86      1.00      0.92         6\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       1.00      0.60      0.75         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       0.83      1.00      0.91         5\n",
      "          17       0.04      1.00      0.07         5\n",
      "          18       0.04      1.00      0.07         5\n",
      "          19       0.00      0.00      0.00         5\n",
      "          20       0.67      0.40      0.50         5\n",
      "          21       1.00      0.80      0.89         5\n",
      "          22       0.83      1.00      0.91         5\n",
      "          23       0.03      0.20      0.05         5\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.80      1.00      0.89         4\n",
      "          26       0.00      0.00      0.00         4\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       1.00      1.00      1.00         4\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       1.00      1.00      1.00         4\n",
      "          32       0.00      0.00      0.00         4\n",
      "          33       0.08      1.00      0.15         3\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       0.00      0.00      0.00         3\n",
      "          36       0.00      0.00      0.00         4\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       1.00      1.00      1.00         3\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       1.00      1.00      1.00         3\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.00      0.00      0.00         3\n",
      "          47       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         3\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.75      1.00      0.86         3\n",
      "          51       1.00      1.00      1.00         3\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         3\n",
      "          54       0.00      0.00      0.00         3\n",
      "          55       0.00      0.00      0.00         3\n",
      "          56       0.75      1.00      0.86         3\n",
      "          57       0.75      1.00      0.86         3\n",
      "          58       0.00      0.00      0.00         3\n",
      "          59       0.17      0.33      0.22         3\n",
      "          60       0.00      0.00      0.00         2\n",
      "          61       0.67      0.67      0.67         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       1.00      1.00      1.00         3\n",
      "          64       1.00      1.00      1.00         3\n",
      "          65       0.00      0.00      0.00         3\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       0.67      1.00      0.80         2\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         2\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       0.67      1.00      0.80         2\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         2\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       0.67      1.00      0.80         2\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.00      0.00      0.00         2\n",
      "          89       0.00      0.00      0.00         2\n",
      "          90       1.00      1.00      1.00         2\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.67      1.00      0.80         2\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         2\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         2\n",
      "          99       1.00      1.00      1.00         2\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.00      0.00      0.00         2\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       1.00      1.00      1.00         2\n",
      "         105       1.00      1.00      1.00         2\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       1.00      1.00      1.00         1\n",
      "         126       0.50      1.00      0.67         1\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       1.00      1.00      1.00         1\n",
      "         129       0.00      0.00      0.00         1\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         1\n",
      "         132       0.00      0.00      0.00         1\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         1\n",
      "         136       1.00      1.00      1.00         1\n",
      "         137       0.20      1.00      0.33         1\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       1.00      1.00      1.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         150       0.00      0.00      0.00         1\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       1.00      1.00      1.00         1\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       1.00      1.00      1.00         1\n",
      "         159       0.25      1.00      0.40         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         1\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         1\n",
      "         167       0.00      0.00      0.00         1\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         1\n",
      "         170       0.50      1.00      0.67         1\n",
      "         171       1.00      1.00      1.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.17      1.00      0.29         1\n",
      "         174       1.00      1.00      1.00         1\n",
      "         175       1.00      1.00      1.00         1\n",
      "         176       0.00      0.00      0.00         1\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       0.50      1.00      0.67         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       1.00      1.00      1.00         1\n",
      "         181       0.00      0.00      0.00         1\n",
      "         182       1.00      1.00      1.00         1\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         1\n",
      "         186       1.00      1.00      1.00         1\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       0.00      0.00      0.00         1\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         1\n",
      "         192       0.00      0.00      0.00         1\n",
      "         193       0.00      0.00      0.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         1\n",
      "         196       1.00      1.00      1.00         1\n",
      "         197       0.00      0.00      0.00         1\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       1.00      1.00      1.00         1\n",
      "         200       0.00      0.00      0.00         1\n",
      "         201       0.50      1.00      0.67         1\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         1\n",
      "         204       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         1\n",
      "         208       1.00      1.00      1.00         1\n",
      "         209       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00         1\n",
      "         211       0.00      0.00      0.00         1\n",
      "         212       0.03      1.00      0.05         1\n",
      "         213       0.00      0.00      0.00         1\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       0.00      0.00      0.00         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         1\n",
      "         220       0.00      0.00      0.00         1\n",
      "         221       0.00      0.00      0.00         1\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       0.50      1.00      0.67         1\n",
      "         224       0.00      0.00      0.00         1\n",
      "         225       1.00      1.00      1.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.50      1.00      0.67         1\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         1\n",
      "         231       0.00      0.00      0.00         1\n",
      "         232       0.00      0.00      0.00         1\n",
      "         233       0.33      1.00      0.50         1\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         1\n",
      "         238       0.50      1.00      0.67         1\n",
      "         239       0.00      0.00      0.00         1\n",
      "         240       0.00      0.00      0.00         1\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       0.50      1.00      0.67         1\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         2\n",
      "         245       0.00      0.00      0.00         3\n",
      "         246       0.00      0.00      0.00         1\n",
      "         247       1.00      1.00      1.00         1\n",
      "         248       0.00      0.00      0.00         2\n",
      "         249       0.00      0.00      0.00         1\n",
      "         250       0.00      0.00      0.00         2\n",
      "         251       0.00      0.00      0.00         3\n",
      "         252       0.00      0.00      0.00         1\n",
      "         253       0.00      0.00      0.00         2\n",
      "         254       0.00      0.00      0.00         2\n",
      "         255       0.00      0.00      0.00         3\n",
      "         256       0.00      0.00      0.00         2\n",
      "         257       1.00      1.00      1.00         3\n",
      "         258       1.00      1.00      1.00         1\n",
      "         259       0.00      0.00      0.00         2\n",
      "         260       1.00      1.00      1.00         3\n",
      "         261       0.00      0.00      0.00         3\n",
      "         262       0.00      0.00      0.00         3\n",
      "         263       1.00      0.50      0.67         4\n",
      "         264       0.00      0.00      0.00         1\n",
      "         265       1.00      1.00      1.00         5\n",
      "         266       0.00      0.00      0.00         1\n",
      "         267       1.00      1.00      1.00         2\n",
      "         268       0.00      0.00      0.00         2\n",
      "         269       1.00      1.00      1.00         4\n",
      "         270       0.00      0.00      0.00         5\n",
      "         271       1.00      1.00      1.00         4\n",
      "         272       0.83      1.00      0.91         5\n",
      "         273       1.00      1.00      1.00         3\n",
      "         274       1.00      1.00      1.00         2\n",
      "         275       1.00      1.00      1.00         1\n",
      "         276       1.00      1.00      1.00         3\n",
      "         277       1.00      0.90      0.95        10\n",
      "         278       0.00      0.00      0.00         2\n",
      "         279       1.00      0.80      0.89         5\n",
      "         280       1.00      1.00      1.00         5\n",
      "         281       0.75      1.00      0.86         3\n",
      "         282       0.00      0.00      0.00         6\n",
      "         283       1.00      1.00      1.00         4\n",
      "         284       0.00      0.00      0.00         2\n",
      "         285       0.00      0.00      0.00         1\n",
      "         286       1.00      0.60      0.75        10\n",
      "         287       0.00      0.00      0.00         2\n",
      "         288       0.00      0.00      0.00         1\n",
      "         289       1.00      1.00      1.00         3\n",
      "         290       1.00      1.00      1.00         9\n",
      "         291       0.00      0.00      0.00         7\n",
      "         292       1.00      1.00      1.00         8\n",
      "         293       1.00      1.00      1.00         4\n",
      "         294       0.86      1.00      0.92         6\n",
      "         295       1.00      0.89      0.94         9\n",
      "         296       0.00      0.00      0.00         1\n",
      "         297       1.00      1.00      1.00         1\n",
      "         298       0.50      1.00      0.67         1\n",
      "         299       0.83      0.71      0.77         7\n",
      "         300       0.00      0.00      0.00         1\n",
      "         301       0.00      0.00      0.00         4\n",
      "         302       0.00      0.00      0.00         2\n",
      "         303       0.00      0.00      0.00         2\n",
      "         304       0.00      0.00      0.00         1\n",
      "         305       0.00      0.00      0.00         4\n",
      "         306       0.00      0.00      0.00         3\n",
      "         307       1.00      0.70      0.82        10\n",
      "         308       0.00      0.00      0.00         5\n",
      "         309       1.00      1.00      1.00         1\n",
      "         310       0.00      0.00      0.00         3\n",
      "         311       1.00      0.50      0.67        12\n",
      "         312       0.83      0.50      0.62        10\n",
      "         313       0.75      1.00      0.86         3\n",
      "         314       0.67      0.22      0.33         9\n",
      "         315       0.00      0.00      0.00         6\n",
      "         316       0.00      0.00      0.00         3\n",
      "         317       0.00      0.00      0.00         1\n",
      "         318       1.00      1.00      1.00         3\n",
      "         319       0.04      0.40      0.07         5\n",
      "         320       0.36      1.00      0.53        10\n",
      "         321       0.00      0.00      0.00        18\n",
      "         322       1.00      0.90      0.95        20\n",
      "         323       0.00      0.00      0.00        51\n",
      "         324       0.00      0.00      0.00        19\n",
      "         325       0.67      0.50      0.57         4\n",
      "         326       0.88      1.00      0.93         7\n",
      "         327       0.00      0.00      0.00        65\n",
      "         328       0.92      0.50      0.65        24\n",
      "         329       1.00      0.50      0.67        14\n",
      "         330       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.43      1033\n",
      "   macro avg       0.33      0.36      0.33      1033\n",
      "weighted avg       0.45      0.43      0.42      1033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_words = X_to_words(X_test, char_tokenizer)\n",
    "baseline_pred = [assign_bucket(word, buckets) for word in test_words]\n",
    "r = classification_report(y_true=y_t, y_pred=baseline_pred)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "64f1ad13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: flang\n",
      "['trang', 'vingefang', 'opprørstrang', 'kjøkkengang', 'sprang']\n",
      "\n",
      "Word: gorlang\n",
      "['trang', 'vingefang', 'opprørstrang', 'kjøkkengang', 'sprang']\n",
      "\n",
      "Word: blatt\n",
      "['vinter-natt', 'betatt', 'satt', 'glatt', 'fatt']\n",
      "\n",
      "Word: knatt\n",
      "['vinter-natt', 'betatt', 'satt', 'glatt', 'fatt']\n",
      "\n",
      "Word: pril\n",
      "['halofil', 'bussfil', 'vegetabil', 'femmil', 'postill']\n",
      "\n",
      "Word: glunn\n",
      "['munn', 'blomstergrunn', 'offerlund', 'barne-munn', 'sekund']\n",
      "\n",
      "Word: svans\n",
      "['solskinnsglans', 'vanns', 'krans', 'Hans', 'blomsterkrans']\n",
      "\n",
      "Word: stritt\n",
      "['milevidt', 'kreditt', 'granitt', 'hvitt', 'mareritt']\n",
      "\n",
      "Word: hjal\n",
      "['sjal', 'kanal', 'Kal', 'ritual', 'smal']\n",
      "\n",
      "Word: sta\n",
      "['Antiokia', 'fra', 'ja', 'hurra', 'ta']\n",
      "\n",
      "Word: plirk\n",
      "['mystikk', 'leskedrikk', 'stikk', 'politikk', 'forgikk']\n",
      "\n",
      "Word: coll\n",
      "['full', 'tankefull', 'fortrøstningsfull', 'hull', 'kull']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_some_more = char_tokenizer.texts_to_sequences(some_more)\n",
    "test_some_more =  tf.keras.preprocessing.sequence.pad_sequences(test_some_more, maxlen=MAX_LEN, padding=\"post\", value=0) \n",
    "more_preds = model.predict(test_some_more)\n",
    "more_preds = np.argmax(more_preds, axis=1)\n",
    "\n",
    "for w, i in zip(some_more, more_preds):\n",
    "    print(f\"Word: {w}\")\n",
    "    print(buckets[i][:5])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa2853",
   "metadata": {},
   "source": [
    "## All larger than 5\n",
    "Train size = 70%  \n",
    "Dev, test = 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fe3744aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/merged_wiktionary_almost_rhyme_and_norsc_buckets.pickle','rb') as f:\n",
    "    buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b9a8c3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = [list(b) for b in buckets if len(b) > 5]\n",
    "bucket_vocab_size = len(buckets)\n",
    "bucket_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ac4b5d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.0, 17.40989399293286)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [len(b) for b in buckets]\n",
    "np.median(l), np.mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "176970f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_name = \"merged_big_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d35c63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_indexer = {w:i for i,b in enumerate(buckets) for w in b}\n",
    "\n",
    "# with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"wb+\") as f:\n",
    "#     pickle.dump(bucket_indexer, f)\n",
    "\n",
    "with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"rb\") as f:\n",
    "    bucket_indexer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7d7cd646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_indexer[buckets[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "20073454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4922"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(bucket_indexer.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8c2cb1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4922, 60), (4922, 283))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = buckets_to_data(vocab, char_tokenizer, bucket_indexer)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0d8fb09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bbd04279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"rhyme_gen_merged_big_5\"\n",
    "\n",
    "# # Uncomment to train\n",
    "# model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Embedding(input_dim=MAX_LEN, output_dim=128, mask_zero=True),\n",
    "#             tf.keras.layers.LSTM(units=128),\n",
    "#             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(bucket_vocab_size, activation=\"softmax\"),\n",
    "#         ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "# csv_logger = tf.keras.callbacks.CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=100,\n",
    "#                     validation_data = (X_dev, y_dev),\n",
    "#                     callbacks=[model_checkpoint, terminate_on_nan, early_stop, csv_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1866785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"models/{model_name}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fcd5a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d597707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((739,), (739,))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.argmax(preds, axis=1)\n",
    "y_t = np.argmax(y_test, axis=1)\n",
    "p.shape, y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "050f2662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6 of 283 buckets are missing from predictions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{len(set(y_t))-len(set(p))} of {len(set(y_t))} buckets are missing from predictions. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "92d69635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       0.86      0.90      0.88        21\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         8\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         6\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      0.50      0.67         4\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       1.00      1.00      1.00         4\n",
      "          19       1.00      1.00      1.00         4\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       1.00      1.00      1.00         3\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         3\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       0.75      1.00      0.86         3\n",
      "          30       1.00      0.33      0.50         3\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       1.00      1.00      1.00         3\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       1.00      1.00      1.00         3\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         3\n",
      "          39       1.00      1.00      1.00         3\n",
      "          40       1.00      1.00      1.00         2\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       1.00      0.50      0.67         2\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      0.50      0.67         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      0.50      0.67         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       1.00      1.00      1.00         1\n",
      "          67       1.00      1.00      1.00         1\n",
      "          68       1.00      1.00      1.00         1\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       1.00      1.00      1.00         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       1.00      1.00      1.00         1\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       0.50      1.00      0.67         1\n",
      "          77       1.00      1.00      1.00         1\n",
      "          78       1.00      1.00      1.00         1\n",
      "          79       1.00      1.00      1.00         1\n",
      "          80       1.00      1.00      1.00         1\n",
      "          81       1.00      1.00      1.00         1\n",
      "          82       1.00      1.00      1.00         1\n",
      "          83       1.00      1.00      1.00         1\n",
      "          84       1.00      1.00      1.00         1\n",
      "          85       1.00      1.00      1.00         1\n",
      "          86       1.00      1.00      1.00         1\n",
      "          87       1.00      1.00      1.00         1\n",
      "          88       0.50      1.00      0.67         1\n",
      "          89       0.50      1.00      0.67         1\n",
      "          90       1.00      1.00      1.00         1\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         1\n",
      "          93       1.00      1.00      1.00         1\n",
      "          94       1.00      1.00      1.00         1\n",
      "          95       1.00      1.00      1.00         1\n",
      "          96       1.00      1.00      1.00         1\n",
      "          97       1.00      1.00      1.00         1\n",
      "          98       1.00      1.00      1.00         1\n",
      "          99       1.00      1.00      1.00         1\n",
      "         100       1.00      1.00      1.00         1\n",
      "         101       1.00      1.00      1.00         1\n",
      "         102       1.00      1.00      1.00         1\n",
      "         103       1.00      1.00      1.00         1\n",
      "         104       1.00      1.00      1.00         1\n",
      "         105       1.00      1.00      1.00         1\n",
      "         106       1.00      1.00      1.00         1\n",
      "         107       1.00      1.00      1.00         1\n",
      "         108       0.33      1.00      0.50         1\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       1.00      1.00      1.00         1\n",
      "         111       1.00      1.00      1.00         1\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       1.00      1.00      1.00         1\n",
      "         114       1.00      1.00      1.00         1\n",
      "         115       1.00      1.00      1.00         1\n",
      "         116       1.00      1.00      1.00         1\n",
      "         117       1.00      1.00      1.00         1\n",
      "         118       0.50      1.00      0.67         1\n",
      "         119       0.50      1.00      0.67         1\n",
      "         120       1.00      1.00      1.00         1\n",
      "         121       1.00      1.00      1.00         1\n",
      "         122       1.00      1.00      1.00         1\n",
      "         123       1.00      1.00      1.00         1\n",
      "         124       1.00      1.00      1.00         1\n",
      "         125       1.00      1.00      1.00         1\n",
      "         126       1.00      1.00      1.00         1\n",
      "         127       1.00      1.00      1.00         1\n",
      "         128       1.00      1.00      1.00         1\n",
      "         129       1.00      1.00      1.00         1\n",
      "         130       1.00      1.00      1.00         1\n",
      "         131       1.00      1.00      1.00         1\n",
      "         132       0.00      0.00      0.00         1\n",
      "         133       1.00      1.00      1.00         1\n",
      "         134       1.00      1.00      1.00         1\n",
      "         135       1.00      1.00      1.00         1\n",
      "         136       1.00      1.00      1.00         1\n",
      "         137       1.00      1.00      1.00         1\n",
      "         138       1.00      1.00      1.00         1\n",
      "         139       1.00      1.00      1.00         1\n",
      "         140       1.00      1.00      1.00         1\n",
      "         141       1.00      1.00      1.00         1\n",
      "         142       1.00      1.00      1.00         1\n",
      "         143       1.00      1.00      1.00         1\n",
      "         144       1.00      1.00      1.00         1\n",
      "         145       1.00      1.00      1.00         1\n",
      "         146       1.00      1.00      1.00         1\n",
      "         147       1.00      1.00      1.00         1\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       1.00      1.00      1.00         1\n",
      "         150       1.00      1.00      1.00         1\n",
      "         151       1.00      1.00      1.00         1\n",
      "         152       0.50      1.00      0.67         1\n",
      "         153       1.00      1.00      1.00         1\n",
      "         154       1.00      1.00      1.00         1\n",
      "         155       1.00      1.00      1.00         1\n",
      "         156       1.00      1.00      1.00         1\n",
      "         157       1.00      1.00      1.00         1\n",
      "         158       1.00      1.00      1.00         1\n",
      "         159       1.00      1.00      1.00         1\n",
      "         160       0.50      1.00      0.67         1\n",
      "         161       1.00      1.00      1.00         1\n",
      "         162       1.00      1.00      1.00         1\n",
      "         163       0.50      1.00      0.67         1\n",
      "         164       1.00      1.00      1.00         1\n",
      "         165       1.00      1.00      1.00         1\n",
      "         166       1.00      1.00      1.00         1\n",
      "         167       1.00      1.00      1.00         1\n",
      "         168       1.00      1.00      1.00         1\n",
      "         169       0.00      0.00      0.00         1\n",
      "         170       1.00      1.00      1.00         1\n",
      "         171       1.00      1.00      1.00         1\n",
      "         172       1.00      1.00      1.00         1\n",
      "         173       1.00      1.00      1.00         1\n",
      "         174       0.50      1.00      0.67         1\n",
      "         175       1.00      1.00      1.00         1\n",
      "         176       1.00      1.00      1.00         1\n",
      "         177       1.00      1.00      1.00         1\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       1.00      1.00      1.00         1\n",
      "         181       1.00      1.00      1.00         1\n",
      "         182       1.00      1.00      1.00         1\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       1.00      1.00      1.00         1\n",
      "         185       1.00      1.00      1.00         1\n",
      "         186       1.00      1.00      1.00         1\n",
      "         187       1.00      1.00      1.00         1\n",
      "         188       1.00      1.00      1.00         1\n",
      "         189       1.00      1.00      1.00         1\n",
      "         190       0.50      1.00      0.67         1\n",
      "         191       1.00      1.00      1.00         1\n",
      "         192       1.00      1.00      1.00         1\n",
      "         193       1.00      1.00      1.00         1\n",
      "         194       1.00      1.00      1.00         1\n",
      "         195       1.00      1.00      1.00         1\n",
      "         196       1.00      1.00      1.00         1\n",
      "         197       1.00      1.00      1.00         1\n",
      "         198       1.00      1.00      1.00         1\n",
      "         199       1.00      1.00      1.00         1\n",
      "         200       1.00      1.00      1.00         1\n",
      "         201       1.00      1.00      1.00         1\n",
      "         202       1.00      1.00      1.00         2\n",
      "         203       1.00      1.00      1.00         1\n",
      "         204       1.00      1.00      1.00         1\n",
      "         205       1.00      1.00      1.00         1\n",
      "         206       1.00      1.00      1.00         1\n",
      "         207       1.00      1.00      1.00         2\n",
      "         208       1.00      1.00      1.00         1\n",
      "         209       1.00      1.00      1.00         1\n",
      "         210       1.00      1.00      1.00         1\n",
      "         211       1.00      1.00      1.00         2\n",
      "         212       1.00      1.00      1.00         1\n",
      "         213       1.00      1.00      1.00         2\n",
      "         214       1.00      1.00      1.00         1\n",
      "         215       1.00      1.00      1.00         2\n",
      "         216       1.00      1.00      1.00         2\n",
      "         217       1.00      1.00      1.00         2\n",
      "         218       1.00      1.00      1.00         2\n",
      "         219       1.00      1.00      1.00         3\n",
      "         220       1.00      1.00      1.00         1\n",
      "         221       1.00      1.00      1.00         4\n",
      "         222       0.50      1.00      0.67         1\n",
      "         223       1.00      1.00      1.00         1\n",
      "         224       1.00      1.00      1.00         1\n",
      "         225       1.00      1.00      1.00         3\n",
      "         226       1.00      1.00      1.00         4\n",
      "         227       1.00      1.00      1.00         3\n",
      "         228       1.00      1.00      1.00         4\n",
      "         229       0.67      1.00      0.80         2\n",
      "         230       1.00      1.00      1.00         1\n",
      "         231       0.00      0.00      0.00         1\n",
      "         232       1.00      1.00      1.00         2\n",
      "         233       1.00      1.00      1.00         7\n",
      "         234       1.00      1.00      1.00         1\n",
      "         235       1.00      0.75      0.86         4\n",
      "         236       1.00      1.00      1.00         4\n",
      "         237       0.67      1.00      0.80         2\n",
      "         238       0.75      0.75      0.75         4\n",
      "         239       1.00      0.67      0.80         3\n",
      "         240       1.00      1.00      1.00         1\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       0.83      0.71      0.77         7\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       1.00      1.00      1.00         1\n",
      "         245       1.00      1.00      1.00         2\n",
      "         246       1.00      1.00      1.00         6\n",
      "         247       1.00      1.00      1.00         6\n",
      "         248       1.00      1.00      1.00         6\n",
      "         249       1.00      0.67      0.80         3\n",
      "         250       1.00      1.00      1.00         4\n",
      "         251       0.88      1.00      0.93         7\n",
      "         252       1.00      0.80      0.89         5\n",
      "         253       1.00      1.00      1.00         1\n",
      "         254       1.00      0.67      0.80         3\n",
      "         255       1.00      1.00      1.00         1\n",
      "         256       1.00      1.00      1.00         1\n",
      "         257       1.00      1.00      1.00         3\n",
      "         258       1.00      1.00      1.00         2\n",
      "         259       1.00      1.00      1.00         7\n",
      "         260       0.80      1.00      0.89         4\n",
      "         261       0.33      1.00      0.50         1\n",
      "         262       1.00      1.00      1.00         2\n",
      "         263       0.90      1.00      0.95         9\n",
      "         264       1.00      1.00      1.00         8\n",
      "         265       1.00      1.00      1.00         2\n",
      "         266       0.86      0.86      0.86         7\n",
      "         267       1.00      1.00      1.00         4\n",
      "         268       1.00      1.00      1.00         2\n",
      "         269       1.00      1.00      1.00         1\n",
      "         270       1.00      1.00      1.00         2\n",
      "         271       1.00      1.00      1.00         4\n",
      "         272       0.75      0.75      0.75         8\n",
      "         273       0.83      0.77      0.80        13\n",
      "         274       1.00      1.00      1.00        15\n",
      "         275       1.00      1.00      1.00        39\n",
      "         276       1.00      0.93      0.96        14\n",
      "         277       1.00      1.00      1.00         3\n",
      "         278       1.00      1.00      1.00         5\n",
      "         279       1.00      1.00      1.00        49\n",
      "         280       0.95      1.00      0.97        18\n",
      "         281       0.80      0.73      0.76        11\n",
      "         282       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.95       739\n",
      "   macro avg       0.94      0.96      0.94       739\n",
      "weighted avg       0.96      0.95      0.95       739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "r = classification_report(y_true=y_t, y_pred=p)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "908d2a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.88      1.00      0.93         7\n",
      "           2       0.81      1.00      0.89        21\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       0.60      1.00      0.75         3\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      0.38      0.55         8\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      0.83      0.91         6\n",
      "          10       1.00      0.60      0.75         5\n",
      "          11       1.00      0.60      0.75         5\n",
      "          12       0.83      1.00      0.91         5\n",
      "          13       0.67      1.00      0.80         4\n",
      "          14       1.00      0.25      0.40         4\n",
      "          15       0.57      1.00      0.73         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       0.04      1.00      0.08         4\n",
      "          18       0.04      1.00      0.08         4\n",
      "          19       0.00      0.00      0.00         4\n",
      "          20       1.00      0.50      0.67         4\n",
      "          21       1.00      0.75      0.86         4\n",
      "          22       0.80      1.00      0.89         4\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.75      1.00      0.86         3\n",
      "          26       0.00      0.00      0.00         3\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       1.00      0.67      0.80         3\n",
      "          29       0.00      0.00      0.00         3\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       0.12      1.00      0.21         3\n",
      "          34       1.00      1.00      1.00         3\n",
      "          35       0.00      0.00      0.00         3\n",
      "          36       0.00      0.00      0.00         3\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.60      1.00      0.75         3\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       0.67      1.00      0.80         2\n",
      "          41       0.75      1.00      0.86         3\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       1.00      0.50      0.67         2\n",
      "          57       0.67      1.00      0.80         2\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       0.25      0.50      0.33         2\n",
      "          60       0.00      0.00      0.00         2\n",
      "          61       1.00      0.50      0.67         2\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       1.00      0.50      0.67         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.50      1.00      0.67         1\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       1.00      1.00      1.00         1\n",
      "          77       0.50      1.00      0.67         1\n",
      "          78       1.00      1.00      1.00         1\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       1.00      1.00      1.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          85       1.00      1.00      1.00         1\n",
      "          86       1.00      1.00      1.00         1\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       1.00      1.00      1.00         1\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.50      1.00      0.67         1\n",
      "          94       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       1.00      1.00      1.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.50      1.00      0.67         1\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         1\n",
      "         104       1.00      1.00      1.00         1\n",
      "         105       1.00      1.00      1.00         1\n",
      "         106       1.00      1.00      1.00         1\n",
      "         107       0.00      0.00      0.00         1\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       1.00      1.00      1.00         1\n",
      "         126       1.00      1.00      1.00         1\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       1.00      1.00      1.00         1\n",
      "         129       0.00      0.00      0.00         1\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         1\n",
      "         132       0.00      0.00      0.00         1\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         1\n",
      "         136       0.50      1.00      0.67         1\n",
      "         137       0.50      1.00      0.67         1\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       1.00      1.00      1.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         150       0.00      0.00      0.00         1\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       1.00      1.00      1.00         1\n",
      "         156       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       1.00      1.00      1.00         1\n",
      "         159       1.00      1.00      1.00         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         1\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         1\n",
      "         167       0.00      0.00      0.00         1\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         1\n",
      "         170       0.50      1.00      0.67         1\n",
      "         171       1.00      1.00      1.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.33      1.00      0.50         1\n",
      "         174       1.00      1.00      1.00         1\n",
      "         175       1.00      1.00      1.00         1\n",
      "         176       0.00      0.00      0.00         1\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       1.00      1.00      1.00         1\n",
      "         181       0.00      0.00      0.00         1\n",
      "         182       1.00      1.00      1.00         1\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         1\n",
      "         186       0.50      1.00      0.67         1\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       0.00      0.00      0.00         1\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       0.00      0.00      0.00         1\n",
      "         192       0.00      0.00      0.00         1\n",
      "         193       0.00      0.00      0.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         1\n",
      "         196       0.50      1.00      0.67         1\n",
      "         197       0.00      0.00      0.00         1\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       1.00      1.00      1.00         1\n",
      "         200       1.00      1.00      1.00         1\n",
      "         201       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         2\n",
      "         203       1.00      1.00      1.00         1\n",
      "         204       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       0.00      0.00      0.00         2\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00         1\n",
      "         211       0.00      0.00      0.00         2\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       1.00      1.00      1.00         2\n",
      "         214       1.00      1.00      1.00         1\n",
      "         215       0.00      0.00      0.00         2\n",
      "         216       1.00      1.00      1.00         2\n",
      "         217       0.00      0.00      0.00         2\n",
      "         218       0.00      0.00      0.00         2\n",
      "         219       1.00      0.67      0.80         3\n",
      "         220       0.00      0.00      0.00         1\n",
      "         221       1.00      1.00      1.00         4\n",
      "         222       0.00      0.00      0.00         1\n",
      "         223       1.00      1.00      1.00         1\n",
      "         224       0.00      0.00      0.00         1\n",
      "         225       1.00      1.00      1.00         3\n",
      "         226       0.00      0.00      0.00         4\n",
      "         227       0.75      1.00      0.86         3\n",
      "         228       1.00      0.50      0.67         4\n",
      "         229       1.00      1.00      1.00         2\n",
      "         230       1.00      1.00      1.00         1\n",
      "         231       0.50      1.00      0.67         1\n",
      "         232       1.00      1.00      1.00         2\n",
      "         233       1.00      0.86      0.92         7\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       1.00      0.75      0.86         4\n",
      "         236       1.00      1.00      1.00         4\n",
      "         237       0.67      1.00      0.80         2\n",
      "         238       0.00      0.00      0.00         4\n",
      "         239       1.00      0.33      0.50         3\n",
      "         240       0.00      0.00      0.00         1\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       1.00      0.43      0.60         7\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       0.67      1.00      0.80         2\n",
      "         246       1.00      1.00      1.00         6\n",
      "         247       0.00      0.00      0.00         6\n",
      "         248       1.00      0.83      0.91         6\n",
      "         249       0.67      0.67      0.67         3\n",
      "         250       1.00      1.00      1.00         4\n",
      "         251       1.00      1.00      1.00         7\n",
      "         252       1.00      0.60      0.75         5\n",
      "         253       0.00      0.00      0.00         1\n",
      "         254       0.00      0.00      0.00         3\n",
      "         255       0.00      0.00      0.00         1\n",
      "         256       0.00      0.00      0.00         1\n",
      "         257       0.00      0.00      0.00         3\n",
      "         258       0.00      0.00      0.00         2\n",
      "         259       1.00      1.00      1.00         7\n",
      "         260       0.00      0.00      0.00         4\n",
      "         261       0.33      1.00      0.50         1\n",
      "         262       0.00      0.00      0.00         2\n",
      "         263       1.00      0.33      0.50         9\n",
      "         264       1.00      0.50      0.67         8\n",
      "         265       1.00      1.00      1.00         2\n",
      "         266       1.00      0.43      0.60         7\n",
      "         267       0.00      0.00      0.00         4\n",
      "         268       0.00      0.00      0.00         2\n",
      "         269       0.00      0.00      0.00         1\n",
      "         270       1.00      1.00      1.00         2\n",
      "         271       0.07      0.75      0.13         4\n",
      "         272       0.40      1.00      0.57         8\n",
      "         273       0.00      0.00      0.00        13\n",
      "         274       0.93      0.93      0.93        15\n",
      "         275       0.00      0.00      0.00        39\n",
      "         276       0.00      0.00      0.00        14\n",
      "         277       1.00      0.67      0.80         3\n",
      "         278       1.00      1.00      1.00         5\n",
      "         279       1.00      0.63      0.78        49\n",
      "         280       0.92      0.61      0.73        18\n",
      "         281       1.00      0.45      0.62        11\n",
      "         282       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.49       739\n",
      "   macro avg       0.37      0.38      0.36       739\n",
      "weighted avg       0.54      0.49      0.48       739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_words = X_to_words(X_test, char_tokenizer)\n",
    "baseline_pred = [assign_bucket(word, buckets) for word in test_words]\n",
    "r = classification_report(y_true=y_t, y_pred=baseline_pred)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "85ccdafd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: flang\n",
      "['trang', 'vingefang', 'opprørstrang', 'kjøkkengang', 'sprang']\n",
      "\n",
      "Word: gorlang\n",
      "['trang', 'vingefang', 'opprørstrang', 'kjøkkengang', 'sprang']\n",
      "\n",
      "Word: blatt\n",
      "['vinter-natt', 'betatt', 'satt', 'glatt', 'fatt']\n",
      "\n",
      "Word: knatt\n",
      "['vinter-natt', 'betatt', 'satt', 'glatt', 'fatt']\n",
      "\n",
      "Word: pril\n",
      "['halofil', 'bussfil', 'vegetabil', 'femmil', 'postill']\n",
      "\n",
      "Word: glunn\n",
      "['munn', 'blomstergrunn', 'offerlund', 'barne-munn', 'sekund']\n",
      "\n",
      "Word: svans\n",
      "['solskinnsglans', 'vanns', 'krans', 'Hans', 'blomsterkrans']\n",
      "\n",
      "Word: stritt\n",
      "['milevidt', 'kreditt', 'granitt', 'hvitt', 'mareritt']\n",
      "\n",
      "Word: hjal\n",
      "['sjal', 'kanal', 'Kal', 'ritual', 'smal']\n",
      "\n",
      "Word: sta\n",
      "['Antiokia', 'fra', 'ja', 'hurra', 'ta']\n",
      "\n",
      "Word: plirk\n",
      "['brysk', 'jysk', 'kysk', 'tysk', 'alltysk']\n",
      "\n",
      "Word: coll\n",
      "['avindsskjold', 'gold', 'protokoll', 'kold', 'vold']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_some_more = char_tokenizer.texts_to_sequences(some_more)\n",
    "test_some_more =  tf.keras.preprocessing.sequence.pad_sequences(test_some_more, maxlen=MAX_LEN, padding=\"post\", value=0) \n",
    "more_preds = model.predict(test_some_more)\n",
    "more_preds = np.argmax(more_preds, axis=1)\n",
    "\n",
    "\n",
    "for w, i in zip(some_more, more_preds):\n",
    "    print(f\"Word: {w}\")\n",
    "    print(buckets[i][:5])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02188400",
   "metadata": {},
   "source": [
    "## All larger than 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6435f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/merged_wiktionary_almost_rhyme_and_norsc_buckets.pickle','rb') as f:\n",
    "    buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7e602b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = [list(b) for b in buckets if len(b) >= 10]\n",
    "bucket_vocab_size = len(buckets)\n",
    "bucket_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "640c7691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.0, 25.211180124223603)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [len(b) for b in buckets]\n",
    "np.median(l), np.mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "be94a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_name = \"merged_big_10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8532212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_indexer = {w:i for i,b in enumerate(buckets) for w in b}\n",
    "\n",
    "# with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"wb+\") as f:\n",
    "#     pickle.dump(bucket_indexer, f)\n",
    "\n",
    "with open(f\"pickles/{buckets_name}_bucket_indexer.pickle\", \"rb\") as f:\n",
    "    bucket_indexer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7e013f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_indexer[buckets[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b49d3f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4054"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(bucket_indexer.keys())\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8ede6d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4054, 60), (4054, 161))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = buckets_to_data(vocab, char_tokenizer, bucket_indexer)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7299444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d0739df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"rhyme_gen_\" + buckets_name\n",
    "\n",
    "# # Uncomment to train\n",
    "# model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Embedding(input_dim=MAX_LEN, output_dim=128, mask_zero=True),\n",
    "#             tf.keras.layers.LSTM(units=128),\n",
    "#             tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#             tf.keras.layers.Dense(bucket_vocab_size, activation=\"softmax\"),\n",
    "#         ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"models/{model_name}.hdf5\",monitor=\"val_loss\")\n",
    "# terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "# csv_logger = tf.keras.callbacks.CSVLogger(f'logs/training_{model_name}.log')\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=100,\n",
    "#                     validation_data = (X_dev, y_dev),\n",
    "#                     callbacks=[model_checkpoint, terminate_on_nan, early_stop, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "03a5f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"models/{model_name}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "335d1bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((609,), (609,))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "p = np.argmax(preds, axis=1)\n",
    "y_t = np.argmax(y_test, axis=1)\n",
    "p.shape, y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5c103749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 of 161 buckets are missing from predictions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{len(set(y_t))-len(set(p))} of {len(set(y_t))} buckets are missing from predictions. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eddfb5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      0.95      0.98        21\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         8\n",
      "           8       1.00      0.86      0.92         7\n",
      "           9       1.00      1.00      1.00         6\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      0.80      0.89         5\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         4\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       1.00      1.00      1.00         4\n",
      "          19       0.80      1.00      0.89         4\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       1.00      0.75      0.86         4\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       0.75      1.00      0.86         3\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       1.00      0.67      0.80         3\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       1.00      1.00      1.00         3\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         3\n",
      "          41       0.75      1.00      0.86         3\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      0.50      0.67         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       1.00      1.00      1.00         1\n",
      "          68       0.50      1.00      0.67         1\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       1.00      1.00      1.00         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       1.00      1.00      1.00         1\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       1.00      1.00      1.00         1\n",
      "          77       1.00      1.00      1.00         1\n",
      "          78       1.00      1.00      1.00         1\n",
      "          79       1.00      1.00      1.00         1\n",
      "          80       1.00      1.00      1.00         1\n",
      "          81       1.00      1.00      1.00         1\n",
      "          82       1.00      1.00      1.00         1\n",
      "          83       1.00      1.00      1.00         1\n",
      "          84       1.00      1.00      1.00         1\n",
      "          85       1.00      1.00      1.00         1\n",
      "          86       1.00      1.00      1.00         1\n",
      "          87       1.00      1.00      1.00         1\n",
      "          88       1.00      1.00      1.00         1\n",
      "          89       1.00      1.00      1.00         1\n",
      "          90       1.00      1.00      1.00         1\n",
      "          91       0.50      1.00      0.67         1\n",
      "          92       1.00      1.00      1.00         1\n",
      "          93       1.00      1.00      1.00         1\n",
      "          94       1.00      1.00      1.00         1\n",
      "          95       1.00      1.00      1.00         1\n",
      "          96       1.00      1.00      1.00         1\n",
      "          97       1.00      1.00      1.00         1\n",
      "          98       1.00      1.00      1.00         1\n",
      "          99       1.00      1.00      1.00         1\n",
      "         100       1.00      1.00      1.00         2\n",
      "         101       1.00      1.00      1.00         1\n",
      "         102       1.00      1.00      1.00         1\n",
      "         103       1.00      1.00      1.00         2\n",
      "         104       1.00      1.00      1.00         1\n",
      "         105       1.00      1.00      1.00         2\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       1.00      1.00      1.00         2\n",
      "         108       1.00      1.00      1.00         2\n",
      "         109       0.67      1.00      0.80         2\n",
      "         110       1.00      1.00      1.00         2\n",
      "         111       1.00      1.00      1.00         3\n",
      "         112       1.00      1.00      1.00         4\n",
      "         113       1.00      1.00      1.00         3\n",
      "         114       1.00      1.00      1.00         4\n",
      "         115       1.00      1.00      1.00         3\n",
      "         116       1.00      1.00      1.00         4\n",
      "         117       1.00      1.00      1.00         2\n",
      "         118       1.00      1.00      1.00         2\n",
      "         119       1.00      1.00      1.00         7\n",
      "         120       1.00      1.00      1.00         1\n",
      "         121       1.00      1.00      1.00         4\n",
      "         122       1.00      1.00      1.00         4\n",
      "         123       1.00      1.00      1.00         2\n",
      "         124       1.00      0.75      0.86         4\n",
      "         125       0.67      1.00      0.80         2\n",
      "         126       1.00      1.00      1.00         7\n",
      "         127       1.00      1.00      1.00         2\n",
      "         128       1.00      1.00      1.00         6\n",
      "         129       1.00      1.00      1.00         6\n",
      "         130       1.00      1.00      1.00         6\n",
      "         131       1.00      0.67      0.80         3\n",
      "         132       1.00      1.00      1.00         4\n",
      "         133       0.88      1.00      0.93         7\n",
      "         134       1.00      1.00      1.00         5\n",
      "         135       0.67      0.67      0.67         3\n",
      "         136       1.00      1.00      1.00         1\n",
      "         137       1.00      1.00      1.00         3\n",
      "         138       0.67      1.00      0.80         2\n",
      "         139       0.75      0.86      0.80         7\n",
      "         140       1.00      1.00      1.00         4\n",
      "         141       1.00      0.50      0.67         2\n",
      "         142       0.82      1.00      0.90         9\n",
      "         143       1.00      1.00      1.00         8\n",
      "         144       1.00      1.00      1.00         2\n",
      "         145       1.00      1.00      1.00         7\n",
      "         146       0.67      0.50      0.57         4\n",
      "         147       1.00      1.00      1.00         2\n",
      "         148       0.67      1.00      0.80         2\n",
      "         149       1.00      0.75      0.86         4\n",
      "         150       0.86      0.75      0.80         8\n",
      "         151       0.92      0.92      0.92        13\n",
      "         152       1.00      1.00      1.00        15\n",
      "         153       1.00      0.97      0.99        39\n",
      "         154       0.75      0.64      0.69        14\n",
      "         155       1.00      1.00      1.00         3\n",
      "         156       1.00      1.00      1.00         5\n",
      "         157       1.00      1.00      1.00        49\n",
      "         158       1.00      1.00      1.00        18\n",
      "         159       0.85      1.00      0.92        11\n",
      "         160       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.96       609\n",
      "   macro avg       0.96      0.97      0.96       609\n",
      "weighted avg       0.97      0.96      0.96       609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = classification_report(y_true=y_t, y_pred=p)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cb949c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.88      1.00      0.93         7\n",
      "           2       0.88      1.00      0.93        21\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       0.50      1.00      0.67         3\n",
      "           7       0.75      0.38      0.50         8\n",
      "           8       1.00      0.86      0.92         7\n",
      "           9       0.80      0.67      0.73         6\n",
      "          10       1.00      0.80      0.89         5\n",
      "          11       1.00      0.60      0.75         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      0.50      0.67         4\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       0.06      1.00      0.12         4\n",
      "          18       0.06      1.00      0.12         4\n",
      "          19       0.00      0.00      0.00         4\n",
      "          20       0.75      0.75      0.75         4\n",
      "          21       0.67      0.50      0.57         4\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       0.06      0.33      0.11         3\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.75      1.00      0.86         3\n",
      "          26       0.00      0.00      0.00         3\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.75      1.00      0.86         3\n",
      "          29       0.00      0.00      0.00         3\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       0.21      1.00      0.35         3\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       0.00      0.00      0.00         2\n",
      "          36       0.00      0.00      0.00         3\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.67      1.00      0.80         2\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       1.00      1.00      1.00         3\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       0.75      1.00      0.86         3\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         2\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       0.25      0.50      0.33         2\n",
      "          60       0.00      0.00      0.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.67      1.00      0.80         2\n",
      "          64       0.67      1.00      0.80         2\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       0.50      1.00      0.67         1\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       1.00      1.00      1.00         1\n",
      "          77       1.00      1.00      1.00         1\n",
      "          78       1.00      1.00      1.00         1\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       1.00      1.00      1.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          85       0.50      1.00      0.67         1\n",
      "          86       1.00      1.00      1.00         1\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       1.00      1.00      1.00         1\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       1.00      1.00      1.00         1\n",
      "          94       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       1.00      1.00      1.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       1.00      1.00      1.00         1\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         2\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       0.00      0.00      0.00         2\n",
      "         108       1.00      1.00      1.00         2\n",
      "         109       0.00      0.00      0.00         2\n",
      "         110       0.00      0.00      0.00         2\n",
      "         111       0.00      0.00      0.00         3\n",
      "         112       0.80      1.00      0.89         4\n",
      "         113       1.00      1.00      1.00         3\n",
      "         114       0.00      0.00      0.00         4\n",
      "         115       1.00      1.00      1.00         3\n",
      "         116       1.00      0.75      0.86         4\n",
      "         117       1.00      1.00      1.00         2\n",
      "         118       1.00      1.00      1.00         2\n",
      "         119       1.00      0.71      0.83         7\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       1.00      1.00      1.00         4\n",
      "         122       0.80      1.00      0.89         4\n",
      "         123       1.00      1.00      1.00         2\n",
      "         124       0.00      0.00      0.00         4\n",
      "         125       0.67      1.00      0.80         2\n",
      "         126       1.00      0.86      0.92         7\n",
      "         127       0.50      1.00      0.67         2\n",
      "         128       0.75      1.00      0.86         6\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.83      0.83      0.83         6\n",
      "         131       1.00      1.00      1.00         3\n",
      "         132       1.00      1.00      1.00         4\n",
      "         133       0.88      1.00      0.93         7\n",
      "         134       0.80      0.80      0.80         5\n",
      "         135       0.00      0.00      0.00         3\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         3\n",
      "         138       0.00      0.00      0.00         2\n",
      "         139       1.00      0.71      0.83         7\n",
      "         140       0.00      0.00      0.00         4\n",
      "         141       0.00      0.00      0.00         2\n",
      "         142       0.75      0.33      0.46         9\n",
      "         143       0.80      0.50      0.62         8\n",
      "         144       1.00      1.00      1.00         2\n",
      "         145       0.50      0.29      0.36         7\n",
      "         146       0.00      0.00      0.00         4\n",
      "         147       0.00      0.00      0.00         2\n",
      "         148       0.67      1.00      0.80         2\n",
      "         149       0.05      0.50      0.09         4\n",
      "         150       0.35      0.88      0.50         8\n",
      "         151       0.00      0.00      0.00        13\n",
      "         152       0.93      0.93      0.93        15\n",
      "         153       0.00      0.00      0.00        39\n",
      "         154       0.00      0.00      0.00        14\n",
      "         155       1.00      0.67      0.80         3\n",
      "         156       0.83      1.00      0.91         5\n",
      "         157       1.00      0.49      0.66        49\n",
      "         158       1.00      0.78      0.88        18\n",
      "         159       1.00      0.64      0.78        11\n",
      "         160       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.54       609\n",
      "   macro avg       0.47      0.49      0.46       609\n",
      "weighted avg       0.58      0.54      0.53       609\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tita/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_words = X_to_words(X_test, char_tokenizer)\n",
    "baseline_pred = [assign_bucket(word, buckets) for word in test_words]\n",
    "r = classification_report(y_true=y_t, y_pred=baseline_pred)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "17fc44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: flang\n",
      "['trang', 'vingefang', 'opprørstrang', 'kjøkkengang', 'sprang']\n",
      "\n",
      "Word: gorlang\n",
      "['trang', 'vingefang', 'opprørstrang', 'kjøkkengang', 'sprang']\n",
      "\n",
      "Word: blatt\n",
      "['vinter-natt', 'betatt', 'satt', 'glatt', 'fatt']\n",
      "\n",
      "Word: knatt\n",
      "['vinter-natt', 'betatt', 'satt', 'glatt', 'fatt']\n",
      "\n",
      "Word: pril\n",
      "['halofil', 'bussfil', 'vegetabil', 'femmil', 'postill']\n",
      "\n",
      "Word: glunn\n",
      "['munn', 'blomstergrunn', 'offerlund', 'barne-munn', 'sekund']\n",
      "\n",
      "Word: svans\n",
      "['solskinnsglans', 'vanns', 'krans', 'Hans', 'blomsterkrans']\n",
      "\n",
      "Word: stritt\n",
      "['milevidt', 'kreditt', 'granitt', 'hvitt', 'mareritt']\n",
      "\n",
      "Word: hjal\n",
      "['sjal', 'kanal', 'Kal', 'ritual', 'smal']\n",
      "\n",
      "Word: sta\n",
      "['Antiokia', 'fra', 'ja', 'hurra', 'ta']\n",
      "\n",
      "Word: plirk\n",
      "['mystikk', 'leskedrikk', 'stikk', 'politikk', 'forgikk']\n",
      "\n",
      "Word: coll\n",
      "['avindsskjold', 'gold', 'protokoll', 'kold', 'vold']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_some_more = char_tokenizer.texts_to_sequences(some_more)\n",
    "test_some_more =  tf.keras.preprocessing.sequence.pad_sequences(test_some_more, maxlen=MAX_LEN, padding=\"post\", value=0) \n",
    "more_preds = model.predict(test_some_more)\n",
    "more_preds = np.argmax(more_preds, axis=1)\n",
    "\n",
    "for w, i in zip(some_more, more_preds):\n",
    "    print(f\"Word: {w}\")\n",
    "    print(buckets[i][:5])\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
